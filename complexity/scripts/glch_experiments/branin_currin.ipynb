{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba23d4e-5f38-4bb3-b2ae-066de2d4930f",
   "metadata": {},
   "source": [
    "https://archive.ax.dev/versions/0.4.1/tutorials/multiobjective_optimization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489316b0-4a9a-4a63-831b-7f7a0263499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from botorch.test_functions.multi_objective import BraninCurrin,ZDT1,ZDT2,ZDT3\n",
    "from complexity.glch_experiments_functions import save_glch_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "606c1674-1e6b-4f15-8c66-8ce2280ccd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEvaluator:\n",
    "\n",
    "    def __init__(self,name,best_init_pt,best_init_pt_img_loc,best_h1_list,best_h2_list,func):\n",
    "        self.name = name\n",
    "        self.best_init_pt = best_init_pt # best initial point\n",
    "        self.best_init_pt_img_loc = best_init_pt_img_loc # best initial point image location\n",
    "        self.best_h1_list = best_h1_list\n",
    "        self.best_h2_list = best_h2_list\n",
    "        self.func = func\n",
    "\n",
    "    def evaluate_one(self,parameters):\n",
    "        evaluation = self.func(torch.tensor([parameters.get(\"h1\"), parameters.get(\"h2\")]))\n",
    "        return {\"a\": evaluation[0].item(), \"b\": evaluation[1].item()}\n",
    "\n",
    "    def evaluate_many(self,possible_values):\n",
    "        \n",
    "        evaluations = []\n",
    "        for h1 in possible_values[\"h1\"]:\n",
    "            for h2 in possible_values[\"h2\"]:\n",
    "                e = self.evaluate_one({\"h1\":h1/max(possible_values[\"h1\"]),\"h2\":h2/max(possible_values[\"h2\"])})\n",
    "                evaluations.append({\"h1\":h1,\"h2\":h2,\"a\": e[\"a\"],\"b\": e[\"b\"]})\n",
    "        \n",
    "        data = pd.DataFrame(evaluations)\n",
    "    \n",
    "        data[\"topology\"] = (data[\"h1\"]).astype(int).apply(lambda x: f\"{x:02d}\") + \"_\" + \\\n",
    "            (data[\"h2\"]).astype(int).apply(lambda x: f\"{x:02d}\")\n",
    "    \n",
    "        data = data.set_index(\"topology\")\n",
    "    \n",
    "        return data\n",
    "\n",
    "\n",
    "class BraninCurrinEvaluator(BaseEvaluator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"branin_currin\",\n",
    "            [0,0],\n",
    "            \"right\",\n",
    "            list(np.arange(0,40 + 1)),\n",
    "            list(np.arange(0,10 + 1)),\n",
    "            BraninCurrin(negate=False).to(dtype=torch.double,device=torch.device(\"cpu\"))\n",
    "        )\n",
    "\n",
    "class ZDT1Evaluator(BaseEvaluator):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            \"zdt1\",\n",
    "            [0,0],\n",
    "            \"left\",\n",
    "            list(np.arange(0,40 + 1)),\n",
    "            list(np.arange(0,10 + 1)),\n",
    "            ZDT1(2).to(dtype=torch.double,device=torch.device(\"cpu\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7261e92-de9a-4a80-9056-12e5fe44b396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a2e25f9-69c2-4771-8566-2902e6f84125",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e36bf74-ca23-43a3-85fe-a7f2a6dbf3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = BraninCurrinEvaluator()\n",
    "evaluator = ZDT1Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7571e2fa-ac4a-4ec4-bc7e-6b9c788da6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = evaluator.evaluate_many({\"h1\": list(np.arange(0,40 + 1)),\"h2\": list(np.arange(0,10 + 1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e218d8e-187e-44e9-9ad5-5eb6c8389419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[\"40_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57b427c-20f2-477a-873f-2168e1e0bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[\"00_00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bae6712f-4caf-4287-9f40-91aa70546181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# plt.close('all')\n",
    "# matplotlib.use(\"Qt5Agg\")\n",
    "# %matplotlib inline\n",
    "# plt.scatter(list(data[\"a\"]),list(data[\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e38d3e3-ecf4-47c0-8c9c-7fe53cf57f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(list(data[\"h1\"]),list(data[\"h2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05526d6-96b3-4415-9b4b-089094c4035f",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2da3f9f2-4b77-4c42-a269-a64abbb26f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def glch_synthetic_2d(evaluator):\n",
    "    \n",
    "    possible_values = {\"h1\": evaluator.best_h1_list,\"h2\": evaluator.best_h2_list} # possible values for the hyperparameters\n",
    "    data = evaluator.evaluate_many(possible_values) # dataframe that maps hyperparameters to objectives\n",
    "    to_str_method = lambda p : '_'.join(map(lambda x: f\"{x:02d}\",[p[\"h1\"],p[\"h2\"]])) # converts hyperparameters to dataframe index\n",
    "    initial_values = {\"h1\":evaluator.best_init_pt[0],\"h2\":evaluator.best_init_pt[1]} # initial hyperparameters\n",
    "    x_in_log_scale=False # used when plotting, when the x-axis varies too much, e.g., network parameters\n",
    "    algo=\"glch\" # options are glch (2d) and gho (1d)\n",
    "    select_function=\"angle_rule\" # Used when algo == glch. options are tie_break,gift_wrapping,angle_rule. Recommended: angle_rule\n",
    "    constrained=True # Used when select_function == gift_wrapping/angle_rule. We only implemented the constrained tie_break select function\n",
    "    fldr=\"glch_synthetic_data_results\" # results are stored here\n",
    "    debug=False # used to debug the algorithm implementation if any problem is detected\n",
    "    debug_folder=\"glch_synthetic_data_debug\" # debug results are stored here\n",
    "    title = evaluator.name # identifies the experiment\n",
    "    start=evaluator.best_init_pt_img_loc # if start == left, the algorithm finds the lch from left to right\n",
    "    weights = [1,1] # used only in 1d problems\n",
    "    axes = [\"a\",\"b\"] # names of the objectives in the data variable\n",
    "    axes_ranges=[None,None] # used only to adjust the plots\n",
    "    axes_aliases=[\"1st Objective\",\"2nd Objective\"] # names of the objectives on the plots\n",
    "    axes_scales = [data[\"a\"].max() - data[\"a\"].min(),data[\"b\"].max() - data[\"b\"].min()] # used only if select_function == tie_break\n",
    "    \n",
    "    \n",
    "    save_glch_data(\n",
    "        algo,\n",
    "        data,possible_values,axes,initial_values,to_str_method,constrained,weights,start,\n",
    "        axes_scales,\n",
    "        debug,title,debug_folder,select_function,\n",
    "        x_in_log_scale,axes_ranges,axes_aliases,fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f24600e-2860-4533-86e7-296a793c0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glch_synthetic_2d(BraninCurrinEvaluator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f63a3a8-d5ef-4221-a533-7397a81c032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glch_synthetic_2d(ZDT1Evaluator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cddba-e48e-4393-836e-fcfb7d1bdb5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
