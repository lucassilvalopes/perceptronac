{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "X = (X > 0).astype(int)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)).astype(int) # signal \n",
    "yt = yy[0:L] > 0 # train on the first part \n",
    "yc = yy[L:L+L] > 0 # encode the second part\n",
    "Xt = X[0:L,0:N] # truncated X for training \n",
    "Xc = X[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bbecba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "my_data = genfromtxt('../SPIHT_dataset/SPIHT_bits_with_context_ricardo28_v3.csv', delimiter=',')\n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(float)\n",
    "extra_context = my_data[:, 7:].astype(float)\n",
    "#extra_context = extra_context.reshape((len(extra_context), 1))\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/SPIHT_bits_with_context_ricardo29_v3.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 7:].astype(float)\n",
    "#extra_context_test = extra_context_test.reshape((len(extra_context_test), 1))\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "\n",
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "Xt = np.append(Xt, extra_context, axis=1)\n",
    "Xc = np.append(Xc, extra_context_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0aa3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0. , 0. , 0. , 0. , 0. , 0.5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961499765246234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8974801400717474"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc,context_coding(Xc,context_training(Xc,yc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449d735",
   "metadata": {},
   "source": [
    "# Criando classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.003491003723144531\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0901, 11.7186, 11.9979, 12.1763, 12.1026]], device='cuda:0')\n",
      "tensor([41.8704], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32098451, 0.77295341, 0.82311742, 0.86189127, 0.7005142 ,\n",
       "         0.80153656, 0.21184858]]),\n",
       " array([[0.2792105]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : train , loss : 36.414972073497864\n",
      "epoch : 0 , phase : valid , loss : 38.97983027316965\n",
      "epoch : 1 , phase : train , loss : 33.92692110398681\n",
      "epoch : 1 , phase : valid , loss : 18.174040159914743\n",
      "epoch : 2 , phase : train , loss : 14.608137556246287\n",
      "epoch : 2 , phase : valid , loss : 9.344935176644658\n",
      "epoch : 3 , phase : train , loss : 29.98220732266315\n",
      "epoch : 3 , phase : valid , loss : 16.141568551408316\n",
      "epoch : 4 , phase : train , loss : 28.952730402966168\n",
      "epoch : 4 , phase : valid , loss : 26.381696869328124\n",
      "epoch : 5 , phase : train , loss : 17.66749824039643\n",
      "epoch : 5 , phase : valid , loss : 7.538301044504013\n",
      "epoch : 6 , phase : train , loss : 19.68650433221858\n",
      "epoch : 6 , phase : valid , loss : 50.28031807128541\n",
      "epoch : 7 , phase : train , loss : 50.14528782232276\n",
      "epoch : 7 , phase : valid , loss : 50.22697743016578\n",
      "epoch : 8 , phase : train , loss : 50.10003702287281\n",
      "epoch : 8 , phase : valid , loss : 50.18922151112938\n",
      "epoch : 9 , phase : train , loss : 50.06617177392451\n",
      "epoch : 9 , phase : valid , loss : 50.1589690341009\n",
      "epoch : 10 , phase : train , loss : 50.038099655266876\n",
      "epoch : 10 , phase : valid , loss : 50.13271138256464\n",
      "epoch : 11 , phase : train , loss : 50.01316363160478\n",
      "epoch : 11 , phase : valid , loss : 50.108693741090676\n",
      "epoch : 12 , phase : train , loss : 49.990063494904945\n",
      "epoch : 12 , phase : valid , loss : 50.08606067942126\n",
      "epoch : 13 , phase : train , loss : 49.96810438822754\n",
      "epoch : 13 , phase : valid , loss : 50.06432125497367\n",
      "epoch : 14 , phase : train , loss : 49.946920320810655\n",
      "epoch : 14 , phase : valid , loss : 50.04321850055586\n",
      "epoch : 15 , phase : train , loss : 48.89260298596928\n",
      "epoch : 15 , phase : valid , loss : 45.83960310740958\n",
      "epoch : 16 , phase : train , loss : 43.05140025793958\n",
      "epoch : 16 , phase : valid , loss : 41.58735718033957\n",
      "epoch : 17 , phase : train , loss : 40.88113284566209\n",
      "epoch : 17 , phase : valid , loss : 38.78025112456958\n",
      "epoch : 18 , phase : train , loss : 36.76222348118072\n",
      "epoch : 18 , phase : valid , loss : 30.70175018325818\n",
      "epoch : 19 , phase : train , loss : 23.26186927196487\n",
      "epoch : 19 , phase : valid , loss : 9.02137461978999\n",
      "epoch : 20 , phase : train , loss : 32.491553648583775\n",
      "epoch : 20 , phase : valid , loss : 41.478517035572374\n",
      "epoch : 21 , phase : train , loss : 40.21028245875272\n",
      "epoch : 21 , phase : valid , loss : 38.624890788943375\n",
      "epoch : 22 , phase : train , loss : 34.8363329658169\n",
      "epoch : 22 , phase : valid , loss : 27.65356900380582\n",
      "epoch : 23 , phase : train , loss : 17.956721295746302\n",
      "epoch : 23 , phase : valid , loss : 22.913563421531688\n",
      "epoch : 24 , phase : train , loss : 18.40896530733053\n",
      "epoch : 24 , phase : valid , loss : 9.734140327247719\n",
      "epoch : 25 , phase : train , loss : 15.085147204061125\n",
      "epoch : 25 , phase : valid , loss : 30.32226695104369\n",
      "epoch : 26 , phase : train , loss : 30.235009465921326\n",
      "epoch : 26 , phase : valid , loss : 41.69092307348991\n",
      "epoch : 27 , phase : train , loss : 40.82143973544242\n",
      "epoch : 27 , phase : valid , loss : 38.74427115313351\n",
      "epoch : 28 , phase : train , loss : 33.39227971390677\n",
      "epoch : 28 , phase : valid , loss : 20.88470964059757\n",
      "epoch : 29 , phase : train , loss : 26.741723421510155\n",
      "epoch : 29 , phase : valid , loss : 28.14371160707282\n",
      "epoch : 30 , phase : train , loss : 23.392556707378265\n",
      "epoch : 30 , phase : valid , loss : 26.220837097677286\n",
      "epoch : 31 , phase : train , loss : 24.217130673111086\n",
      "epoch : 31 , phase : valid , loss : 24.47195887781075\n",
      "epoch : 32 , phase : train , loss : 18.24368415895696\n",
      "epoch : 32 , phase : valid , loss : 24.245601803639197\n",
      "epoch : 33 , phase : train , loss : 30.64028083476407\n",
      "epoch : 33 , phase : valid , loss : 38.83357316937925\n",
      "epoch : 34 , phase : train , loss : 34.35874655199069\n",
      "epoch : 34 , phase : valid , loss : 24.09774059905815\n",
      "epoch : 35 , phase : train , loss : 20.127233153914794\n",
      "epoch : 35 , phase : valid , loss : 7.622515046950611\n",
      "epoch : 36 , phase : train , loss : 26.037621358400393\n",
      "epoch : 36 , phase : valid , loss : 41.65362141158841\n",
      "epoch : 37 , phase : train , loss : 40.68574107450412\n",
      "epoch : 37 , phase : valid , loss : 38.72273020203031\n",
      "epoch : 38 , phase : train , loss : 33.66412270031002\n",
      "epoch : 38 , phase : valid , loss : 22.7048981158895\n",
      "epoch : 39 , phase : train , loss : 25.0205842256795\n",
      "epoch : 39 , phase : valid , loss : 37.051479995780326\n",
      "epoch : 40 , phase : train , loss : 27.421924923241956\n",
      "epoch : 40 , phase : valid , loss : 4.1767147319291205\n",
      "epoch : 41 , phase : train , loss : 32.338950079470344\n",
      "epoch : 41 , phase : valid , loss : 41.59460923404842\n",
      "epoch : 42 , phase : train , loss : 40.67432789246279\n",
      "epoch : 42 , phase : valid , loss : 38.716289623664785\n",
      "epoch : 43 , phase : train , loss : 34.510082375892004\n",
      "epoch : 43 , phase : valid , loss : 26.237355523577417\n",
      "epoch : 44 , phase : train , loss : 24.61308012671858\n",
      "epoch : 44 , phase : valid , loss : 38.716013045818606\n",
      "epoch : 45 , phase : train , loss : 34.25522524281851\n",
      "epoch : 45 , phase : valid , loss : 25.80442751090758\n",
      "epoch : 46 , phase : train , loss : 24.07823150009086\n",
      "epoch : 46 , phase : valid , loss : 41.453539993562295\n",
      "epoch : 47 , phase : train , loss : 39.977201436975676\n",
      "epoch : 47 , phase : valid , loss : 37.704698881786975\n",
      "epoch : 48 , phase : train , loss : 32.50329239118937\n",
      "epoch : 48 , phase : valid , loss : 23.12258763595593\n",
      "epoch : 49 , phase : train , loss : 26.992640093601416\n",
      "epoch : 49 , phase : valid , loss : 39.93697440065784\n",
      "epoch : 50 , phase : train , loss : 37.680715016097494\n",
      "epoch : 50 , phase : valid , loss : 32.78177788161657\n",
      "epoch : 51 , phase : train , loss : 23.74405517170883\n",
      "epoch : 51 , phase : valid , loss : 31.135338026816555\n",
      "epoch : 52 , phase : train , loss : 22.01700636508621\n",
      "epoch : 52 , phase : valid , loss : 38.758143831299684\n",
      "epoch : 53 , phase : train , loss : 35.041814995484025\n",
      "epoch : 53 , phase : valid , loss : 26.382016218687195\n",
      "epoch : 54 , phase : train , loss : 23.11664510389459\n",
      "epoch : 54 , phase : valid , loss : 31.184227725678056\n",
      "epoch : 55 , phase : train , loss : 24.884152057549546\n",
      "epoch : 55 , phase : valid , loss : 38.7284590488968\n",
      "epoch : 56 , phase : train , loss : 34.03838037814864\n",
      "epoch : 56 , phase : valid , loss : 24.283144118697205\n",
      "epoch : 57 , phase : train , loss : 23.411273854664206\n",
      "epoch : 57 , phase : valid , loss : 25.704622890502222\n",
      "epoch : 58 , phase : train , loss : 22.518698161197317\n",
      "epoch : 58 , phase : valid , loss : 17.40123816767515\n",
      "epoch : 59 , phase : train , loss : 26.840218333238404\n",
      "epoch : 59 , phase : valid , loss : 35.000329154686135\n",
      "epoch : 60 , phase : train , loss : 24.909258193175315\n",
      "epoch : 60 , phase : valid , loss : 37.19090684398304\n",
      "epoch : 61 , phase : train , loss : 28.77454566459447\n",
      "epoch : 61 , phase : valid , loss : 5.2989400145592205\n",
      "epoch : 62 , phase : train , loss : 40.39299465880642\n",
      "epoch : 62 , phase : valid , loss : 43.01639366156609\n",
      "epoch : 63 , phase : train , loss : 41.94704813787155\n",
      "epoch : 63 , phase : valid , loss : 41.42020560080282\n",
      "epoch : 64 , phase : train , loss : 40.030436564765616\n",
      "epoch : 64 , phase : valid , loss : 37.73498178914084\n",
      "epoch : 65 , phase : train , loss : 33.89549031234828\n",
      "epoch : 65 , phase : valid , loss : 26.474471070227782\n",
      "epoch : 66 , phase : train , loss : 23.177225559479346\n",
      "epoch : 66 , phase : valid , loss : 50.250175481542996\n",
      "epoch : 67 , phase : train , loss : 50.12869465894204\n",
      "epoch : 67 , phase : valid , loss : 50.229448034471474\n",
      "epoch : 68 , phase : train , loss : 50.10842548367061\n",
      "epoch : 68 , phase : valid , loss : 50.20912159146544\n",
      "epoch : 69 , phase : train , loss : 50.0884670360817\n",
      "epoch : 69 , phase : valid , loss : 50.18904907261893\n",
      "epoch : 70 , phase : train , loss : 50.06876015416704\n",
      "epoch : 70 , phase : valid , loss : 50.169183141870235\n",
      "epoch : 71 , phase : train , loss : 50.04924381121318\n",
      "epoch : 71 , phase : valid , loss : 50.14950351233578\n",
      "epoch : 72 , phase : train , loss : 50.029906649470696\n",
      "epoch : 72 , phase : valid , loss : 50.12998989713198\n",
      "epoch : 73 , phase : train , loss : 50.01074985557011\n",
      "epoch : 73 , phase : valid , loss : 50.110670021666394\n",
      "epoch : 74 , phase : train , loss : 49.68515504853658\n",
      "epoch : 74 , phase : valid , loss : 47.055915046646305\n",
      "epoch : 75 , phase : train , loss : 46.8614490182836\n",
      "epoch : 75 , phase : valid , loss : 45.77692999266967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 76 , phase : train , loss : 44.00915688883103\n",
      "epoch : 76 , phase : valid , loss : 41.67472264448995\n",
      "epoch : 77 , phase : train , loss : 41.27775461022916\n",
      "epoch : 77 , phase : valid , loss : 40.81285248460225\n",
      "epoch : 78 , phase : train , loss : 39.71493133816665\n",
      "epoch : 78 , phase : valid , loss : 37.76153782692313\n",
      "epoch : 79 , phase : train , loss : 36.15138286532625\n",
      "epoch : 79 , phase : valid , loss : 33.086108691712404\n",
      "epoch : 80 , phase : train , loss : 28.202116575940288\n",
      "epoch : 80 , phase : valid , loss : 20.64365877664682\n",
      "epoch : 81 , phase : train , loss : 12.944895017948635\n",
      "epoch : 81 , phase : valid , loss : 6.941043949504595\n",
      "epoch : 82 , phase : train , loss : 36.48994211955269\n",
      "epoch : 82 , phase : valid , loss : 40.43227122481383\n",
      "epoch : 83 , phase : train , loss : 38.41628084222289\n",
      "epoch : 83 , phase : valid , loss : 33.37855730503629\n",
      "epoch : 84 , phase : train , loss : 25.98971954156733\n",
      "epoch : 84 , phase : valid , loss : 4.709938804193028\n",
      "epoch : 85 , phase : train , loss : 17.215757487299662\n",
      "epoch : 85 , phase : valid , loss : 7.659331450823242\n",
      "epoch : 86 , phase : train , loss : 20.690816378078118\n",
      "epoch : 86 , phase : valid , loss : 17.43302995425984\n",
      "epoch : 87 , phase : train , loss : 33.23068750322086\n",
      "epoch : 87 , phase : valid , loss : 40.51423564432495\n",
      "epoch : 88 , phase : train , loss : 38.12803896081\n",
      "epoch : 88 , phase : valid , loss : 32.78573010465327\n",
      "epoch : 89 , phase : train , loss : 22.83637924440792\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(300):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271db70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bac832",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
