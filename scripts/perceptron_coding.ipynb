{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "X = (X > 0).astype(int)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)).astype(int) # signal \n",
    "yt = yy[0:L] > 0 # train on the first part \n",
    "yc = yy[L:L+L] > 0 # encode the second part\n",
    "Xt = X[0:L,0:N] # truncated X for training \n",
    "Xc = X[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bbecba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "L = 100000 # how many samples \n",
    "#N = 10 # order of the AR\n",
    "first = True\n",
    "for pc_num in range(11, 38):\n",
    "    if first:\n",
    "        my_data = genfromtxt(f'../SPIHT_dataset/SPIHT_bits_with_context_ricardo{pc_num}_v5.csv', delimiter=',')\n",
    "        first = False\n",
    "    else:\n",
    "        my_data = np.append(my_data,\n",
    "                            genfromtxt(f'../SPIHT_dataset/SPIHT_bits_with_context_ricardo{pc_num}_v5.csv', delimiter=','),\n",
    "                            axis=0)\n",
    "    \n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(float)\n",
    "extra_context = my_data[:, 6:].astype(float)\n",
    "#extra_context = extra_context.reshape((len(extra_context), 1))\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/SPIHT_bits_with_context_ricardo39_v5.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "#extra_context_test = extra_context_test.reshape((len(extra_context_test), 1))\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "\n",
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "Xt = np.append(Xt, extra_context/extra_context.max(axis=0), axis=1)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0aa3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03703704, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.03703704, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03703704, 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.03703704, 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03703704, 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.03703704, 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[0:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863930727603271"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8630416694804717"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc[:],context_coding(Xc[:, :],context_training(Xc[:, :],yc[:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449d735",
   "metadata": {},
   "source": [
    "# Criando classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a561b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_N_64N_32N_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 64*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64*N, 32*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32*N, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28dc8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_N_1024_512_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class MLP_N_2048_1024_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.003491003723144531\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0901, 11.7186, 11.9979, 12.1763, 12.1026]], device='cuda:0')\n",
      "tensor([41.8704], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32098451, 0.77295341, 0.82311742, 0.86189127, 0.7005142 ,\n",
       "         0.80153656, 0.21184858]]),\n",
       " array([[0.2792105]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Perceptron(N)\n",
    "#net = MLP_N_64N_32N_1(N)\n",
    "net = MLP_N_1024_512_1(N) #melhor resultado\n",
    "#net = MLP_N_2048_1024_1(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : train , loss : 0.94574865010092\n",
      "epoch : 0 , phase : valid , loss : 0.9375248378642078\n",
      "epoch : 1 , phase : train , loss : 0.9390850375099759\n",
      "epoch : 1 , phase : valid , loss : 0.9302343690444428\n",
      "epoch : 2 , phase : train , loss : 0.9335460590307181\n",
      "epoch : 2 , phase : valid , loss : 0.9266530133035238\n",
      "epoch : 3 , phase : train , loss : 0.9292743493473878\n",
      "epoch : 3 , phase : valid , loss : 0.9222399453815845\n",
      "epoch : 4 , phase : train , loss : 0.9260195367711569\n",
      "epoch : 4 , phase : valid , loss : 0.9189252337641299\n",
      "epoch : 5 , phase : train , loss : 0.9232785168124248\n",
      "epoch : 5 , phase : valid , loss : 0.9158085710125332\n",
      "epoch : 6 , phase : train , loss : 0.9205771347927059\n",
      "epoch : 6 , phase : valid , loss : 0.9134357227979072\n",
      "epoch : 7 , phase : train , loss : 0.9187165659181135\n",
      "epoch : 7 , phase : valid , loss : 0.9121008005927992\n",
      "epoch : 8 , phase : train , loss : 0.9171505613955967\n",
      "epoch : 8 , phase : valid , loss : 0.9103757255783016\n",
      "epoch : 9 , phase : train , loss : 0.9154612652329288\n",
      "epoch : 9 , phase : valid , loss : 0.9090369003562104\n",
      "epoch : 10 , phase : train , loss : 0.9140824029111997\n",
      "epoch : 10 , phase : valid , loss : 0.909388985456359\n",
      "epoch : 11 , phase : train , loss : 0.91288585043487\n",
      "epoch : 11 , phase : valid , loss : 0.907861185617023\n",
      "epoch : 12 , phase : train , loss : 0.9119089464120959\n",
      "epoch : 12 , phase : valid , loss : 0.9050736072844292\n",
      "epoch : 13 , phase : train , loss : 0.9105268643748198\n",
      "epoch : 13 , phase : valid , loss : 0.9047382908001614\n",
      "epoch : 14 , phase : train , loss : 0.9094519225942455\n",
      "epoch : 14 , phase : valid , loss : 0.9030219497167197\n",
      "epoch : 15 , phase : train , loss : 0.9093092259370513\n",
      "epoch : 15 , phase : valid , loss : 0.9122086732822131\n",
      "epoch : 16 , phase : train , loss : 0.9098379889559302\n",
      "epoch : 16 , phase : valid , loss : 0.9127737599508854\n",
      "epoch : 17 , phase : train , loss : 0.9099566213044811\n",
      "epoch : 17 , phase : valid , loss : 0.9018700332779523\n",
      "epoch : 18 , phase : train , loss : 0.9085274835686563\n",
      "epoch : 18 , phase : valid , loss : 0.8998209041633429\n",
      "epoch : 19 , phase : train , loss : 0.9092992943396577\n",
      "epoch : 19 , phase : valid , loss : 0.907316576493858\n",
      "epoch : 20 , phase : train , loss : 0.9072548572781085\n",
      "epoch : 20 , phase : valid , loss : 0.8984209121778214\n",
      "epoch : 21 , phase : train , loss : 0.9092473435453012\n",
      "epoch : 21 , phase : valid , loss : 0.9107712330717539\n",
      "epoch : 22 , phase : train , loss : 0.9077399483600375\n",
      "epoch : 22 , phase : valid , loss : 0.8987463062783144\n",
      "epoch : 23 , phase : train , loss : 0.9068522289805426\n",
      "epoch : 23 , phase : valid , loss : 0.8965013403619686\n",
      "epoch : 24 , phase : train , loss : 0.907678581514183\n",
      "epoch : 24 , phase : valid , loss : 0.9267126433204852\n",
      "epoch : 25 , phase : train , loss : 0.9071511214622477\n",
      "epoch : 25 , phase : valid , loss : 0.9082256657206973\n",
      "epoch : 26 , phase : train , loss : 0.907902510130686\n",
      "epoch : 26 , phase : valid , loss : 0.9038055760904115\n",
      "epoch : 27 , phase : train , loss : 0.9054574937163493\n",
      "epoch : 27 , phase : valid , loss : 0.911295324768448\n",
      "epoch : 28 , phase : train , loss : 0.9069727278086145\n",
      "epoch : 28 , phase : valid , loss : 0.8975857276942261\n",
      "epoch : 29 , phase : train , loss : 0.9058515557401515\n",
      "epoch : 29 , phase : valid , loss : 0.9093650249733531\n",
      "epoch : 30 , phase : train , loss : 0.9060535796998912\n",
      "epoch : 30 , phase : valid , loss : 0.9064965361415545\n",
      "epoch : 31 , phase : train , loss : 0.9075185017315158\n",
      "epoch : 31 , phase : valid , loss : 0.9036782946653181\n",
      "epoch : 32 , phase : train , loss : 0.9060064081138395\n",
      "epoch : 32 , phase : valid , loss : 0.9020167128038015\n",
      "epoch : 33 , phase : train , loss : 0.9060741407139647\n",
      "epoch : 33 , phase : valid , loss : 0.9011767133585191\n",
      "epoch : 34 , phase : train , loss : 0.9064123453449804\n",
      "epoch : 34 , phase : valid , loss : 0.9018116289359427\n",
      "epoch : 35 , phase : train , loss : 0.905158747628957\n",
      "epoch : 35 , phase : valid , loss : 0.9041026733177763\n",
      "epoch : 36 , phase : train , loss : 0.9059381737822229\n",
      "epoch : 36 , phase : valid , loss : 0.9030045111006483\n",
      "epoch : 37 , phase : train , loss : 0.9036084450956506\n",
      "epoch : 37 , phase : valid , loss : 0.8943492013767887\n",
      "epoch : 38 , phase : train , loss : 0.9057022887987554\n",
      "epoch : 38 , phase : valid , loss : 0.907226440198378\n",
      "epoch : 39 , phase : train , loss : 0.9005691113252623\n",
      "epoch : 39 , phase : valid , loss : 0.9301418930657576\n",
      "epoch : 40 , phase : train , loss : 0.9053453844527856\n",
      "epoch : 40 , phase : valid , loss : 0.90497644130441\n",
      "epoch : 41 , phase : train , loss : 0.902967872317169\n",
      "epoch : 41 , phase : valid , loss : 0.9021301874392533\n",
      "epoch : 42 , phase : train , loss : 0.9058470789138087\n",
      "epoch : 42 , phase : valid , loss : 0.9077376024866324\n",
      "epoch : 43 , phase : train , loss : 0.9078703033818791\n",
      "epoch : 43 , phase : valid , loss : 0.9034607971828172\n",
      "epoch : 44 , phase : train , loss : 0.9044288125386066\n",
      "epoch : 44 , phase : valid , loss : 0.9003484548689573\n",
      "epoch : 45 , phase : train , loss : 0.9026323768443396\n",
      "epoch : 45 , phase : valid , loss : 0.8984520007184104\n",
      "epoch : 46 , phase : train , loss : 0.9015071533180676\n",
      "epoch : 46 , phase : valid , loss : 0.8979606539516654\n",
      "epoch : 47 , phase : train , loss : 0.9004279371305476\n",
      "epoch : 47 , phase : valid , loss : 0.8963572158765287\n",
      "epoch : 48 , phase : train , loss : 0.8994113754064873\n",
      "epoch : 48 , phase : valid , loss : 0.8956739752059942\n",
      "epoch : 49 , phase : train , loss : 0.8981955669935617\n",
      "epoch : 49 , phase : valid , loss : 0.8947879291999951\n",
      "epoch : 50 , phase : train , loss : 0.8982046825817651\n",
      "epoch : 50 , phase : valid , loss : 0.8933990932493929\n",
      "epoch : 51 , phase : train , loss : 0.8973911523096284\n",
      "epoch : 51 , phase : valid , loss : 0.8931076032855277\n",
      "epoch : 52 , phase : train , loss : 0.8966220196144035\n",
      "epoch : 52 , phase : valid , loss : 0.8927624149333726\n",
      "epoch : 53 , phase : train , loss : 0.8984376951284614\n",
      "epoch : 53 , phase : valid , loss : 0.9030449317867488\n",
      "epoch : 54 , phase : train , loss : 0.8979492722808169\n",
      "epoch : 54 , phase : valid , loss : 0.8923502345383524\n",
      "epoch : 55 , phase : train , loss : 0.8974322085274882\n",
      "epoch : 55 , phase : valid , loss : 0.8910480891679644\n",
      "epoch : 56 , phase : train , loss : 0.9000430960297819\n",
      "epoch : 56 , phase : valid , loss : 0.9013350753480087\n",
      "epoch : 57 , phase : train , loss : 0.8974826990241849\n",
      "epoch : 57 , phase : valid , loss : 0.8912514741067685\n",
      "epoch : 58 , phase : train , loss : 0.8982489234035608\n",
      "epoch : 58 , phase : valid , loss : 0.9001842622825711\n",
      "epoch : 59 , phase : train , loss : 0.8969930795037635\n",
      "epoch : 59 , phase : valid , loss : 0.9116536073703594\n",
      "epoch : 60 , phase : train , loss : 0.9059517266722232\n",
      "epoch : 60 , phase : valid , loss : 0.9019683398535341\n",
      "epoch : 61 , phase : train , loss : 0.902296743803067\n",
      "epoch : 61 , phase : valid , loss : 0.8987817976772986\n",
      "epoch : 62 , phase : train , loss : 0.8972221058273382\n",
      "epoch : 62 , phase : valid , loss : 0.8916509883077097\n",
      "epoch : 63 , phase : train , loss : 0.8972477770198206\n",
      "epoch : 63 , phase : valid , loss : 0.9068110161516414\n",
      "epoch : 64 , phase : train , loss : 0.9055947897089097\n",
      "epoch : 64 , phase : valid , loss : 0.9020329416973066\n",
      "epoch : 65 , phase : train , loss : 0.9034261488727888\n",
      "epoch : 65 , phase : valid , loss : 0.9006720809133919\n",
      "epoch : 66 , phase : train , loss : 0.8994651823195615\n",
      "epoch : 66 , phase : valid , loss : 0.8910281965432585\n",
      "epoch : 67 , phase : train , loss : 0.8980072077821243\n",
      "epoch : 67 , phase : valid , loss : 0.9017216681167031\n",
      "epoch : 68 , phase : train , loss : 0.9041430176471587\n",
      "epoch : 68 , phase : valid , loss : 0.8973190490072597\n",
      "epoch : 69 , phase : train , loss : 0.9005561892930606\n",
      "epoch : 69 , phase : valid , loss : 0.8906306125809615\n",
      "epoch : 70 , phase : train , loss : 0.890306831819426\n",
      "epoch : 70 , phase : valid , loss : 0.8906349383361603\n",
      "epoch : 71 , phase : train , loss : 0.8900154332683471\n",
      "epoch : 71 , phase : valid , loss : 0.889865086847339\n",
      "epoch : 72 , phase : train , loss : 0.8899853368616714\n",
      "epoch : 72 , phase : valid , loss : 0.8899887949380826\n",
      "epoch : 73 , phase : train , loss : 0.8897185442590062\n",
      "epoch : 73 , phase : valid , loss : 0.8897216935129008\n",
      "epoch : 74 , phase : train , loss : 0.8906686807628194\n",
      "epoch : 74 , phase : valid , loss : 0.8895405860804334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 75 , phase : train , loss : 0.8895677473723284\n",
      "epoch : 75 , phase : valid , loss : 0.8894611724467335\n",
      "epoch : 76 , phase : train , loss : 0.9034983581073902\n",
      "epoch : 76 , phase : valid , loss : 0.8912086844914227\n",
      "epoch : 77 , phase : train , loss : 0.8896750996841278\n",
      "epoch : 77 , phase : valid , loss : 0.8895827083543196\n",
      "epoch : 78 , phase : train , loss : 0.9041732531572115\n",
      "epoch : 78 , phase : valid , loss : 0.908502341235904\n",
      "epoch : 79 , phase : train , loss : 0.9067968403181704\n",
      "epoch : 79 , phase : valid , loss : 0.9040226614696205\n",
      "epoch : 80 , phase : train , loss : 0.905291027265938\n",
      "epoch : 80 , phase : valid , loss : 0.9023425987695138\n",
      "epoch : 81 , phase : train , loss : 0.9040644940785691\n",
      "epoch : 81 , phase : valid , loss : 0.9004829361373685\n",
      "epoch : 82 , phase : train , loss : 0.9029609854528674\n",
      "epoch : 82 , phase : valid , loss : 0.899228408637668\n",
      "epoch : 83 , phase : train , loss : 0.9011974786937679\n",
      "epoch : 83 , phase : valid , loss : 0.8961663402666796\n",
      "epoch : 84 , phase : train , loss : 0.9017484011684236\n",
      "epoch : 84 , phase : valid , loss : 0.8920816575175128\n",
      "epoch : 85 , phase : train , loss : 0.8903557603290977\n",
      "epoch : 85 , phase : valid , loss : 0.8902848260143505\n",
      "epoch : 86 , phase : train , loss : 0.8972918551386317\n",
      "epoch : 86 , phase : valid , loss : 0.9118165450357537\n",
      "epoch : 87 , phase : train , loss : 0.9070196536133889\n",
      "epoch : 87 , phase : valid , loss : 0.904203205251134\n",
      "epoch : 88 , phase : train , loss : 0.9049554266501423\n",
      "epoch : 88 , phase : valid , loss : 0.9017836697216407\n",
      "epoch : 89 , phase : train , loss : 0.9033639990188211\n",
      "epoch : 89 , phase : valid , loss : 0.9003663055883205\n",
      "epoch : 90 , phase : train , loss : 0.9018523319208791\n",
      "epoch : 90 , phase : valid , loss : 0.8988939509234857\n",
      "epoch : 91 , phase : train , loss : 0.9008009404379861\n",
      "epoch : 91 , phase : valid , loss : 0.8974080234373298\n",
      "epoch : 92 , phase : train , loss : 0.8995934429242105\n",
      "epoch : 92 , phase : valid , loss : 0.8951029994483453\n",
      "epoch : 93 , phase : train , loss : 0.8932224478136623\n",
      "epoch : 93 , phase : valid , loss : 0.8914511767032554\n",
      "epoch : 94 , phase : train , loss : 0.8911794008265508\n",
      "epoch : 94 , phase : valid , loss : 0.8912060417128931\n",
      "epoch : 95 , phase : train , loss : 0.8906957092205292\n",
      "epoch : 95 , phase : valid , loss : 0.8911568897544677\n",
      "epoch : 96 , phase : train , loss : 0.9033971248092507\n",
      "epoch : 96 , phase : valid , loss : 0.9107497558434227\n",
      "epoch : 97 , phase : train , loss : 0.9105988800158936\n",
      "epoch : 97 , phase : valid , loss : 0.9055902252885212\n",
      "epoch : 98 , phase : train , loss : 0.9065302223142269\n",
      "epoch : 98 , phase : valid , loss : 0.901765175589396\n",
      "epoch : 99 , phase : train , loss : 0.9034289631739415\n",
      "epoch : 99 , phase : valid , loss : 0.8995688910361036\n",
      "epoch : 100 , phase : train , loss : 0.9015979853290658\n",
      "epoch : 100 , phase : valid , loss : 0.8982640151490658\n",
      "epoch : 101 , phase : train , loss : 0.9006524889301801\n",
      "epoch : 101 , phase : valid , loss : 0.8973617242971762\n",
      "epoch : 102 , phase : train , loss : 0.8963237092563484\n",
      "epoch : 102 , phase : valid , loss : 0.8908542570493378\n",
      "epoch : 103 , phase : train , loss : 0.8903610401176933\n",
      "epoch : 103 , phase : valid , loss : 0.8903118094744068\n",
      "epoch : 104 , phase : train , loss : 0.8906203149982583\n",
      "epoch : 104 , phase : valid , loss : 0.8902815770451724\n",
      "epoch : 105 , phase : train , loss : 0.8894673611657888\n",
      "epoch : 105 , phase : valid , loss : 0.889721531330315\n",
      "epoch : 106 , phase : train , loss : 0.8893423287188229\n",
      "epoch : 106 , phase : valid , loss : 0.8895217782179408\n",
      "epoch : 107 , phase : train , loss : 0.889071608987988\n",
      "epoch : 107 , phase : valid , loss : 0.889315973834004\n",
      "epoch : 108 , phase : train , loss : 0.8890154845167174\n",
      "epoch : 108 , phase : valid , loss : 0.8893718417467207\n",
      "epoch : 109 , phase : train , loss : 0.8887522038426245\n",
      "epoch : 109 , phase : valid , loss : 0.8891256538989162\n",
      "epoch : 110 , phase : train , loss : 0.8887413012077252\n",
      "epoch : 110 , phase : valid , loss : 0.889363171625207\n",
      "epoch : 111 , phase : train , loss : 0.8885869363673907\n",
      "epoch : 111 , phase : valid , loss : 0.8892300383333697\n",
      "epoch : 112 , phase : train , loss : 0.8887131973370102\n",
      "epoch : 112 , phase : valid , loss : 0.889002679617905\n",
      "epoch : 113 , phase : train , loss : 0.8886549114870591\n",
      "epoch : 113 , phase : valid , loss : 0.8888840497032091\n",
      "epoch : 114 , phase : train , loss : 0.88845510224495\n",
      "epoch : 114 , phase : valid , loss : 0.8887301384292711\n",
      "epoch : 115 , phase : train , loss : 0.8883538773889464\n",
      "epoch : 115 , phase : valid , loss : 0.8887096901298039\n",
      "epoch : 116 , phase : train , loss : 0.8883747459653835\n",
      "epoch : 116 , phase : valid , loss : 0.88847687038104\n",
      "epoch : 117 , phase : train , loss : 0.8882722776211217\n",
      "epoch : 117 , phase : valid , loss : 0.88873495870842\n",
      "epoch : 118 , phase : train , loss : 0.8882396564401844\n",
      "epoch : 118 , phase : valid , loss : 0.8886433016188566\n",
      "epoch : 119 , phase : train , loss : 0.8881099744868213\n",
      "epoch : 119 , phase : valid , loss : 0.8885831371969812\n",
      "epoch : 120 , phase : train , loss : 0.8881391048445262\n",
      "epoch : 120 , phase : valid , loss : 0.8883918282139931\n",
      "epoch : 121 , phase : train , loss : 0.8880455517796048\n",
      "epoch : 121 , phase : valid , loss : 0.8884457153721781\n",
      "epoch : 122 , phase : train , loss : 0.8879669533829917\n",
      "epoch : 122 , phase : valid , loss : 0.8884440111256616\n",
      "epoch : 123 , phase : train , loss : 0.8879702941664435\n",
      "epoch : 123 , phase : valid , loss : 0.8883370556984133\n",
      "epoch : 124 , phase : train , loss : 0.8880046778351357\n",
      "epoch : 124 , phase : valid , loss : 0.8883037763635504\n",
      "epoch : 125 , phase : train , loss : 0.8878129339027659\n",
      "epoch : 125 , phase : valid , loss : 0.888116599048404\n",
      "epoch : 126 , phase : train , loss : 0.9288051185447191\n",
      "epoch : 126 , phase : valid , loss : 0.9144461894345352\n",
      "epoch : 127 , phase : train , loss : 0.9148476572124035\n",
      "epoch : 127 , phase : valid , loss : 0.9087975933040139\n",
      "epoch : 128 , phase : train , loss : 0.9103549663692317\n",
      "epoch : 128 , phase : valid , loss : 0.906509529359536\n",
      "epoch : 129 , phase : train , loss : 0.9081525387618065\n",
      "epoch : 129 , phase : valid , loss : 0.9043077492094423\n",
      "epoch : 130 , phase : train , loss : 0.9055442782987397\n",
      "epoch : 130 , phase : valid , loss : 0.9020805063933758\n",
      "epoch : 131 , phase : train , loss : 0.9038931296543491\n",
      "epoch : 131 , phase : valid , loss : 0.9007622969707993\n",
      "epoch : 132 , phase : train , loss : 0.9025737824726915\n",
      "epoch : 132 , phase : valid , loss : 0.8995254473729527\n",
      "epoch : 133 , phase : train , loss : 0.9011781705694222\n",
      "epoch : 133 , phase : valid , loss : 0.8981971055268593\n",
      "epoch : 134 , phase : train , loss : 0.8999759580246438\n",
      "epoch : 134 , phase : valid , loss : 0.8969478848540651\n",
      "epoch : 135 , phase : train , loss : 0.8983490394617486\n",
      "epoch : 135 , phase : valid , loss : 0.8955813077986831\n",
      "epoch : 136 , phase : train , loss : 0.8963769012365623\n",
      "epoch : 136 , phase : valid , loss : 0.8937623689479627\n",
      "epoch : 137 , phase : train , loss : 0.8949873603802712\n",
      "epoch : 137 , phase : valid , loss : 0.8932648167032622\n",
      "epoch : 138 , phase : train , loss : 0.8935290151563172\n",
      "epoch : 138 , phase : valid , loss : 0.8921649103586539\n",
      "epoch : 139 , phase : train , loss : 0.8926699226762355\n",
      "epoch : 139 , phase : valid , loss : 0.8914498845600306\n",
      "epoch : 140 , phase : train , loss : 0.891713103646185\n",
      "epoch : 140 , phase : valid , loss : 0.8912796194322347\n",
      "epoch : 141 , phase : train , loss : 0.8907206670525204\n",
      "epoch : 141 , phase : valid , loss : 0.8907153357002987\n",
      "epoch : 142 , phase : train , loss : 0.8902791774924526\n",
      "epoch : 142 , phase : valid , loss : 0.890677260014865\n",
      "epoch : 143 , phase : train , loss : 0.8900721235545958\n",
      "epoch : 143 , phase : valid , loss : 0.8901656271312387\n",
      "epoch : 144 , phase : train , loss : 0.8898755267370981\n",
      "epoch : 144 , phase : valid , loss : 0.8898998125318197\n",
      "epoch : 145 , phase : train , loss : 0.8893616945950535\n",
      "epoch : 145 , phase : valid , loss : 0.889697788863244\n",
      "epoch : 146 , phase : train , loss : 0.8894564201575441\n",
      "epoch : 146 , phase : valid , loss : 0.8896316928126974\n",
      "epoch : 147 , phase : train , loss : 0.889255644290864\n",
      "epoch : 147 , phase : valid , loss : 0.889518141074049\n",
      "epoch : 148 , phase : train , loss : 0.889003693347005\n",
      "epoch : 148 , phase : valid , loss : 0.889516141708401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 149 , phase : train , loss : 0.8888545597529842\n",
      "epoch : 149 , phase : valid , loss : 0.889461188399119\n",
      "epoch : 150 , phase : train , loss : 0.8889325871542175\n",
      "epoch : 150 , phase : valid , loss : 0.8892730725519596\n",
      "epoch : 151 , phase : train , loss : 0.8885610573832429\n",
      "epoch : 151 , phase : valid , loss : 0.8891287912013959\n",
      "epoch : 152 , phase : train , loss : 0.8885151774439978\n",
      "epoch : 152 , phase : valid , loss : 0.8888804896625139\n",
      "epoch : 153 , phase : train , loss : 0.8882935500770193\n",
      "epoch : 153 , phase : valid , loss : 0.888737367518629\n",
      "epoch : 154 , phase : train , loss : 0.888270593798725\n",
      "epoch : 154 , phase : valid , loss : 0.888714409377178\n",
      "epoch : 155 , phase : train , loss : 0.8888204681054506\n",
      "epoch : 155 , phase : valid , loss : 0.8886405285625123\n",
      "epoch : 156 , phase : train , loss : 0.8880953665216886\n",
      "epoch : 156 , phase : valid , loss : 0.8884558477956951\n",
      "epoch : 157 , phase : train , loss : 0.8999454709773118\n",
      "epoch : 157 , phase : valid , loss : 0.9041944660026163\n",
      "epoch : 158 , phase : train , loss : 0.9039737702804052\n",
      "epoch : 158 , phase : valid , loss : 0.9010065971196543\n",
      "epoch : 159 , phase : train , loss : 0.9017091651902036\n",
      "epoch : 159 , phase : valid , loss : 0.8990719502995135\n",
      "epoch : 160 , phase : train , loss : 0.8928567365930531\n",
      "epoch : 160 , phase : valid , loss : 0.8896521756756665\n",
      "epoch : 161 , phase : train , loss : 0.888900866595697\n",
      "epoch : 161 , phase : valid , loss : 0.8893554240833206\n",
      "epoch : 162 , phase : train , loss : 0.8887705407375979\n",
      "epoch : 162 , phase : valid , loss : 0.889250449410604\n",
      "epoch : 163 , phase : train , loss : 0.8885895896923595\n",
      "epoch : 163 , phase : valid , loss : 0.8892417261144719\n",
      "epoch : 164 , phase : train , loss : 0.8884005211496321\n",
      "epoch : 164 , phase : valid , loss : 0.8888737524383753\n",
      "epoch : 165 , phase : train , loss : 0.8882662641341618\n",
      "epoch : 165 , phase : valid , loss : 0.8889919144164302\n",
      "epoch : 166 , phase : train , loss : 0.9048509047563007\n",
      "epoch : 166 , phase : valid , loss : 0.9037929524360271\n",
      "epoch : 167 , phase : train , loss : 0.9027817330037639\n",
      "epoch : 167 , phase : valid , loss : 0.9008495565194294\n",
      "epoch : 168 , phase : train , loss : 0.900656044796233\n",
      "epoch : 168 , phase : valid , loss : 0.8986958435655479\n",
      "epoch : 169 , phase : train , loss : 0.8987074846894035\n",
      "epoch : 169 , phase : valid , loss : 0.8960600016650037\n",
      "epoch : 170 , phase : train , loss : 0.8969174611811553\n",
      "epoch : 170 , phase : valid , loss : 0.8940548639121136\n",
      "epoch : 171 , phase : train , loss : 0.8943856887725706\n",
      "epoch : 171 , phase : valid , loss : 0.8923340322321565\n",
      "epoch : 172 , phase : train , loss : 0.8899741314610767\n",
      "epoch : 172 , phase : valid , loss : 0.8891955891569041\n",
      "epoch : 173 , phase : train , loss : 0.8885814629852675\n",
      "epoch : 173 , phase : valid , loss : 0.8890140137877957\n",
      "epoch : 174 , phase : train , loss : 0.888167426100243\n",
      "epoch : 174 , phase : valid , loss : 0.8888208782566689\n",
      "epoch : 175 , phase : train , loss : 0.8880242633987688\n",
      "epoch : 175 , phase : valid , loss : 0.8887293408099967\n",
      "epoch : 176 , phase : train , loss : 0.8878183082816581\n",
      "epoch : 176 , phase : valid , loss : 0.888449535968503\n",
      "epoch : 177 , phase : train , loss : 0.8878146275103659\n",
      "epoch : 177 , phase : valid , loss : 0.8884826345096637\n",
      "epoch : 178 , phase : train , loss : 0.8876430004205964\n",
      "epoch : 178 , phase : valid , loss : 0.8885164987653279\n",
      "epoch : 179 , phase : train , loss : 0.8874975328241299\n",
      "epoch : 179 , phase : valid , loss : 0.8881277152023597\n",
      "epoch : 180 , phase : train , loss : 0.8872695368248796\n",
      "epoch : 180 , phase : valid , loss : 0.8881281565516915\n",
      "epoch : 181 , phase : train , loss : 0.8873586155577257\n",
      "epoch : 181 , phase : valid , loss : 0.888003632230557\n",
      "epoch : 182 , phase : train , loss : 0.8871894998115469\n",
      "epoch : 182 , phase : valid , loss : 0.8880677741138812\n",
      "epoch : 183 , phase : train , loss : 0.8872917150835957\n",
      "epoch : 183 , phase : valid , loss : 0.8880889881278519\n",
      "epoch : 184 , phase : train , loss : 0.8871697659349338\n",
      "epoch : 184 , phase : valid , loss : 0.8877846830809765\n",
      "epoch : 185 , phase : train , loss : 0.8869774970551988\n",
      "epoch : 185 , phase : valid , loss : 0.8879482907465615\n",
      "epoch : 186 , phase : train , loss : 0.8871742421856765\n",
      "epoch : 186 , phase : valid , loss : 0.8876537246310277\n",
      "epoch : 187 , phase : train , loss : 0.8871125439859844\n",
      "epoch : 187 , phase : valid , loss : 0.8880093671131406\n",
      "epoch : 188 , phase : train , loss : 0.8868672203107453\n",
      "epoch : 188 , phase : valid , loss : 0.8875560056349782\n",
      "epoch : 189 , phase : train , loss : 0.8869269501496843\n",
      "epoch : 189 , phase : valid , loss : 0.8876276079172497\n",
      "epoch : 190 , phase : train , loss : 0.8868741639675981\n",
      "epoch : 190 , phase : valid , loss : 0.8875910211211285\n",
      "epoch : 191 , phase : train , loss : 0.8868327430110903\n",
      "epoch : 191 , phase : valid , loss : 0.8877886206614616\n",
      "epoch : 192 , phase : train , loss : 0.8867123988276003\n",
      "epoch : 192 , phase : valid , loss : 0.887334262159206\n",
      "epoch : 193 , phase : train , loss : 0.8867652895770528\n",
      "epoch : 193 , phase : valid , loss : 0.887325722315507\n",
      "epoch : 194 , phase : train , loss : 0.8866760799910989\n",
      "epoch : 194 , phase : valid , loss : 0.8872421584028488\n",
      "epoch : 195 , phase : train , loss : 0.886697638136553\n",
      "epoch : 195 , phase : valid , loss : 0.8874638992198901\n",
      "epoch : 196 , phase : train , loss : 0.8867320762953957\n",
      "epoch : 196 , phase : valid , loss : 0.8873368544218481\n",
      "epoch : 197 , phase : train , loss : 0.8866136024287614\n",
      "epoch : 197 , phase : valid , loss : 0.8876147396596212\n",
      "epoch : 198 , phase : train , loss : 0.8865793350313058\n",
      "epoch : 198 , phase : valid , loss : 0.8871641937774977\n",
      "epoch : 199 , phase : train , loss : 0.8865612834421557\n",
      "epoch : 199 , phase : valid , loss : 0.887232773082719\n",
      "epoch : 200 , phase : train , loss : 0.8864198181856159\n",
      "epoch : 200 , phase : valid , loss : 0.887585408540167\n",
      "epoch : 201 , phase : train , loss : 0.8865022082524894\n",
      "epoch : 201 , phase : valid , loss : 0.8873772910603343\n",
      "epoch : 202 , phase : train , loss : 0.8864905728785594\n",
      "epoch : 202 , phase : valid , loss : 0.8870427828302646\n",
      "epoch : 203 , phase : train , loss : 0.8864841075454571\n",
      "epoch : 203 , phase : valid , loss : 0.8877035519071056\n",
      "epoch : 204 , phase : train , loss : 0.8863825630394863\n",
      "epoch : 204 , phase : valid , loss : 0.887139284127555\n",
      "epoch : 205 , phase : train , loss : 0.8864018456455574\n",
      "epoch : 205 , phase : valid , loss : 0.8869005008453488\n",
      "epoch : 206 , phase : train , loss : 0.8863565597256993\n",
      "epoch : 206 , phase : valid , loss : 0.8871771072335518\n",
      "epoch : 207 , phase : train , loss : 0.8863642117545084\n",
      "epoch : 207 , phase : valid , loss : 0.8871277824576168\n",
      "epoch : 208 , phase : train , loss : 0.8863980083110158\n",
      "epoch : 208 , phase : valid , loss : 0.8869549436782951\n",
      "epoch : 209 , phase : train , loss : 0.8863419744008404\n",
      "epoch : 209 , phase : valid , loss : 0.8869600298305355\n",
      "epoch : 210 , phase : train , loss : 0.88625258522763\n",
      "epoch : 210 , phase : valid , loss : 0.8869461512551592\n",
      "epoch : 211 , phase : train , loss : 0.8863293574367347\n",
      "epoch : 211 , phase : valid , loss : 0.8871699366362741\n",
      "epoch : 212 , phase : train , loss : 0.886240099116632\n",
      "epoch : 212 , phase : valid , loss : 0.8874672970779994\n",
      "epoch : 213 , phase : train , loss : 0.8861978838318741\n",
      "epoch : 213 , phase : valid , loss : 0.8871684610406162\n",
      "epoch : 214 , phase : train , loss : 0.8861860897841608\n",
      "epoch : 214 , phase : valid , loss : 0.8868501737278589\n",
      "epoch : 215 , phase : train , loss : 0.8861431505862416\n",
      "epoch : 215 , phase : valid , loss : 0.8869866410682636\n",
      "epoch : 216 , phase : train , loss : 0.8861309522753343\n",
      "epoch : 216 , phase : valid , loss : 0.8873421000979433\n",
      "epoch : 217 , phase : train , loss : 0.8861884230754288\n",
      "epoch : 217 , phase : valid , loss : 0.8869194629142345\n",
      "epoch : 218 , phase : train , loss : 0.8861182188481252\n",
      "epoch : 218 , phase : valid , loss : 0.8866954222949519\n",
      "epoch : 219 , phase : train , loss : 0.8861504334634679\n",
      "epoch : 219 , phase : valid , loss : 0.8869347479582648\n",
      "epoch : 220 , phase : train , loss : 0.8861345231069919\n",
      "epoch : 220 , phase : valid , loss : 0.8872435063794227\n",
      "epoch : 221 , phase : train , loss : 0.8861296901760036\n",
      "epoch : 221 , phase : valid , loss : 0.8869614469341132\n",
      "epoch : 222 , phase : train , loss : 0.8861229406882786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 222 , phase : valid , loss : 0.8869225470420959\n",
      "epoch : 223 , phase : train , loss : 0.8859560363979961\n",
      "epoch : 223 , phase : valid , loss : 0.887042173980885\n",
      "epoch : 224 , phase : train , loss : 0.8860452596064876\n",
      "epoch : 224 , phase : valid , loss : 0.8871861442599318\n",
      "epoch : 225 , phase : train , loss : 0.8859270800634127\n",
      "epoch : 225 , phase : valid , loss : 0.8868644192081014\n",
      "epoch : 226 , phase : train , loss : 0.8859974059342212\n",
      "epoch : 226 , phase : valid , loss : 0.8871068609040468\n",
      "epoch : 227 , phase : train , loss : 0.885943177873681\n",
      "epoch : 227 , phase : valid , loss : 0.8866277496169725\n",
      "epoch : 228 , phase : train , loss : 0.8859573338008045\n",
      "epoch : 228 , phase : valid , loss : 0.8868142994716229\n",
      "epoch : 229 , phase : train , loss : 0.8860206321690005\n",
      "epoch : 229 , phase : valid , loss : 0.886827779237362\n",
      "epoch : 230 , phase : train , loss : 0.8858346016440295\n",
      "epoch : 230 , phase : valid , loss : 0.8867092822592118\n",
      "epoch : 231 , phase : train , loss : 0.8859499406002102\n",
      "epoch : 231 , phase : valid , loss : 0.8869746475331061\n",
      "epoch : 232 , phase : train , loss : 0.8859124640398776\n",
      "epoch : 232 , phase : valid , loss : 0.8867720681897693\n",
      "epoch : 233 , phase : train , loss : 0.8858924087864966\n",
      "epoch : 233 , phase : valid , loss : 0.8867130044824927\n",
      "epoch : 234 , phase : train , loss : 0.8859029367056779\n",
      "epoch : 234 , phase : valid , loss : 0.8866358481113397\n",
      "epoch : 235 , phase : train , loss : 0.8858310102826321\n",
      "epoch : 235 , phase : valid , loss : 0.8866443985899622\n",
      "epoch : 236 , phase : train , loss : 0.8857755698162436\n",
      "epoch : 236 , phase : valid , loss : 0.8868129089553545\n",
      "epoch : 237 , phase : train , loss : 0.8859107761882794\n",
      "epoch : 237 , phase : valid , loss : 0.8866955765013449\n",
      "epoch : 238 , phase : train , loss : 0.8858568610623712\n",
      "epoch : 238 , phase : valid , loss : 0.8868533695224188\n",
      "epoch : 239 , phase : train , loss : 0.8858182626572852\n",
      "epoch : 239 , phase : valid , loss : 0.8867196007938928\n",
      "epoch : 240 , phase : train , loss : 0.8857128825435735\n",
      "epoch : 240 , phase : valid , loss : 0.886745738777518\n",
      "epoch : 241 , phase : train , loss : 0.885953398806099\n",
      "epoch : 241 , phase : valid , loss : 0.8865618529712446\n",
      "epoch : 242 , phase : train , loss : 0.8858333619931059\n",
      "epoch : 242 , phase : valid , loss : 0.8871274394813288\n",
      "epoch : 243 , phase : train , loss : 0.8857661767887529\n",
      "epoch : 243 , phase : valid , loss : 0.8866543289499298\n",
      "epoch : 244 , phase : train , loss : 0.8858026301238301\n",
      "epoch : 244 , phase : valid , loss : 0.8872321615746085\n",
      "epoch : 245 , phase : train , loss : 0.885766966895935\n",
      "epoch : 245 , phase : valid , loss : 0.8865622943205764\n",
      "epoch : 246 , phase : train , loss : 0.8858644321234216\n",
      "epoch : 246 , phase : valid , loss : 0.8865776777376505\n",
      "epoch : 247 , phase : train , loss : 0.885688270071691\n",
      "epoch : 247 , phase : valid , loss : 0.8867169713090178\n",
      "epoch : 248 , phase : train , loss : 0.8856771569589921\n",
      "epoch : 248 , phase : valid , loss : 0.886684032291712\n",
      "epoch : 249 , phase : train , loss : 0.8857176272158673\n",
      "epoch : 249 , phase : valid , loss : 0.8865991602834437\n",
      "epoch : 250 , phase : train , loss : 0.8858348946245218\n",
      "epoch : 250 , phase : valid , loss : 0.886385533913155\n",
      "epoch : 251 , phase : train , loss : 0.8857361912810454\n",
      "epoch : 251 , phase : valid , loss : 0.8867157270229497\n",
      "epoch : 252 , phase : train , loss : 0.8856821516336313\n",
      "epoch : 252 , phase : valid , loss : 0.8865317880420578\n",
      "epoch : 253 , phase : train , loss : 0.8857266004389591\n",
      "epoch : 253 , phase : valid , loss : 0.8866801425683835\n",
      "epoch : 254 , phase : train , loss : 0.8856400537713103\n",
      "epoch : 254 , phase : valid , loss : 0.8870696227188514\n",
      "epoch : 255 , phase : train , loss : 0.8857890190982114\n",
      "epoch : 255 , phase : valid , loss : 0.8863831703013716\n",
      "epoch : 256 , phase : train , loss : 0.8855907043060395\n",
      "epoch : 256 , phase : valid , loss : 0.8867415672287124\n",
      "epoch : 257 , phase : train , loss : 0.8856282647121319\n",
      "epoch : 257 , phase : valid , loss : 0.8864532863530618\n",
      "epoch : 258 , phase : train , loss : 0.8856148186918985\n",
      "epoch : 258 , phase : valid , loss : 0.8864065910620018\n",
      "epoch : 259 , phase : train , loss : 0.8855603396696793\n",
      "epoch : 259 , phase : valid , loss : 0.8862579334403519\n",
      "epoch : 260 , phase : train , loss : 0.8856617892016203\n",
      "epoch : 260 , phase : valid , loss : 0.8871581584583206\n",
      "epoch : 261 , phase : train , loss : 0.8856187462038017\n",
      "epoch : 261 , phase : valid , loss : 0.8864899475936486\n",
      "epoch : 262 , phase : train , loss : 0.8855922085411797\n",
      "epoch : 262 , phase : valid , loss : 0.886313538138708\n",
      "epoch : 263 , phase : train , loss : 0.8855471004817776\n",
      "epoch : 263 , phase : valid , loss : 0.8865837529377913\n",
      "epoch : 264 , phase : train , loss : 0.8855945466291159\n",
      "epoch : 264 , phase : valid , loss : 0.8865424841165288\n",
      "epoch : 265 , phase : train , loss : 0.8855187661791234\n",
      "epoch : 265 , phase : valid , loss : 0.8864427152389438\n",
      "epoch : 266 , phase : train , loss : 0.8855812174557193\n",
      "epoch : 266 , phase : valid , loss : 0.8863527171974713\n",
      "epoch : 267 , phase : train , loss : 0.8855641307643396\n",
      "epoch : 267 , phase : valid , loss : 0.8862970433721113\n",
      "epoch : 268 , phase : train , loss : 0.8856128963791599\n",
      "epoch : 268 , phase : valid , loss : 0.8865590293990128\n",
      "epoch : 269 , phase : train , loss : 0.8854343540288132\n",
      "epoch : 269 , phase : valid , loss : 0.8864516219875089\n",
      "epoch : 270 , phase : train , loss : 0.8855448807756121\n",
      "epoch : 270 , phase : valid , loss : 0.8863191613545932\n",
      "epoch : 271 , phase : train , loss : 0.8854703083185334\n",
      "epoch : 271 , phase : valid , loss : 0.8864022068147229\n",
      "epoch : 272 , phase : train , loss : 0.8855455611350264\n",
      "epoch : 272 , phase : valid , loss : 0.8865966079017653\n",
      "epoch : 273 , phase : train , loss : 0.8854724021601259\n",
      "epoch : 273 , phase : valid , loss : 0.886802133118956\n",
      "epoch : 274 , phase : train , loss : 0.885441446766113\n",
      "epoch : 274 , phase : valid , loss : 0.886348566918513\n",
      "epoch : 275 , phase : train , loss : 0.8854351303215909\n",
      "epoch : 275 , phase : valid , loss : 0.8863006486112321\n",
      "epoch : 276 , phase : train , loss : 0.8854641229189858\n",
      "epoch : 276 , phase : valid , loss : 0.8863505290619282\n",
      "epoch : 277 , phase : train , loss : 0.8854157352816179\n",
      "epoch : 277 , phase : valid , loss : 0.8864832236631646\n",
      "epoch : 278 , phase : train , loss : 0.8854768686256654\n",
      "epoch : 278 , phase : valid , loss : 0.8864108450314657\n",
      "epoch : 279 , phase : train , loss : 0.8854364847088174\n",
      "epoch : 279 , phase : valid , loss : 0.8865281508981661\n",
      "epoch : 280 , phase : train , loss : 0.885395301667051\n",
      "epoch : 280 , phase : valid , loss : 0.8865219773249815\n",
      "epoch : 281 , phase : train , loss : 0.8854994975793234\n",
      "epoch : 281 , phase : valid , loss : 0.8862551683602002\n",
      "epoch : 282 , phase : train , loss : 0.8854807512407545\n",
      "epoch : 282 , phase : valid , loss : 0.8864591754420384\n",
      "epoch : 283 , phase : train , loss : 0.8854249291514459\n",
      "epoch : 283 , phase : valid , loss : 0.8863399845351194\n",
      "epoch : 284 , phase : train , loss : 0.885447981171237\n",
      "epoch : 284 , phase : valid , loss : 0.8862022223927591\n",
      "epoch : 285 , phase : train , loss : 0.8853794469519259\n",
      "epoch : 285 , phase : valid , loss : 0.8866737882014966\n",
      "epoch : 286 , phase : train , loss : 0.885371214142534\n",
      "epoch : 286 , phase : valid , loss : 0.8862690416181147\n",
      "epoch : 287 , phase : train , loss : 0.8855046474741448\n",
      "epoch : 287 , phase : valid , loss : 0.8862941187681049\n",
      "epoch : 288 , phase : train , loss : 0.8854137475423254\n",
      "epoch : 288 , phase : valid , loss : 0.8864553255996735\n",
      "epoch : 289 , phase : train , loss : 0.8853518448127022\n",
      "epoch : 289 , phase : valid , loss : 0.8861958254861777\n",
      "epoch : 290 , phase : train , loss : 0.8853392495295367\n",
      "epoch : 290 , phase : valid , loss : 0.8863225166730079\n",
      "epoch : 291 , phase : train , loss : 0.8854149254121629\n",
      "epoch : 291 , phase : valid , loss : 0.886306500477976\n",
      "epoch : 292 , phase : train , loss : 0.8853116049877662\n",
      "epoch : 292 , phase : valid , loss : 0.886363362756055\n",
      "epoch : 293 , phase : train , loss : 0.8853282478914062\n",
      "epoch : 293 , phase : valid , loss : 0.8864759201293411\n",
      "epoch : 294 , phase : train , loss : 0.885344542173203\n",
      "epoch : 294 , phase : valid , loss : 0.8865577425732499\n",
      "epoch : 295 , phase : train , loss : 0.8854539844892605\n",
      "epoch : 295 , phase : valid , loss : 0.8860547824698682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 296 , phase : train , loss : 0.885339121362563\n",
      "epoch : 296 , phase : valid , loss : 0.8864591222674202\n",
      "epoch : 297 , phase : train , loss : 0.8853711644490516\n",
      "epoch : 297 , phase : valid , loss : 0.8862964664275028\n",
      "epoch : 298 , phase : train , loss : 0.8852887503988373\n",
      "epoch : 298 , phase : valid , loss : 0.8863598346201307\n",
      "epoch : 299 , phase : train , loss : 0.885404023928464\n",
      "epoch : 299 , phase : valid , loss : 0.8861702325423899\n",
      "epoch : 300 , phase : train , loss : 0.8853325564506294\n",
      "epoch : 300 , phase : valid , loss : 0.8863112463126592\n",
      "epoch : 301 , phase : train , loss : 0.8853538749545414\n",
      "epoch : 301 , phase : valid , loss : 0.8863769701408779\n",
      "epoch : 302 , phase : train , loss : 0.8852428932917327\n",
      "epoch : 302 , phase : valid , loss : 0.8861798731006877\n",
      "epoch : 303 , phase : train , loss : 0.8852890995962804\n",
      "epoch : 303 , phase : valid , loss : 0.886376058196174\n",
      "epoch : 304 , phase : train , loss : 0.885217303067009\n",
      "epoch : 304 , phase : valid , loss : 0.886277820747596\n",
      "epoch : 305 , phase : train , loss : 0.8852851991375857\n",
      "epoch : 305 , phase : valid , loss : 0.8863715702583895\n",
      "epoch : 306 , phase : train , loss : 0.8853196042953514\n",
      "epoch : 306 , phase : valid , loss : 0.8860988429585915\n",
      "epoch : 307 , phase : train , loss : 0.8852782660334029\n",
      "epoch : 307 , phase : valid , loss : 0.8864470303592188\n",
      "epoch : 308 , phase : train , loss : 0.8851963721338856\n",
      "epoch : 308 , phase : valid , loss : 0.8862102863236243\n",
      "epoch : 309 , phase : train , loss : 0.8853182533617261\n",
      "epoch : 309 , phase : valid , loss : 0.8862931802360919\n",
      "epoch : 310 , phase : train , loss : 0.885242456411195\n",
      "epoch : 310 , phase : valid , loss : 0.8865060302569534\n",
      "epoch : 311 , phase : train , loss : 0.885366673424571\n",
      "epoch : 311 , phase : valid , loss : 0.8864082501100927\n",
      "epoch : 312 , phase : train , loss : 0.8853473040947393\n",
      "epoch : 312 , phase : valid , loss : 0.8868472172190814\n",
      "epoch : 313 , phase : train , loss : 0.8851739505881596\n",
      "epoch : 313 , phase : valid , loss : 0.8862477425247547\n",
      "epoch : 314 , phase : train , loss : 0.8851479395997035\n",
      "epoch : 314 , phase : valid , loss : 0.8860272327001272\n",
      "epoch : 315 , phase : train , loss : 0.8851106412835603\n",
      "epoch : 315 , phase : valid , loss : 0.8863760635136358\n",
      "epoch : 316 , phase : train , loss : 0.8852050358759467\n",
      "epoch : 316 , phase : valid , loss : 0.8862521294307645\n",
      "epoch : 317 , phase : train , loss : 0.8851623524363746\n",
      "epoch : 317 , phase : valid , loss : 0.8862844941621926\n",
      "epoch : 318 , phase : train , loss : 0.8852579832260836\n",
      "epoch : 318 , phase : valid , loss : 0.8860748239835055\n",
      "epoch : 319 , phase : train , loss : 0.88514974947854\n",
      "epoch : 319 , phase : valid , loss : 0.8862925687279815\n",
      "epoch : 320 , phase : train , loss : 0.8851433570547941\n",
      "epoch : 320 , phase : valid , loss : 0.8858872877396856\n",
      "epoch : 321 , phase : train , loss : 0.8851971382577268\n",
      "epoch : 321 , phase : valid , loss : 0.8860994970063966\n",
      "epoch : 322 , phase : train , loss : 0.8852099338497554\n",
      "epoch : 322 , phase : valid , loss : 0.8862523394705067\n",
      "epoch : 323 , phase : train , loss : 0.88517083889358\n",
      "epoch : 323 , phase : valid , loss : 0.8862669651492701\n",
      "epoch : 324 , phase : train , loss : 0.885093176806595\n",
      "epoch : 324 , phase : valid , loss : 0.8867528003668282\n",
      "epoch : 325 , phase : train , loss : 0.8850446059365027\n",
      "epoch : 325 , phase : valid , loss : 0.8862347945051987\n",
      "epoch : 326 , phase : train , loss : 0.8853161330425252\n",
      "epoch : 326 , phase : valid , loss : 0.8859764349872653\n",
      "epoch : 327 , phase : train , loss : 0.8850478066572437\n",
      "epoch : 327 , phase : valid , loss : 0.8859934003492339\n",
      "epoch : 328 , phase : train , loss : 0.8851434606628267\n",
      "epoch : 328 , phase : valid , loss : 0.8860068641625874\n",
      "epoch : 329 , phase : train , loss : 0.8851540929575076\n",
      "epoch : 329 , phase : valid , loss : 0.8859922278489004\n",
      "epoch : 330 , phase : train , loss : 0.8851678664942441\n",
      "epoch : 330 , phase : valid , loss : 0.8862951982128564\n",
      "epoch : 331 , phase : train , loss : 0.8851434800413661\n",
      "epoch : 331 , phase : valid , loss : 0.8861105759381194\n",
      "epoch : 332 , phase : train , loss : 0.8850510637868025\n",
      "epoch : 332 , phase : valid , loss : 0.8863347920336424\n",
      "epoch : 333 , phase : train , loss : 0.8850168441641619\n",
      "epoch : 333 , phase : valid , loss : 0.8864432336914722\n",
      "epoch : 334 , phase : train , loss : 0.8851236335389842\n",
      "epoch : 334 , phase : valid , loss : 0.885878580395939\n",
      "epoch : 335 , phase : train , loss : 0.8851193263228281\n",
      "epoch : 335 , phase : valid , loss : 0.886029771788151\n",
      "epoch : 336 , phase : train , loss : 0.8850594310947703\n",
      "epoch : 336 , phase : valid , loss : 0.8863407555670848\n",
      "epoch : 337 , phase : train , loss : 0.8851080105988653\n",
      "epoch : 337 , phase : valid , loss : 0.8858341556610805\n",
      "epoch : 338 , phase : train , loss : 0.8850764891980076\n",
      "epoch : 338 , phase : valid , loss : 0.8860643033852749\n",
      "epoch : 339 , phase : train , loss : 0.8850537597061847\n",
      "epoch : 339 , phase : valid , loss : 0.8861748321468729\n",
      "epoch : 340 , phase : train , loss : 0.8850087207188043\n",
      "epoch : 340 , phase : valid , loss : 0.886274002810002\n",
      "epoch : 341 , phase : train , loss : 0.8850176375330784\n",
      "epoch : 341 , phase : valid , loss : 0.8859005016323331\n",
      "epoch : 342 , phase : train , loss : 0.8849942662470535\n",
      "epoch : 342 , phase : valid , loss : 0.8862342202193211\n",
      "epoch : 343 , phase : train , loss : 0.8851318341147661\n",
      "epoch : 343 , phase : valid , loss : 0.8860538625489717\n",
      "epoch : 344 , phase : train , loss : 0.8850673759122051\n",
      "epoch : 344 , phase : valid , loss : 0.885966339785981\n",
      "epoch : 345 , phase : train , loss : 0.885009539989729\n",
      "epoch : 345 , phase : valid , loss : 0.886170200637619\n",
      "epoch : 346 , phase : train , loss : 0.8851803447387061\n",
      "epoch : 346 , phase : valid , loss : 0.886710460077007\n",
      "epoch : 347 , phase : train , loss : 0.8849826437281941\n",
      "epoch : 347 , phase : valid , loss : 0.8858075577170069\n",
      "epoch : 348 , phase : train , loss : 0.8851255861666656\n",
      "epoch : 348 , phase : valid , loss : 0.8860917893454741\n",
      "epoch : 349 , phase : train , loss : 0.8850499586344546\n",
      "epoch : 349 , phase : valid , loss : 0.8859598737523958\n",
      "epoch : 350 , phase : train , loss : 0.8849628526752963\n",
      "epoch : 350 , phase : valid , loss : 0.8859682274849308\n",
      "epoch : 351 , phase : train , loss : 0.885030536541273\n",
      "epoch : 351 , phase : valid , loss : 0.8859770730826849\n",
      "epoch : 352 , phase : train , loss : 0.8849554452765641\n",
      "epoch : 352 , phase : valid , loss : 0.8860552158430074\n",
      "epoch : 353 , phase : train , loss : 0.8848963570399604\n",
      "epoch : 353 , phase : valid , loss : 0.8859486485904727\n",
      "epoch : 354 , phase : train , loss : 0.8851317199540635\n",
      "epoch : 354 , phase : valid , loss : 0.8858171424419554\n",
      "epoch : 355 , phase : train , loss : 0.8849364754132583\n",
      "epoch : 355 , phase : valid , loss : 0.8860307874233605\n",
      "epoch : 356 , phase : train , loss : 0.8849669459600518\n",
      "epoch : 356 , phase : valid , loss : 0.8857033966159503\n",
      "epoch : 357 , phase : train , loss : 0.8849331636016822\n",
      "epoch : 357 , phase : valid , loss : 0.8867450448487493\n",
      "epoch : 358 , phase : train , loss : 0.8849456761902884\n",
      "epoch : 358 , phase : valid , loss : 0.8860428952839473\n",
      "epoch : 359 , phase : train , loss : 0.8849719717171007\n",
      "epoch : 359 , phase : valid , loss : 0.8857713431432138\n",
      "epoch : 360 , phase : train , loss : 0.8849140978050127\n",
      "epoch : 360 , phase : valid , loss : 0.8859287931879996\n",
      "epoch : 361 , phase : train , loss : 0.8849092840606971\n",
      "epoch : 361 , phase : valid , loss : 0.8862438634363498\n",
      "epoch : 362 , phase : train , loss : 0.8849730874221187\n",
      "epoch : 362 , phase : valid , loss : 0.8856789389502633\n",
      "epoch : 363 , phase : train , loss : 0.8849472888301294\n",
      "epoch : 363 , phase : valid , loss : 0.8860515361594211\n",
      "epoch : 364 , phase : train , loss : 0.8848682401223079\n",
      "epoch : 364 , phase : valid , loss : 0.8859671613338338\n",
      "epoch : 365 , phase : train , loss : 0.8849207218118983\n",
      "epoch : 365 , phase : valid , loss : 0.8859431822397115\n",
      "epoch : 366 , phase : train , loss : 0.8850106516655456\n",
      "epoch : 366 , phase : valid , loss : 0.8861970245738203\n",
      "epoch : 367 , phase : train , loss : 0.8848597728517754\n",
      "epoch : 367 , phase : valid , loss : 0.8857282185277726\n",
      "epoch : 368 , phase : train , loss : 0.8849061017591618\n",
      "epoch : 368 , phase : valid , loss : 0.8859470772805019\n",
      "epoch : 369 , phase : train , loss : 0.8850345381137329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 369 , phase : valid , loss : 0.8858942642496066\n",
      "epoch : 370 , phase : train , loss : 0.8848389265318787\n",
      "epoch : 370 , phase : valid , loss : 0.8857951786658667\n",
      "epoch : 371 , phase : train , loss : 0.8849900263761186\n",
      "epoch : 371 , phase : valid , loss : 0.8862041871949053\n",
      "epoch : 372 , phase : train , loss : 0.8848596999424191\n",
      "epoch : 372 , phase : valid , loss : 0.8862097386250558\n",
      "epoch : 373 , phase : train , loss : 0.8848765592717271\n",
      "epoch : 373 , phase : valid , loss : 0.885837484392186\n",
      "epoch : 374 , phase : train , loss : 0.8848455027639491\n",
      "epoch : 374 , phase : valid , loss : 0.8861591642455908\n",
      "epoch : 375 , phase : train , loss : 0.8849234892975696\n",
      "epoch : 375 , phase : valid , loss : 0.885703125425397\n",
      "epoch : 376 , phase : train , loss : 0.8849210779165437\n",
      "epoch : 376 , phase : valid , loss : 0.8859937513017146\n",
      "epoch : 377 , phase : train , loss : 0.8848914667408208\n",
      "epoch : 377 , phase : valid , loss : 0.8861354802706001\n",
      "epoch : 378 , phase : train , loss : 0.8848136521197878\n",
      "epoch : 378 , phase : valid , loss : 0.8860843129941411\n",
      "epoch : 379 , phase : train , loss : 0.8849278951332235\n",
      "epoch : 379 , phase : valid , loss : 0.8860645958456755\n",
      "epoch : 380 , phase : train , loss : 0.8848729581251267\n",
      "epoch : 380 , phase : valid , loss : 0.8859502783925236\n",
      "epoch : 381 , phase : train , loss : 0.8848942065976834\n",
      "epoch : 381 , phase : valid , loss : 0.8858149170841796\n",
      "epoch : 382 , phase : train , loss : 0.8849224451588409\n",
      "epoch : 382 , phase : valid , loss : 0.8859409329533574\n",
      "epoch : 383 , phase : train , loss : 0.884939556792895\n",
      "epoch : 383 , phase : valid , loss : 0.8864401947620364\n",
      "epoch : 384 , phase : train , loss : 0.8848645892822251\n",
      "epoch : 384 , phase : valid , loss : 0.8857518200821051\n",
      "epoch : 385 , phase : train , loss : 0.8849172755017465\n",
      "epoch : 385 , phase : valid , loss : 0.886071678704833\n",
      "epoch : 386 , phase : train , loss : 0.884814754969735\n",
      "epoch : 386 , phase : valid , loss : 0.8857973375553697\n",
      "epoch : 387 , phase : train , loss : 0.8848623267897795\n",
      "epoch : 387 , phase : valid , loss : 0.8861871394122783\n",
      "epoch : 388 , phase : train , loss : 0.8847099406710014\n",
      "epoch : 388 , phase : valid , loss : 0.8856789628788415\n",
      "epoch : 389 , phase : train , loss : 0.8848519863243905\n",
      "epoch : 389 , phase : valid , loss : 0.8858525514202813\n",
      "epoch : 390 , phase : train , loss : 0.8847760228335404\n",
      "epoch : 390 , phase : valid , loss : 0.8856370798907377\n",
      "epoch : 391 , phase : train , loss : 0.8848824052590345\n",
      "epoch : 391 , phase : valid , loss : 0.885841020504303\n",
      "epoch : 392 , phase : train , loss : 0.8848292027261505\n",
      "epoch : 392 , phase : valid , loss : 0.8860712825539268\n",
      "epoch : 393 , phase : train , loss : 0.8847049966491781\n",
      "epoch : 393 , phase : valid , loss : 0.8858120084325586\n",
      "epoch : 394 , phase : train , loss : 0.8848913190034409\n",
      "epoch : 394 , phase : valid , loss : 0.8856816322446801\n",
      "epoch : 395 , phase : train , loss : 0.8848007124358471\n",
      "epoch : 395 , phase : valid , loss : 0.8858880242081492\n",
      "epoch : 396 , phase : train , loss : 0.8847644676599022\n",
      "epoch : 396 , phase : valid , loss : 0.8857804918362923\n",
      "epoch : 397 , phase : train , loss : 0.8848331730243338\n",
      "epoch : 397 , phase : valid , loss : 0.8855757934844162\n",
      "epoch : 398 , phase : train , loss : 0.884664113686973\n",
      "epoch : 398 , phase : valid , loss : 0.8858834086512807\n",
      "epoch : 399 , phase : train , loss : 0.8846855897134679\n",
      "epoch : 399 , phase : valid , loss : 0.8859299975931041\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(400):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.8846855897134679\n",
      "(compare com a entropia do dataset de treino).\n",
      "comprimento médio de código final no dataset de validação: 0.8859299975931041\n",
      "(compare com a entropia do dataset de validação).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9fbc5",
   "metadata": {},
   "source": [
    "### Salva os pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e919036",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pesos_ricardo9-v3_1024-512.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e98cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.eval().state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b2bbddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_N_1024_512_1(N)\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f292d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_test = genfromtxt('../SPIHT_dataset/SPIHT_bits_with_context_ricardo40_v5.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xc = Xc.astype(int)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d65daa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.9560299515724182\n"
     ]
    }
   ],
   "source": [
    "Xc_tensor = torch.from_numpy(Xc[0:9357, :])\n",
    "yc_tensor = torch.from_numpy(yc[0:9357])\n",
    "predictions = model(Xc_tensor.float())\n",
    "criterion=Log2BCELoss()\n",
    "tamanho_medio = criterion(predictions,yc_tensor.float())\n",
    "print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_medio}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271db70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41bac832",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241m.\u001b[39mT, C0\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
