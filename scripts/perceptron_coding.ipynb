{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)); # signal \n",
    "yt = (yy[0:L] > 0).astype(int) # train on the first part \n",
    "yc = (yy[L:L+L] > 0).astype(int); # encode the second part\n",
    "Xt = (X[0:L,0:N] > 0).astype(int); # truncated X for training \n",
    "Xc = (X[L:L+L,0:N] > 0).astype(int); # truncated X for coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7278209104289146"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7248627782756322"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc,context_coding(Xc,context_training(Xc,yc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.728532890625\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos estão relacionados com os parâmetros usados para gerar os dados por um fator de escala, com o bias ajustado para corrigir a diferença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2242, 0.9829, 0.2125, 0.2316, 1.4047, 1.8878, 1.7824]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.9886], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.10138062, 0.49044468, 0.09653812, 0.11257858, 0.71199488,\n",
       "         0.93575754, 0.88620181]]),\n",
       " array([[0.37240823]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : valid , loss : 0.99760828125\n",
      "epoch : 1 , phase : valid , loss : 0.97324859375\n",
      "epoch : 2 , phase : valid , loss : 0.9519415625\n",
      "epoch : 3 , phase : valid , loss : 0.933254296875\n",
      "epoch : 4 , phase : valid , loss : 0.91680921875\n",
      "epoch : 5 , phase : valid , loss : 0.90228078125\n",
      "epoch : 6 , phase : valid , loss : 0.889391875\n",
      "epoch : 7 , phase : valid , loss : 0.877906953125\n",
      "epoch : 8 , phase : valid , loss : 0.867627890625\n",
      "epoch : 9 , phase : valid , loss : 0.858387578125\n",
      "epoch : 10 , phase : valid , loss : 0.850045234375\n",
      "epoch : 11 , phase : valid , loss : 0.84248234375\n",
      "epoch : 12 , phase : valid , loss : 0.83559890625\n",
      "epoch : 13 , phase : valid , loss : 0.829310234375\n",
      "epoch : 14 , phase : valid , loss : 0.823544453125\n",
      "epoch : 15 , phase : valid , loss : 0.81824046875\n",
      "epoch : 16 , phase : valid , loss : 0.813346328125\n",
      "epoch : 17 , phase : valid , loss : 0.808816953125\n",
      "epoch : 18 , phase : valid , loss : 0.80461390625\n",
      "epoch : 19 , phase : valid , loss : 0.800703828125\n",
      "epoch : 20 , phase : valid , loss : 0.797058125\n",
      "epoch : 21 , phase : valid , loss : 0.79365125\n",
      "epoch : 22 , phase : valid , loss : 0.79046140625\n",
      "epoch : 23 , phase : valid , loss : 0.787469296875\n",
      "epoch : 24 , phase : valid , loss : 0.784657734375\n",
      "epoch : 25 , phase : valid , loss : 0.782011796875\n",
      "epoch : 26 , phase : valid , loss : 0.779518125\n",
      "epoch : 27 , phase : valid , loss : 0.777164609375\n",
      "epoch : 28 , phase : valid , loss : 0.774940703125\n",
      "epoch : 29 , phase : valid , loss : 0.772836875\n",
      "epoch : 30 , phase : valid , loss : 0.770844453125\n",
      "epoch : 31 , phase : valid , loss : 0.768955625\n",
      "epoch : 32 , phase : valid , loss : 0.76716328125\n",
      "epoch : 33 , phase : valid , loss : 0.765461171875\n",
      "epoch : 34 , phase : valid , loss : 0.76384328125\n",
      "epoch : 35 , phase : valid , loss : 0.762304296875\n",
      "epoch : 36 , phase : valid , loss : 0.760839453125\n",
      "epoch : 37 , phase : valid , loss : 0.759444140625\n",
      "epoch : 38 , phase : valid , loss : 0.75811421875\n",
      "epoch : 39 , phase : valid , loss : 0.75684578125\n",
      "epoch : 40 , phase : valid , loss : 0.755635625\n",
      "epoch : 41 , phase : valid , loss : 0.754480078125\n",
      "epoch : 42 , phase : valid , loss : 0.753376328125\n",
      "epoch : 43 , phase : valid , loss : 0.7523215625\n",
      "epoch : 44 , phase : valid , loss : 0.751313046875\n",
      "epoch : 45 , phase : valid , loss : 0.750348515625\n",
      "epoch : 46 , phase : valid , loss : 0.749425546875\n",
      "epoch : 47 , phase : valid , loss : 0.748541953125\n",
      "epoch : 48 , phase : valid , loss : 0.747695859375\n",
      "epoch : 49 , phase : valid , loss : 0.7468853125\n",
      "epoch : 50 , phase : valid , loss : 0.74610859375\n",
      "epoch : 51 , phase : valid , loss : 0.745363984375\n",
      "epoch : 52 , phase : valid , loss : 0.74465\n",
      "epoch : 53 , phase : valid , loss : 0.743965078125\n",
      "epoch : 54 , phase : valid , loss : 0.743307890625\n",
      "epoch : 55 , phase : valid , loss : 0.74267734375\n",
      "epoch : 56 , phase : valid , loss : 0.742071796875\n",
      "epoch : 57 , phase : valid , loss : 0.74149046875\n",
      "epoch : 58 , phase : valid , loss : 0.74093203125\n",
      "epoch : 59 , phase : valid , loss : 0.740395546875\n",
      "epoch : 60 , phase : valid , loss : 0.73988\n",
      "epoch : 61 , phase : valid , loss : 0.739384375\n",
      "epoch : 62 , phase : valid , loss : 0.73890796875\n",
      "epoch : 63 , phase : valid , loss : 0.73844984375\n",
      "epoch : 64 , phase : valid , loss : 0.7380090625\n",
      "epoch : 65 , phase : valid , loss : 0.73758515625\n",
      "epoch : 66 , phase : valid , loss : 0.737177265625\n",
      "epoch : 67 , phase : valid , loss : 0.7367846875\n",
      "epoch : 68 , phase : valid , loss : 0.736406796875\n",
      "epoch : 69 , phase : valid , loss : 0.73604296875\n",
      "epoch : 70 , phase : valid , loss : 0.735692578125\n",
      "epoch : 71 , phase : valid , loss : 0.735355078125\n",
      "epoch : 72 , phase : valid , loss : 0.735030078125\n",
      "epoch : 73 , phase : valid , loss : 0.734716953125\n",
      "epoch : 74 , phase : valid , loss : 0.73441515625\n",
      "epoch : 75 , phase : valid , loss : 0.734124296875\n",
      "epoch : 76 , phase : valid , loss : 0.733843984375\n",
      "epoch : 77 , phase : valid , loss : 0.733573828125\n",
      "epoch : 78 , phase : valid , loss : 0.733313125\n",
      "epoch : 79 , phase : valid , loss : 0.733061875\n",
      "epoch : 80 , phase : valid , loss : 0.73281953125\n",
      "epoch : 81 , phase : valid , loss : 0.73258578125\n",
      "epoch : 82 , phase : valid , loss : 0.73236015625\n",
      "epoch : 83 , phase : valid , loss : 0.732142578125\n",
      "epoch : 84 , phase : valid , loss : 0.731932578125\n",
      "epoch : 85 , phase : valid , loss : 0.73172984375\n",
      "epoch : 86 , phase : valid , loss : 0.73153421875\n",
      "epoch : 87 , phase : valid , loss : 0.731345390625\n",
      "epoch : 88 , phase : valid , loss : 0.731163046875\n",
      "epoch : 89 , phase : valid , loss : 0.730986953125\n",
      "epoch : 90 , phase : valid , loss : 0.730816875\n",
      "epoch : 91 , phase : valid , loss : 0.73065265625\n",
      "epoch : 92 , phase : valid , loss : 0.7304940625\n",
      "epoch : 93 , phase : valid , loss : 0.73034078125\n",
      "epoch : 94 , phase : valid , loss : 0.730192734375\n",
      "epoch : 95 , phase : valid , loss : 0.730049765625\n",
      "epoch : 96 , phase : valid , loss : 0.72991140625\n",
      "epoch : 97 , phase : valid , loss : 0.7297778125\n",
      "epoch : 98 , phase : valid , loss : 0.729648671875\n",
      "epoch : 99 , phase : valid , loss : 0.72952390625\n",
      "epoch : 100 , phase : valid , loss : 0.729403203125\n",
      "epoch : 101 , phase : valid , loss : 0.729286484375\n",
      "epoch : 102 , phase : valid , loss : 0.729173828125\n",
      "epoch : 103 , phase : valid , loss : 0.729064609375\n",
      "epoch : 104 , phase : valid , loss : 0.72895921875\n",
      "epoch : 105 , phase : valid , loss : 0.728857109375\n",
      "epoch : 106 , phase : valid , loss : 0.7287584375\n",
      "epoch : 107 , phase : valid , loss : 0.72866296875\n",
      "epoch : 108 , phase : valid , loss : 0.728570703125\n",
      "epoch : 109 , phase : valid , loss : 0.728481328125\n",
      "epoch : 110 , phase : valid , loss : 0.728395\n",
      "epoch : 111 , phase : valid , loss : 0.72831125\n",
      "epoch : 112 , phase : valid , loss : 0.7282303125\n",
      "epoch : 113 , phase : valid , loss : 0.728151953125\n",
      "epoch : 114 , phase : valid , loss : 0.728076171875\n",
      "epoch : 115 , phase : valid , loss : 0.728002734375\n",
      "epoch : 116 , phase : valid , loss : 0.727931796875\n",
      "epoch : 117 , phase : valid , loss : 0.72786296875\n",
      "epoch : 118 , phase : valid , loss : 0.727796484375\n",
      "epoch : 119 , phase : valid , loss : 0.72773203125\n",
      "epoch : 120 , phase : valid , loss : 0.72766953125\n",
      "epoch : 121 , phase : valid , loss : 0.727609140625\n",
      "epoch : 122 , phase : valid , loss : 0.727550625\n",
      "epoch : 123 , phase : valid , loss : 0.727493984375\n",
      "epoch : 124 , phase : valid , loss : 0.727439140625\n",
      "epoch : 125 , phase : valid , loss : 0.727386015625\n",
      "epoch : 126 , phase : valid , loss : 0.727334453125\n",
      "epoch : 127 , phase : valid , loss : 0.72728453125\n",
      "epoch : 128 , phase : valid , loss : 0.727236328125\n",
      "epoch : 129 , phase : valid , loss : 0.727189453125\n",
      "epoch : 130 , phase : valid , loss : 0.727144140625\n",
      "epoch : 131 , phase : valid , loss : 0.727100234375\n",
      "epoch : 132 , phase : valid , loss : 0.72705765625\n",
      "epoch : 133 , phase : valid , loss : 0.72701640625\n",
      "epoch : 134 , phase : valid , loss : 0.72697640625\n",
      "epoch : 135 , phase : valid , loss : 0.726937734375\n",
      "epoch : 136 , phase : valid , loss : 0.726900234375\n",
      "epoch : 137 , phase : valid , loss : 0.726863828125\n",
      "epoch : 138 , phase : valid , loss : 0.726828515625\n",
      "epoch : 139 , phase : valid , loss : 0.726794375\n",
      "epoch : 140 , phase : valid , loss : 0.72676125\n",
      "epoch : 141 , phase : valid , loss : 0.726729140625\n",
      "epoch : 142 , phase : valid , loss : 0.726698046875\n",
      "epoch : 143 , phase : valid , loss : 0.7266678125\n",
      "epoch : 144 , phase : valid , loss : 0.72663859375\n",
      "epoch : 145 , phase : valid , loss : 0.726610234375\n",
      "epoch : 146 , phase : valid , loss : 0.726582734375\n",
      "epoch : 147 , phase : valid , loss : 0.72655609375\n",
      "epoch : 148 , phase : valid , loss : 0.7265303125\n",
      "epoch : 149 , phase : valid , loss : 0.726505234375\n",
      "epoch : 150 , phase : valid , loss : 0.7264809375\n",
      "epoch : 151 , phase : valid , loss : 0.72645734375\n",
      "epoch : 152 , phase : valid , loss : 0.726434453125\n",
      "epoch : 153 , phase : valid , loss : 0.726412421875\n",
      "epoch : 154 , phase : valid , loss : 0.72639078125\n",
      "epoch : 155 , phase : valid , loss : 0.726369921875\n",
      "epoch : 156 , phase : valid , loss : 0.7263496875\n",
      "epoch : 157 , phase : valid , loss : 0.726330078125\n",
      "epoch : 158 , phase : valid , loss : 0.72631109375\n",
      "epoch : 159 , phase : valid , loss : 0.72629265625\n",
      "epoch : 160 , phase : valid , loss : 0.726274765625\n",
      "epoch : 161 , phase : valid , loss : 0.726257421875\n",
      "epoch : 162 , phase : valid , loss : 0.726240546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 163 , phase : valid , loss : 0.726224140625\n",
      "epoch : 164 , phase : valid , loss : 0.726208359375\n",
      "epoch : 165 , phase : valid , loss : 0.72619296875\n",
      "epoch : 166 , phase : valid , loss : 0.726178046875\n",
      "epoch : 167 , phase : valid , loss : 0.72616359375\n",
      "epoch : 168 , phase : valid , loss : 0.72614953125\n",
      "epoch : 169 , phase : valid , loss : 0.7261359375\n",
      "epoch : 170 , phase : valid , loss : 0.726122734375\n",
      "epoch : 171 , phase : valid , loss : 0.72610984375\n",
      "epoch : 172 , phase : valid , loss : 0.726097421875\n",
      "epoch : 173 , phase : valid , loss : 0.726085390625\n",
      "epoch : 174 , phase : valid , loss : 0.726073671875\n",
      "epoch : 175 , phase : valid , loss : 0.726062265625\n",
      "epoch : 176 , phase : valid , loss : 0.726051171875\n",
      "epoch : 177 , phase : valid , loss : 0.726040546875\n",
      "epoch : 178 , phase : valid , loss : 0.72603015625\n",
      "epoch : 179 , phase : valid , loss : 0.726020078125\n",
      "epoch : 180 , phase : valid , loss : 0.726010234375\n",
      "epoch : 181 , phase : valid , loss : 0.726000625\n",
      "epoch : 182 , phase : valid , loss : 0.7259915625\n",
      "epoch : 183 , phase : valid , loss : 0.725982578125\n",
      "epoch : 184 , phase : valid , loss : 0.725973828125\n",
      "epoch : 185 , phase : valid , loss : 0.72596546875\n",
      "epoch : 186 , phase : valid , loss : 0.725957265625\n",
      "epoch : 187 , phase : valid , loss : 0.725949296875\n",
      "epoch : 188 , phase : valid , loss : 0.7259415625\n",
      "epoch : 189 , phase : valid , loss : 0.7259340625\n",
      "epoch : 190 , phase : valid , loss : 0.725926796875\n",
      "epoch : 191 , phase : valid , loss : 0.725919765625\n",
      "epoch : 192 , phase : valid , loss : 0.72591296875\n",
      "epoch : 193 , phase : valid , loss : 0.72590625\n",
      "epoch : 194 , phase : valid , loss : 0.72589984375\n",
      "epoch : 195 , phase : valid , loss : 0.72589359375\n",
      "epoch : 196 , phase : valid , loss : 0.7258875\n",
      "epoch : 197 , phase : valid , loss : 0.7258815625\n",
      "epoch : 198 , phase : valid , loss : 0.725875859375\n",
      "epoch : 199 , phase : valid , loss : 0.7258703125\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.72873578125\n",
      "(compare com a entropia do dataset de treino).\n",
      "comprimento médio de código final no dataset de validação: 0.7258703125\n",
      "(compare com a entropia do dataset de validação).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos estão relacionados com os parâmetros usados para gerar os dados por um fator de escala, com o bias ajustado para corrigir a diferença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "271db70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1999, 0.9447, 0.1883, 0.2068, 1.3592, 1.8354, 1.7316]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.8569], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41bac832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.10138062, 0.49044468, 0.09653812, 0.11257858, 0.71199488,\n",
       "         0.93575754, 0.88620181]]),\n",
       " array([[0.37240823]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
