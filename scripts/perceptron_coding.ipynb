{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "X = (X > 0).astype(int)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)).astype(int) # signal \n",
    "yt = yy[0:L] > 0 # train on the first part \n",
    "yc = yy[L:L+L] > 0 # encode the second part\n",
    "Xt = X[0:L,0:N] # truncated X for training \n",
    "Xc = X[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bbecba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "L = 100000 # how many samples \n",
    "#N = 10 # order of the AR\n",
    "first = True\n",
    "for pc_num in range(29, 39):\n",
    "    if first:\n",
    "        my_data = genfromtxt(f'../SPIHT_dataset/ricardo_vox7/SPIHT_bits_with_context_ricardo_Y{pc_num}_v6.csv', delimiter=',')\n",
    "        first = False\n",
    "    else:\n",
    "        my_data = np.append(my_data,\n",
    "                            genfromtxt(f'../SPIHT_dataset/ricardo_vox7/SPIHT_bits_with_context_ricardo_Y{pc_num}_v6.csv', delimiter=','),\n",
    "                            axis=0)\n",
    "    \n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(float)\n",
    "extra_context = my_data[:, 6:].astype(float)\n",
    "#extra_context = extra_context.reshape((len(extra_context), 1))\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/ricardo_vox7/SPIHT_bits_with_context_ricardo_Y40_v6.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "#extra_context_test = extra_context_test.reshape((len(extra_context_test), 1))\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bb78ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158805/2126683720.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Xt = np.append(Xt, extra_context/abs(extra_context).max(axis=0), axis=1)\n",
      "/tmp/ipykernel_158805/2126683720.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Xc = np.append(Xc, extra_context_test/abs(extra_context_test).max(axis=0), axis=1)\n"
     ]
    }
   ],
   "source": [
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "Xt = np.append(Xt, extra_context/abs(extra_context).max(axis=0), axis=1)\n",
    "Xt[np.isnan(Xt)] = 0\n",
    "Xc = np.append(Xc, extra_context_test/abs(extra_context_test).max(axis=0), axis=1)\n",
    "Xc[np.isnan(Xc)] = 0\n",
    "\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0aa3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c9921e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "#Xt = np.append(Xt, extra_context/abs(extra_context).max(axis=0), axis=1)\n",
    "Xt[np.isnan(Xt)] = 0\n",
    "#Xc = np.append(Xc, extra_context_test/abs(extra_context_test).max(axis=0), axis=1)\n",
    "Xc[np.isnan(Xc)] = 0\n",
    "\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9692049957297869"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9687832094703483"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc[:],context_coding(Xc[:, :],context_training(Xc[:, :],yc[:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449d735",
   "metadata": {},
   "source": [
    "# Criando classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a561b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_N_64N_32N_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 64*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64*N, 32*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32*N, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28dc8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_N_1024_512_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class MLP_N_2048_1024_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.003491003723144531\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0901, 11.7186, 11.9979, 12.1763, 12.1026]], device='cuda:0')\n",
      "tensor([41.8704], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32098451, 0.77295341, 0.82311742, 0.86189127, 0.7005142 ,\n",
       "         0.80153656, 0.21184858]]),\n",
       " array([[0.2792105]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Perceptron(N)\n",
    "#net = MLP_N_64N_32N_1(N)\n",
    "net = MLP_N_1024_512_1(N) #melhor resultado\n",
    "#net = MLP_N_2048_1024_1(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : train , loss : 0.99040030383119\n",
      "epoch : 0 , phase : valid , loss : 0.9848929829258791\n",
      "epoch : 1 , phase : train , loss : 0.9806520884489289\n",
      "epoch : 1 , phase : valid , loss : 0.9763866706134026\n",
      "epoch : 2 , phase : train , loss : 0.9735905009523117\n",
      "epoch : 2 , phase : valid , loss : 0.9712299068075474\n",
      "epoch : 3 , phase : train , loss : 0.9700478519467435\n",
      "epoch : 3 , phase : valid , loss : 0.9690347209974908\n",
      "epoch : 4 , phase : train , loss : 0.9686832561773686\n",
      "epoch : 4 , phase : valid , loss : 0.9680573213392746\n",
      "epoch : 5 , phase : train , loss : 0.9680317223255851\n",
      "epoch : 5 , phase : valid , loss : 0.9675429748193971\n",
      "epoch : 6 , phase : train , loss : 0.9676588164679237\n",
      "epoch : 6 , phase : valid , loss : 0.9671516905573018\n",
      "epoch : 7 , phase : train , loss : 0.9673760193891251\n",
      "epoch : 7 , phase : valid , loss : 0.9668558336114559\n",
      "epoch : 8 , phase : train , loss : 0.967133098867413\n",
      "epoch : 8 , phase : valid , loss : 0.9666254581348338\n",
      "epoch : 9 , phase : train , loss : 0.9669095098325842\n",
      "epoch : 9 , phase : valid , loss : 0.9663678052530004\n",
      "epoch : 10 , phase : train , loss : 0.9666820722781573\n",
      "epoch : 10 , phase : valid , loss : 0.9661252212190586\n",
      "epoch : 11 , phase : train , loss : 0.9664582606950977\n",
      "epoch : 11 , phase : valid , loss : 0.9659070194181639\n",
      "epoch : 12 , phase : train , loss : 0.9662574980671687\n",
      "epoch : 12 , phase : valid , loss : 0.9656843004510608\n",
      "epoch : 13 , phase : train , loss : 0.9660354351394448\n",
      "epoch : 13 , phase : valid , loss : 0.9654587211933858\n",
      "epoch : 14 , phase : train , loss : 0.9658048588725695\n",
      "epoch : 14 , phase : valid , loss : 0.9652545069110201\n",
      "epoch : 15 , phase : train , loss : 0.9655792240892103\n",
      "epoch : 15 , phase : valid , loss : 0.9650117223079224\n",
      "epoch : 16 , phase : train , loss : 0.96535006026467\n",
      "epoch : 16 , phase : valid , loss : 0.964851502433898\n",
      "epoch : 17 , phase : train , loss : 0.9651187761466352\n",
      "epoch : 17 , phase : valid , loss : 0.9645582703278758\n",
      "epoch : 18 , phase : train , loss : 0.9648925989019638\n",
      "epoch : 18 , phase : valid , loss : 0.9643248514323219\n",
      "epoch : 19 , phase : train , loss : 0.9646500571903748\n",
      "epoch : 19 , phase : valid , loss : 0.9640568648787572\n",
      "epoch : 20 , phase : train , loss : 0.9643929344403652\n",
      "epoch : 20 , phase : valid , loss : 0.9638116734457879\n",
      "epoch : 21 , phase : train , loss : 0.9641366679794462\n",
      "epoch : 21 , phase : valid , loss : 0.9636543313031316\n",
      "epoch : 22 , phase : train , loss : 0.9638807646807278\n",
      "epoch : 22 , phase : valid , loss : 0.9633262176047676\n",
      "epoch : 23 , phase : train , loss : 0.9636134999036366\n",
      "epoch : 23 , phase : valid , loss : 0.9630706837796689\n",
      "epoch : 24 , phase : train , loss : 0.9633276234440957\n",
      "epoch : 24 , phase : valid , loss : 0.9627814107343775\n",
      "epoch : 25 , phase : train , loss : 0.9630200700479598\n",
      "epoch : 25 , phase : valid , loss : 0.962493646317955\n",
      "epoch : 26 , phase : train , loss : 0.9627496887263103\n",
      "epoch : 26 , phase : valid , loss : 0.9621608672066151\n",
      "epoch : 27 , phase : train , loss : 0.9624468136243276\n",
      "epoch : 27 , phase : valid , loss : 0.9618585135641955\n",
      "epoch : 28 , phase : train , loss : 0.962128144769933\n",
      "epoch : 28 , phase : valid , loss : 0.9615567877904381\n",
      "epoch : 29 , phase : train , loss : 0.9618254596163425\n",
      "epoch : 29 , phase : valid , loss : 0.9613161484052694\n",
      "epoch : 30 , phase : train , loss : 0.9614937071427745\n",
      "epoch : 30 , phase : valid , loss : 0.9609213672635418\n",
      "epoch : 31 , phase : train , loss : 0.9611715079432054\n",
      "epoch : 31 , phase : valid , loss : 0.9606108949305047\n",
      "epoch : 32 , phase : train , loss : 0.9608466351222168\n",
      "epoch : 32 , phase : valid , loss : 0.9602676775026566\n",
      "epoch : 33 , phase : train , loss : 0.9605097140529248\n",
      "epoch : 33 , phase : valid , loss : 0.9599250443414802\n",
      "epoch : 34 , phase : train , loss : 0.9601448510100796\n",
      "epoch : 34 , phase : valid , loss : 0.9595840942171343\n",
      "epoch : 35 , phase : train , loss : 0.9598077376017407\n",
      "epoch : 35 , phase : valid , loss : 0.9592421499674066\n",
      "epoch : 36 , phase : train , loss : 0.9594562678765344\n",
      "epoch : 36 , phase : valid , loss : 0.958932654318955\n",
      "epoch : 37 , phase : train , loss : 0.9590623201271312\n",
      "epoch : 37 , phase : valid , loss : 0.9585853295836086\n",
      "epoch : 38 , phase : train , loss : 0.9587343824866615\n",
      "epoch : 38 , phase : valid , loss : 0.958192981432947\n",
      "epoch : 39 , phase : train , loss : 0.9583475930097907\n",
      "epoch : 39 , phase : valid , loss : 0.9578463020070589\n",
      "epoch : 40 , phase : train , loss : 0.9579841952210187\n",
      "epoch : 40 , phase : valid , loss : 0.957553200707008\n",
      "epoch : 41 , phase : train , loss : 0.9576182783340618\n",
      "epoch : 41 , phase : valid , loss : 0.9571693985464701\n",
      "epoch : 42 , phase : train , loss : 0.9572910596286967\n",
      "epoch : 42 , phase : valid , loss : 0.9568114436458576\n",
      "epoch : 43 , phase : train , loss : 0.9569327452414041\n",
      "epoch : 43 , phase : valid , loss : 0.9565543663102977\n",
      "epoch : 44 , phase : train , loss : 0.9565702561187966\n",
      "epoch : 44 , phase : valid , loss : 0.9561620443208303\n",
      "epoch : 45 , phase : train , loss : 0.9562271980212458\n",
      "epoch : 45 , phase : valid , loss : 0.9558603447082671\n",
      "epoch : 46 , phase : train , loss : 0.9559124331061747\n",
      "epoch : 46 , phase : valid , loss : 0.9555037589101539\n",
      "epoch : 47 , phase : train , loss : 0.9556044035350646\n",
      "epoch : 47 , phase : valid , loss : 0.9551780694824576\n",
      "epoch : 48 , phase : train , loss : 0.9552848927355083\n",
      "epoch : 48 , phase : valid , loss : 0.9549394183480524\n",
      "epoch : 49 , phase : train , loss : 0.9549600494717067\n",
      "epoch : 49 , phase : valid , loss : 0.954865809467813\n",
      "epoch : 50 , phase : train , loss : 0.95466702691024\n",
      "epoch : 50 , phase : valid , loss : 0.9543190405078537\n",
      "epoch : 51 , phase : train , loss : 0.9543508660700853\n",
      "epoch : 51 , phase : valid , loss : 0.9541029752044898\n",
      "epoch : 52 , phase : train , loss : 0.9541056361758158\n",
      "epoch : 52 , phase : valid , loss : 0.9541178522036237\n",
      "epoch : 53 , phase : train , loss : 0.9538306878341284\n",
      "epoch : 53 , phase : valid , loss : 0.9535457766484203\n",
      "epoch : 54 , phase : train , loss : 0.953532516454173\n",
      "epoch : 54 , phase : valid , loss : 0.9532574715673164\n",
      "epoch : 55 , phase : train , loss : 0.9532787075864104\n",
      "epoch : 55 , phase : valid , loss : 0.9531107334287322\n",
      "epoch : 56 , phase : train , loss : 0.9529815039869933\n",
      "epoch : 56 , phase : valid , loss : 0.9527746754477122\n",
      "epoch : 57 , phase : train , loss : 0.952802589988142\n",
      "epoch : 57 , phase : valid , loss : 0.9525738621205999\n",
      "epoch : 58 , phase : train , loss : 0.9525579516722747\n",
      "epoch : 58 , phase : valid , loss : 0.9522776214772383\n",
      "epoch : 59 , phase : train , loss : 0.9522681699694169\n",
      "epoch : 59 , phase : valid , loss : 0.9521064749444127\n",
      "epoch : 60 , phase : train , loss : 0.951973994025665\n",
      "epoch : 60 , phase : valid , loss : 0.9521439813765783\n",
      "epoch : 61 , phase : train , loss : 0.9518030767671916\n",
      "epoch : 61 , phase : valid , loss : 0.9516620398559864\n",
      "epoch : 62 , phase : train , loss : 0.9516261941729418\n",
      "epoch : 62 , phase : valid , loss : 0.9513605233717831\n",
      "epoch : 63 , phase : train , loss : 0.9513124904912791\n",
      "epoch : 63 , phase : valid , loss : 0.9512152851416695\n",
      "epoch : 64 , phase : train , loss : 0.951115583120248\n",
      "epoch : 64 , phase : valid , loss : 0.950980994206307\n",
      "epoch : 65 , phase : train , loss : 0.9509584599400944\n",
      "epoch : 65 , phase : valid , loss : 0.9508656931028209\n",
      "epoch : 66 , phase : train , loss : 0.950704993370636\n",
      "epoch : 66 , phase : valid , loss : 0.9505264608968979\n",
      "epoch : 67 , phase : train , loss : 0.950448653234082\n",
      "epoch : 67 , phase : valid , loss : 0.9504859197661985\n",
      "epoch : 68 , phase : train , loss : 0.950175868435008\n",
      "epoch : 68 , phase : valid , loss : 0.9501063731599262\n",
      "epoch : 69 , phase : train , loss : 0.9500551818769851\n",
      "epoch : 69 , phase : valid , loss : 0.9500017196625025\n",
      "epoch : 70 , phase : train , loss : 0.9497955028649746\n",
      "epoch : 70 , phase : valid , loss : 0.9497452440344105\n",
      "epoch : 71 , phase : train , loss : 0.9496319862044995\n",
      "epoch : 71 , phase : valid , loss : 0.9495132465637446\n",
      "epoch : 72 , phase : train , loss : 0.9494053390874894\n",
      "epoch : 72 , phase : valid , loss : 0.9492857400980926\n",
      "epoch : 73 , phase : train , loss : 0.9492366712178707\n",
      "epoch : 73 , phase : valid , loss : 0.9491383130480596\n",
      "epoch : 74 , phase : train , loss : 0.9489616931016641\n",
      "epoch : 74 , phase : valid , loss : 0.9489602774007465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 75 , phase : train , loss : 0.9488704717989803\n",
      "epoch : 75 , phase : valid , loss : 0.9493100002455664\n",
      "epoch : 76 , phase : train , loss : 0.9486318448933276\n",
      "epoch : 76 , phase : valid , loss : 0.9485750799765149\n",
      "epoch : 77 , phase : train , loss : 0.9484554771591935\n",
      "epoch : 77 , phase : valid , loss : 0.948612935224604\n",
      "epoch : 78 , phase : train , loss : 0.9482633334938926\n",
      "epoch : 78 , phase : valid , loss : 0.9482385859755907\n",
      "epoch : 79 , phase : train , loss : 0.9482148573167488\n",
      "epoch : 79 , phase : valid , loss : 0.9489809796258014\n",
      "epoch : 80 , phase : train , loss : 0.9480971351707045\n",
      "epoch : 80 , phase : valid , loss : 0.9478004993369707\n",
      "epoch : 81 , phase : train , loss : 0.9478343263568683\n",
      "epoch : 81 , phase : valid , loss : 0.9487295095062106\n",
      "epoch : 82 , phase : train , loss : 0.9476482199643205\n",
      "epoch : 82 , phase : valid , loss : 0.9477632109147572\n",
      "epoch : 83 , phase : train , loss : 0.947258923559871\n",
      "epoch : 83 , phase : valid , loss : 0.9474663424027334\n",
      "epoch : 84 , phase : train , loss : 0.9475548881480939\n",
      "epoch : 84 , phase : valid , loss : 0.9472730896607612\n",
      "epoch : 85 , phase : train , loss : 0.946842217211232\n",
      "epoch : 85 , phase : valid , loss : 0.9469864588960897\n",
      "epoch : 86 , phase : train , loss : 0.9469528964881723\n",
      "epoch : 86 , phase : valid , loss : 0.9468804973389531\n",
      "epoch : 87 , phase : train , loss : 0.9469233442999306\n",
      "epoch : 87 , phase : valid , loss : 0.9472171483070428\n",
      "epoch : 88 , phase : train , loss : 0.9463687086867029\n",
      "epoch : 88 , phase : valid , loss : 0.9465939624986606\n",
      "epoch : 89 , phase : train , loss : 0.9464073573165401\n",
      "epoch : 89 , phase : valid , loss : 0.9467140423802975\n",
      "epoch : 90 , phase : train , loss : 0.9466278439334076\n",
      "epoch : 90 , phase : valid , loss : 0.94616990698056\n",
      "epoch : 91 , phase : train , loss : 0.9466690253533621\n",
      "epoch : 91 , phase : valid , loss : 0.9463451346596896\n",
      "epoch : 92 , phase : train , loss : 0.9460072479803331\n",
      "epoch : 92 , phase : valid , loss : 0.9459292065526048\n",
      "epoch : 93 , phase : train , loss : 0.9459160736214166\n",
      "epoch : 93 , phase : valid , loss : 0.9461648142680782\n",
      "epoch : 94 , phase : train , loss : 0.9459594859569841\n",
      "epoch : 94 , phase : valid , loss : 0.9458604985360893\n",
      "epoch : 95 , phase : train , loss : 0.9455408140554175\n",
      "epoch : 95 , phase : valid , loss : 0.9466030665942617\n",
      "epoch : 96 , phase : train , loss : 0.9456044815399581\n",
      "epoch : 96 , phase : valid , loss : 0.9463343562476559\n",
      "epoch : 97 , phase : train , loss : 0.9453417548777148\n",
      "epoch : 97 , phase : valid , loss : 0.9461573147257246\n",
      "epoch : 98 , phase : train , loss : 0.9456543056117567\n",
      "epoch : 98 , phase : valid , loss : 0.9450480800892522\n",
      "epoch : 99 , phase : train , loss : 0.9454980363300389\n",
      "epoch : 99 , phase : valid , loss : 0.9450981264538648\n",
      "epoch : 100 , phase : train , loss : 0.9447716223879375\n",
      "epoch : 100 , phase : valid , loss : 0.9448041356732092\n",
      "epoch : 101 , phase : train , loss : 0.9453360290420851\n",
      "epoch : 101 , phase : valid , loss : 0.9449276513916918\n",
      "epoch : 102 , phase : train , loss : 0.9447384011965417\n",
      "epoch : 102 , phase : valid , loss : 0.9448691288001402\n",
      "epoch : 103 , phase : train , loss : 0.9444531147940772\n",
      "epoch : 103 , phase : valid , loss : 0.9442661743153162\n",
      "epoch : 104 , phase : train , loss : 0.9462347024866761\n",
      "epoch : 104 , phase : valid , loss : 0.9443229179456584\n",
      "epoch : 105 , phase : train , loss : 0.9446241137694791\n",
      "epoch : 105 , phase : valid , loss : 0.9444287835784161\n",
      "epoch : 106 , phase : train , loss : 0.9441831359717668\n",
      "epoch : 106 , phase : valid , loss : 0.9440137013499456\n",
      "epoch : 107 , phase : train , loss : 0.9439722358807335\n",
      "epoch : 107 , phase : valid , loss : 0.9451125151107058\n",
      "epoch : 108 , phase : train , loss : 0.9445407872783448\n",
      "epoch : 108 , phase : valid , loss : 0.9437765152424187\n",
      "epoch : 109 , phase : train , loss : 0.9436793454572787\n",
      "epoch : 109 , phase : valid , loss : 0.943771439970733\n",
      "epoch : 110 , phase : train , loss : 0.9443136444264576\n",
      "epoch : 110 , phase : valid , loss : 0.9434246297388736\n",
      "epoch : 111 , phase : train , loss : 0.9447088272750744\n",
      "epoch : 111 , phase : valid , loss : 0.9445367508271123\n",
      "epoch : 112 , phase : train , loss : 0.9437121469800873\n",
      "epoch : 112 , phase : valid , loss : 0.9455956338850392\n",
      "epoch : 113 , phase : train , loss : 0.9435392472167701\n",
      "epoch : 113 , phase : valid , loss : 0.9467713528365153\n",
      "epoch : 114 , phase : train , loss : 0.9432537104475461\n",
      "epoch : 114 , phase : valid , loss : 0.94313819082296\n",
      "epoch : 115 , phase : train , loss : 0.9437602602123627\n",
      "epoch : 115 , phase : valid , loss : 0.9430216601433438\n",
      "epoch : 116 , phase : train , loss : 0.9432921771702848\n",
      "epoch : 116 , phase : valid , loss : 0.9426737685821218\n",
      "epoch : 117 , phase : train , loss : 0.9435591305102524\n",
      "epoch : 117 , phase : valid , loss : 0.9443031226420043\n",
      "epoch : 118 , phase : train , loss : 0.943299316752243\n",
      "epoch : 118 , phase : valid , loss : 0.9429421301128043\n",
      "epoch : 119 , phase : train , loss : 0.9432464356849245\n",
      "epoch : 119 , phase : valid , loss : 0.9426723209960397\n",
      "epoch : 120 , phase : train , loss : 0.9438455589937248\n",
      "epoch : 120 , phase : valid , loss : 0.9421842403151957\n",
      "epoch : 121 , phase : train , loss : 0.9429312317586952\n",
      "epoch : 121 , phase : valid , loss : 0.9426897094698221\n",
      "epoch : 122 , phase : train , loss : 0.9432887865697511\n",
      "epoch : 122 , phase : valid , loss : 0.9422324030738217\n",
      "epoch : 123 , phase : train , loss : 0.9426320232692118\n",
      "epoch : 123 , phase : valid , loss : 0.9431936176731913\n",
      "epoch : 124 , phase : train , loss : 0.9431953795565637\n",
      "epoch : 124 , phase : valid , loss : 0.9431177240486533\n",
      "epoch : 125 , phase : train , loss : 0.9422324277064591\n",
      "epoch : 125 , phase : valid , loss : 0.9423645345456129\n",
      "epoch : 126 , phase : train , loss : 0.9427404307720749\n",
      "epoch : 126 , phase : valid , loss : 0.9418932842330737\n",
      "epoch : 127 , phase : train , loss : 0.9419644944153469\n",
      "epoch : 127 , phase : valid , loss : 0.9416484677772221\n",
      "epoch : 128 , phase : train , loss : 0.9430688087276962\n",
      "epoch : 128 , phase : valid , loss : 0.9416260912357348\n",
      "epoch : 129 , phase : train , loss : 0.9418716592033263\n",
      "epoch : 129 , phase : valid , loss : 0.9420866154586287\n",
      "epoch : 130 , phase : train , loss : 0.9429354882109386\n",
      "epoch : 130 , phase : valid , loss : 0.9418173470065455\n",
      "epoch : 131 , phase : train , loss : 0.9419892107435492\n",
      "epoch : 131 , phase : valid , loss : 0.9422166976368698\n",
      "epoch : 132 , phase : train , loss : 0.9417829872080111\n",
      "epoch : 132 , phase : valid , loss : 0.942561249285625\n",
      "epoch : 133 , phase : train , loss : 0.9410686415087808\n",
      "epoch : 133 , phase : valid , loss : 0.9408512664250442\n",
      "epoch : 134 , phase : train , loss : 0.9422352230339421\n",
      "epoch : 134 , phase : valid , loss : 0.9411639624595932\n",
      "epoch : 135 , phase : train , loss : 0.9423979857688196\n",
      "epoch : 135 , phase : valid , loss : 0.9405821636605245\n",
      "epoch : 136 , phase : train , loss : 0.9409499567981725\n",
      "epoch : 136 , phase : valid , loss : 0.9409063793409445\n",
      "epoch : 137 , phase : train , loss : 0.9415734547888679\n",
      "epoch : 137 , phase : valid , loss : 0.9434632175004019\n",
      "epoch : 138 , phase : train , loss : 0.9416125669884083\n",
      "epoch : 138 , phase : valid , loss : 0.9404209234999241\n",
      "epoch : 139 , phase : train , loss : 0.9403785646506365\n",
      "epoch : 139 , phase : valid , loss : 0.9407994934216107\n",
      "epoch : 140 , phase : train , loss : 0.9413412387501174\n",
      "epoch : 140 , phase : valid , loss : 0.9422447598779089\n",
      "epoch : 141 , phase : train , loss : 0.9416031584576924\n",
      "epoch : 141 , phase : valid , loss : 0.941639581691573\n",
      "epoch : 142 , phase : train , loss : 0.9406597352148275\n",
      "epoch : 142 , phase : valid , loss : 0.9404739522406819\n",
      "epoch : 143 , phase : train , loss : 0.9403984179522675\n",
      "epoch : 143 , phase : valid , loss : 0.940771971845253\n",
      "epoch : 144 , phase : train , loss : 0.9422408026049632\n",
      "epoch : 144 , phase : valid , loss : 0.9409987370770677\n",
      "epoch : 145 , phase : train , loss : 0.940166590938256\n",
      "epoch : 145 , phase : valid , loss : 0.9397439851577429\n",
      "epoch : 146 , phase : train , loss : 0.9408423271274554\n",
      "epoch : 146 , phase : valid , loss : 0.940265526006041\n",
      "epoch : 147 , phase : train , loss : 0.9406158173644315\n",
      "epoch : 147 , phase : valid , loss : 0.9400001294107075\n",
      "epoch : 148 , phase : train , loss : 0.9399704635726936\n",
      "epoch : 148 , phase : valid , loss : 0.9395980144141902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 149 , phase : train , loss : 0.9404910619119023\n",
      "epoch : 149 , phase : valid , loss : 0.9395137928094807\n",
      "epoch : 150 , phase : train , loss : 0.941943202374178\n",
      "epoch : 150 , phase : valid , loss : 0.9406030141323469\n",
      "epoch : 151 , phase : train , loss : 0.9400006821016337\n",
      "epoch : 151 , phase : valid , loss : 0.9391874406315298\n",
      "epoch : 152 , phase : train , loss : 0.9391089908904472\n",
      "epoch : 152 , phase : valid , loss : 0.9406122228727252\n",
      "epoch : 153 , phase : train , loss : 0.9406722374702147\n",
      "epoch : 153 , phase : valid , loss : 0.9390402664730413\n",
      "epoch : 154 , phase : train , loss : 0.9395474211194488\n",
      "epoch : 154 , phase : valid , loss : 0.9435873087651582\n",
      "epoch : 155 , phase : train , loss : 0.9399330372194669\n",
      "epoch : 155 , phase : valid , loss : 0.9392508989683979\n",
      "epoch : 156 , phase : train , loss : 0.9397978965450611\n",
      "epoch : 156 , phase : valid , loss : 0.9413135696091476\n",
      "epoch : 157 , phase : train , loss : 0.9399838836222\n",
      "epoch : 157 , phase : valid , loss : 0.9396144349237852\n",
      "epoch : 158 , phase : train , loss : 0.9397121241967121\n",
      "epoch : 158 , phase : valid , loss : 0.941126203135883\n",
      "epoch : 159 , phase : train , loss : 0.939228321729854\n",
      "epoch : 159 , phase : valid , loss : 0.9386508745373305\n",
      "epoch : 160 , phase : train , loss : 0.9394183140231479\n",
      "epoch : 160 , phase : valid , loss : 0.9386927150073446\n",
      "epoch : 161 , phase : train , loss : 0.9397664505235364\n",
      "epoch : 161 , phase : valid , loss : 0.9404692432257157\n",
      "epoch : 162 , phase : train , loss : 0.9384157566292806\n",
      "epoch : 162 , phase : valid , loss : 0.9384515349574947\n",
      "epoch : 163 , phase : train , loss : 0.9394501019083121\n",
      "epoch : 163 , phase : valid , loss : 0.9400669276600423\n",
      "epoch : 164 , phase : train , loss : 0.9395628982187629\n",
      "epoch : 164 , phase : valid , loss : 0.9380836039214723\n",
      "epoch : 165 , phase : train , loss : 0.939326269900541\n",
      "epoch : 165 , phase : valid , loss : 0.939684407398023\n",
      "epoch : 166 , phase : train , loss : 0.9391311976830837\n",
      "epoch : 166 , phase : valid , loss : 0.9408071237699356\n",
      "epoch : 167 , phase : train , loss : 0.9388818578185116\n",
      "epoch : 167 , phase : valid , loss : 0.9385336113442752\n",
      "epoch : 168 , phase : train , loss : 0.9387589972859269\n",
      "epoch : 168 , phase : valid , loss : 0.9377817560621416\n",
      "epoch : 169 , phase : train , loss : 0.9392801289584932\n",
      "epoch : 169 , phase : valid , loss : 0.9379296627340694\n",
      "epoch : 170 , phase : train , loss : 0.9383107742827799\n",
      "epoch : 170 , phase : valid , loss : 0.9379025335756255\n",
      "epoch : 171 , phase : train , loss : 0.9386131297433373\n",
      "epoch : 171 , phase : valid , loss : 0.940278484517596\n",
      "epoch : 172 , phase : train , loss : 0.9390528841777778\n",
      "epoch : 172 , phase : valid , loss : 0.9379390458824094\n",
      "epoch : 173 , phase : train , loss : 0.9376621305153433\n",
      "epoch : 173 , phase : valid , loss : 0.9374714406962701\n",
      "epoch : 174 , phase : train , loss : 0.9374088588929188\n",
      "epoch : 174 , phase : valid , loss : 0.9374388525686247\n",
      "epoch : 175 , phase : train , loss : 0.9384507629878313\n",
      "epoch : 175 , phase : valid , loss : 0.9380869089523467\n",
      "epoch : 176 , phase : train , loss : 0.9382713723793416\n",
      "epoch : 176 , phase : valid , loss : 0.9370401908497491\n",
      "epoch : 177 , phase : train , loss : 0.9385013316399407\n",
      "epoch : 177 , phase : valid , loss : 0.9371818101146572\n",
      "epoch : 178 , phase : train , loss : 0.9373088015126826\n",
      "epoch : 178 , phase : valid , loss : 0.9369477633504412\n",
      "epoch : 179 , phase : train , loss : 0.9396665070254026\n",
      "epoch : 179 , phase : valid , loss : 0.939733171864117\n",
      "epoch : 180 , phase : train , loss : 0.9378489784455502\n",
      "epoch : 180 , phase : valid , loss : 0.9405715422156564\n",
      "epoch : 181 , phase : train , loss : 0.9376602518953181\n",
      "epoch : 181 , phase : valid , loss : 0.9378204310276508\n",
      "epoch : 182 , phase : train , loss : 0.9379257095546966\n",
      "epoch : 182 , phase : valid , loss : 0.9391654652283544\n",
      "epoch : 183 , phase : train , loss : 0.937153266161995\n",
      "epoch : 183 , phase : valid , loss : 0.9377463512459147\n",
      "epoch : 184 , phase : train , loss : 0.9389825150357758\n",
      "epoch : 184 , phase : valid , loss : 0.9364662142477631\n",
      "epoch : 185 , phase : train , loss : 0.9369889112510065\n",
      "epoch : 185 , phase : valid , loss : 0.9375050578308896\n",
      "epoch : 186 , phase : train , loss : 0.9365823510587621\n",
      "epoch : 186 , phase : valid , loss : 0.9363019132274347\n",
      "epoch : 187 , phase : train , loss : 0.9383727213651781\n",
      "epoch : 187 , phase : valid , loss : 0.9373514480186139\n",
      "epoch : 188 , phase : train , loss : 0.9376990211445577\n",
      "epoch : 188 , phase : valid , loss : 0.9373528171211134\n",
      "epoch : 189 , phase : train , loss : 0.9362402483538107\n",
      "epoch : 189 , phase : valid , loss : 0.9361942250314772\n",
      "epoch : 190 , phase : train , loss : 0.938241838012345\n",
      "epoch : 190 , phase : valid , loss : 0.9360683548055114\n",
      "epoch : 191 , phase : train , loss : 0.9370497555895353\n",
      "epoch : 191 , phase : valid , loss : 0.9362165666913721\n",
      "epoch : 192 , phase : train , loss : 0.9362087812510571\n",
      "epoch : 192 , phase : valid , loss : 0.9360537132571259\n",
      "epoch : 193 , phase : train , loss : 0.9376003594720728\n",
      "epoch : 193 , phase : valid , loss : 0.9379686865155019\n",
      "epoch : 194 , phase : train , loss : 0.9366440514690492\n",
      "epoch : 194 , phase : valid , loss : 0.9368339098330372\n",
      "epoch : 195 , phase : train , loss : 0.9368417986119194\n",
      "epoch : 195 , phase : valid , loss : 0.9378225326435894\n",
      "epoch : 196 , phase : train , loss : 0.9376905910436605\n",
      "epoch : 196 , phase : valid , loss : 0.9360382781525146\n",
      "epoch : 197 , phase : train , loss : 0.9370608977796614\n",
      "epoch : 197 , phase : valid , loss : 0.9364290740723171\n",
      "epoch : 198 , phase : train , loss : 0.9358687529824941\n",
      "epoch : 198 , phase : valid , loss : 0.9356630394228966\n",
      "epoch : 199 , phase : train , loss : 0.9372556479107145\n",
      "epoch : 199 , phase : valid , loss : 0.9385842768571517\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 10000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.9372556479107145\n",
      "(compare com a entropia do dataset de treino).\n",
      "comprimento médio de código final no dataset de validação: 0.9385842768571517\n",
      "(compare com a entropia do dataset de validação).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9fbc5",
   "metadata": {},
   "source": [
    "### Salva os pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e919036",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pesos_ricardo_vox7_Y_1024-512.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e98cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.eval().state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7b8ef",
   "metadata": {},
   "source": [
    "### Carregando os pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "381e1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pesos_phil9-v3_U_1024-512.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f292d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_test = genfromtxt('../SPIHT_dataset/david/SPIHT_bits_with_context_david_Y80_v5.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xc = Xc.astype(int)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)\n",
    "N = Xc[0, :].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b2bbddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_N_1024_512_1(N)\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d65daa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.9485439658164978\n"
     ]
    }
   ],
   "source": [
    "Xc_tensor = torch.from_numpy(Xc[0:, :])\n",
    "yc_tensor = torch.from_numpy(yc[0:])\n",
    "predictions = model(Xc_tensor.float())\n",
    "criterion=Log2BCELoss()\n",
    "tamanho_medio = criterion(predictions,yc_tensor.float())\n",
    "print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_medio}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb037251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.9572733044624329\n",
      "comprimento médio de código final no modelo treinado: 0.961675226688385\n",
      "comprimento médio de código final no modelo treinado: 0.9664247632026672\n",
      "comprimento médio de código final no modelo treinado: 0.9623333811759949\n"
     ]
    }
   ],
   "source": [
    "bit_list = [591889,301037,131569,51154]\n",
    "for i in bit_list:\n",
    "    Xc_tensor = torch.from_numpy(Xc[0:i, :])\n",
    "    yc_tensor = torch.from_numpy(yc[0:i])\n",
    "    predictions = model(Xc_tensor.float())\n",
    "    criterion=Log2BCELoss()\n",
    "    tamanho_medio = criterion(predictions,yc_tensor.float())\n",
    "    print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_medio}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a11252b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040812081822108"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_AC(yc[0:1042536],context_coding(Xc[0:1042536, :],context_training(Xc[0:, :],yc[0:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271db70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41bac832",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241m.\u001b[39mT, C0\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
