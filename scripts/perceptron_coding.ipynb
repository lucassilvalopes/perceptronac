{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "X = (X > 0).astype(int)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)).astype(int) # signal \n",
    "yt = yy[0:L] > 0 # train on the first part \n",
    "yc = yy[L:L+L] > 0 # encode the second part\n",
    "Xt = X[0:L,0:N] # truncated X for training \n",
    "Xc = X[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bbecba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1, -1, -1, -1],\n",
       "       [ 0, -1, -1, -1, -1],\n",
       "       [ 1, -1, -1, -1, -1],\n",
       "       ...,\n",
       "       [-1, -1,  1, -1, -1],\n",
       "       [ 1, -1, -1, -1, -1],\n",
       "       [-1, -1,  0, -1, -1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "L = 100000 # how many samples \n",
    "N = 5 # order of the AR\n",
    "my_data = genfromtxt('../SPIHT_dataset/SPIHT_bits_with_context_ricardo14.csv', delimiter=',')\n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(int)\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/SPIHT_bits_with_context_ricardo15.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(int)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "\n",
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context # truncated X for training \n",
    "Xc = context_test # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0aa3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2034265038149176e-16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.203426503814918e-16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc,context_coding(Xc,context_training(Xc,yc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a5949",
   "metadata": {},
   "source": [
    "# Criando classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.003491003723144531\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0901, 11.7186, 11.9979, 12.1763, 12.1026]], device='cuda:0')\n",
      "tensor([41.8704], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32098451, 0.77295341, 0.82311742, 0.86189127, 0.7005142 ,\n",
       "         0.80153656, 0.21184858]]),\n",
       " array([[0.2792105]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : train , loss : 0.9249599924875869\n",
      "epoch : 0 , phase : valid , loss : 0.8783912045136745\n",
      "epoch : 1 , phase : train , loss : 0.857345049755064\n",
      "epoch : 1 , phase : valid , loss : 0.8312144911447269\n",
      "epoch : 2 , phase : train , loss : 0.8135192317285984\n",
      "epoch : 2 , phase : valid , loss : 0.7903413277088718\n",
      "epoch : 3 , phase : train , loss : 0.7741555494609583\n",
      "epoch : 3 , phase : valid , loss : 0.7527223796351283\n",
      "epoch : 4 , phase : train , loss : 0.7376844539512554\n",
      "epoch : 4 , phase : valid , loss : 0.7177247682844596\n",
      "epoch : 5 , phase : train , loss : 0.7036943713799233\n",
      "epoch : 5 , phase : valid , loss : 0.6850489927572441\n",
      "epoch : 6 , phase : train , loss : 0.6719609167035114\n",
      "epoch : 6 , phase : valid , loss : 0.6545516308790982\n",
      "epoch : 7 , phase : train , loss : 0.6423258949765303\n",
      "epoch : 7 , phase : valid , loss : 0.626070957784818\n",
      "epoch : 8 , phase : train , loss : 0.61464486179801\n",
      "epoch : 8 , phase : valid , loss : 0.5994407061490827\n",
      "epoch : 9 , phase : train , loss : 0.5887580989127869\n",
      "epoch : 9 , phase : valid , loss : 0.5745361090527255\n",
      "epoch : 10 , phase : train , loss : 0.5645401599860316\n",
      "epoch : 10 , phase : valid , loss : 0.5512220014817106\n",
      "epoch : 11 , phase : train , loss : 0.5418727210472122\n",
      "epoch : 11 , phase : valid , loss : 0.5293795896730884\n",
      "epoch : 12 , phase : train , loss : 0.5206066811567551\n",
      "epoch : 12 , phase : valid , loss : 0.5088978669383953\n",
      "epoch : 13 , phase : train , loss : 0.5006761253294832\n",
      "epoch : 13 , phase : valid , loss : 0.48967452317760385\n",
      "epoch : 14 , phase : train , loss : 0.4819479346407019\n",
      "epoch : 14 , phase : valid , loss : 0.47161393679495295\n",
      "epoch : 15 , phase : train , loss : 0.4643548975088721\n",
      "epoch : 15 , phase : valid , loss : 0.454645073729084\n",
      "epoch : 16 , phase : train , loss : 0.447796676735387\n",
      "epoch : 16 , phase : valid , loss : 0.43863882387624137\n",
      "epoch : 17 , phase : train , loss : 0.43220172516501876\n",
      "epoch : 17 , phase : valid , loss : 0.42357086284791257\n",
      "epoch : 18 , phase : train , loss : 0.41750253063003845\n",
      "epoch : 18 , phase : valid , loss : 0.40935865991765075\n",
      "epoch : 19 , phase : train , loss : 0.40363157332069527\n",
      "epoch : 19 , phase : valid , loss : 0.39593489572432794\n",
      "epoch : 20 , phase : train , loss : 0.3905298746602459\n",
      "epoch : 20 , phase : valid , loss : 0.3832470994884812\n",
      "epoch : 21 , phase : train , loss : 0.3781357635329405\n",
      "epoch : 21 , phase : valid , loss : 0.371247861518101\n",
      "epoch : 22 , phase : train , loss : 0.36640425135657095\n",
      "epoch : 22 , phase : valid , loss : 0.3598751023765252\n",
      "epoch : 23 , phase : train , loss : 0.35529122583409306\n",
      "epoch : 23 , phase : valid , loss : 0.34910251769403183\n",
      "epoch : 24 , phase : train , loss : 0.3447521849253519\n",
      "epoch : 24 , phase : valid , loss : 0.33887216683339044\n",
      "epoch : 25 , phase : train , loss : 0.3347477212713781\n",
      "epoch : 25 , phase : valid , loss : 0.3291595465690763\n",
      "epoch : 26 , phase : train , loss : 0.32524160914160244\n",
      "epoch : 26 , phase : valid , loss : 0.3199259565715878\n",
      "epoch : 27 , phase : train , loss : 0.3162029671260194\n",
      "epoch : 27 , phase : valid , loss : 0.31114151828576775\n",
      "epoch : 28 , phase : train , loss : 0.30759696798404523\n",
      "epoch : 28 , phase : valid , loss : 0.3027730242332123\n",
      "epoch : 29 , phase : train , loss : 0.2993975345900322\n",
      "epoch : 29 , phase : valid , loss : 0.29479857454433556\n",
      "epoch : 30 , phase : train , loss : 0.29158072958443054\n",
      "epoch : 30 , phase : valid , loss : 0.287192615964868\n",
      "epoch : 31 , phase : train , loss : 0.28412106937195053\n",
      "epoch : 31 , phase : valid , loss : 0.2799277787674561\n",
      "epoch : 32 , phase : train , loss : 0.276997489993231\n",
      "epoch : 32 , phase : valid , loss : 0.2729872522729265\n",
      "epoch : 33 , phase : train , loss : 0.270187287001569\n",
      "epoch : 33 , phase : valid , loss : 0.266354223247291\n",
      "epoch : 34 , phase : train , loss : 0.26367416505919283\n",
      "epoch : 34 , phase : valid , loss : 0.2600015416772402\n",
      "epoch : 35 , phase : train , loss : 0.2574397298196825\n",
      "epoch : 35 , phase : valid , loss : 0.2539199489151563\n",
      "epoch : 36 , phase : train , loss : 0.2514662186770849\n",
      "epoch : 36 , phase : valid , loss : 0.2480901663310935\n",
      "epoch : 37 , phase : train , loss : 0.24574240804874853\n",
      "epoch : 37 , phase : valid , loss : 0.24250201554422698\n",
      "epoch : 38 , phase : train , loss : 0.24024731294287044\n",
      "epoch : 38 , phase : valid , loss : 0.23713702269116715\n",
      "epoch : 39 , phase : train , loss : 0.23497422621167005\n",
      "epoch : 39 , phase : valid , loss : 0.23198581415764538\n",
      "epoch : 40 , phase : train , loss : 0.2299092049864131\n",
      "epoch : 40 , phase : valid , loss : 0.227034821324043\n",
      "epoch : 41 , phase : train , loss : 0.22503981824500705\n",
      "epoch : 41 , phase : valid , loss : 0.2222752070871289\n",
      "epoch : 42 , phase : train , loss : 0.22035853986967072\n",
      "epoch : 42 , phase : valid , loss : 0.2176965810164777\n",
      "epoch : 43 , phase : train , loss : 0.21585109074271158\n",
      "epoch : 43 , phase : valid , loss : 0.21328635554122496\n",
      "epoch : 44 , phase : train , loss : 0.21151200681855828\n",
      "epoch : 44 , phase : valid , loss : 0.20903937376837503\n",
      "epoch : 45 , phase : train , loss : 0.20732956523580304\n",
      "epoch : 45 , phase : valid , loss : 0.20494592612555723\n",
      "epoch : 46 , phase : train , loss : 0.2032993552742096\n",
      "epoch : 46 , phase : valid , loss : 0.2009984810197315\n",
      "epoch : 47 , phase : train , loss : 0.19941093411101807\n",
      "epoch : 47 , phase : valid , loss : 0.19718930119529346\n",
      "epoch : 48 , phase : train , loss : 0.19565751817823004\n",
      "epoch : 48 , phase : valid , loss : 0.19351301004520347\n",
      "epoch : 49 , phase : train , loss : 0.19203465217714882\n",
      "epoch : 49 , phase : valid , loss : 0.1899609160906548\n",
      "epoch : 50 , phase : train , loss : 0.18853416041814208\n",
      "epoch : 50 , phase : valid , loss : 0.18652873107556953\n",
      "epoch : 51 , phase : train , loss : 0.18515070877000864\n",
      "epoch : 51 , phase : valid , loss : 0.18321007818304538\n",
      "epoch : 52 , phase : train , loss : 0.1818776512211421\n",
      "epoch : 52 , phase : valid , loss : 0.18000109325620545\n",
      "epoch : 53 , phase : train , loss : 0.17871274611182084\n",
      "epoch : 53 , phase : valid , loss : 0.17689410035499248\n",
      "epoch : 54 , phase : train , loss : 0.17564767510133933\n",
      "epoch : 54 , phase : valid , loss : 0.1738875614810991\n",
      "epoch : 55 , phase : train , loss : 0.1726801417621532\n",
      "epoch : 55 , phase : valid , loss : 0.1709734915619179\n",
      "epoch : 56 , phase : train , loss : 0.1698052883157522\n",
      "epoch : 56 , phase : valid , loss : 0.1681497215599689\n",
      "epoch : 57 , phase : train , loss : 0.16701965547361133\n",
      "epoch : 57 , phase : valid , loss : 0.16541300813828994\n",
      "epoch : 58 , phase : train , loss : 0.16431735378428028\n",
      "epoch : 58 , phase : valid , loss : 0.16275908092450436\n",
      "epoch : 59 , phase : train , loss : 0.16169665360349653\n",
      "epoch : 59 , phase : valid , loss : 0.16018389436990835\n",
      "epoch : 60 , phase : train , loss : 0.1591535683432325\n",
      "epoch : 60 , phase : valid , loss : 0.15768402630052727\n",
      "epoch : 61 , phase : train , loss : 0.15668436742319014\n",
      "epoch : 61 , phase : valid , loss : 0.15525667663970855\n",
      "epoch : 62 , phase : train , loss : 0.1542869340033369\n",
      "epoch : 62 , phase : valid , loss : 0.152899615034425\n",
      "epoch : 63 , phase : train , loss : 0.1519581412230952\n",
      "epoch : 63 , phase : valid , loss : 0.15060851490638177\n",
      "epoch : 64 , phase : train , loss : 0.1496946393295856\n",
      "epoch : 64 , phase : valid , loss : 0.148381840812086\n",
      "epoch : 65 , phase : train , loss : 0.14749352308086214\n",
      "epoch : 65 , phase : valid , loss : 0.14621614502941838\n",
      "epoch : 66 , phase : train , loss : 0.14535325770421764\n",
      "epoch : 66 , phase : valid , loss : 0.14411066750107587\n",
      "epoch : 67 , phase : train , loss : 0.14327070360237162\n",
      "epoch : 67 , phase : valid , loss : 0.1420613435172462\n",
      "epoch : 68 , phase : train , loss : 0.14124426104543183\n",
      "epoch : 68 , phase : valid , loss : 0.14006535256276095\n",
      "epoch : 69 , phase : train , loss : 0.1392714400079689\n",
      "epoch : 69 , phase : valid , loss : 0.13812303059572223\n",
      "epoch : 70 , phase : train , loss : 0.13734997335685528\n",
      "epoch : 70 , phase : valid , loss : 0.13623135143839732\n",
      "epoch : 71 , phase : train , loss : 0.1354789020183578\n",
      "epoch : 71 , phase : valid , loss : 0.13438755589116508\n",
      "epoch : 72 , phase : train , loss : 0.13365521121488502\n",
      "epoch : 72 , phase : valid , loss : 0.132591178977793\n",
      "epoch : 73 , phase : train , loss : 0.13187803994531655\n",
      "epoch : 73 , phase : valid , loss : 0.13083975530232325\n",
      "epoch : 74 , phase : train , loss : 0.1301447568068201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 74 , phase : valid , loss : 0.1291319895738226\n",
      "epoch : 75 , phase : train , loss : 0.12845528792651856\n",
      "epoch : 75 , phase : valid , loss : 0.12746629014287994\n",
      "epoch : 76 , phase : train , loss : 0.1268065752220303\n",
      "epoch : 76 , phase : valid , loss : 0.1258409210130669\n",
      "epoch : 77 , phase : train , loss : 0.12519721765602929\n",
      "epoch : 77 , phase : valid , loss : 0.12425487814229916\n",
      "epoch : 78 , phase : train , loss : 0.12362710187185923\n",
      "epoch : 78 , phase : valid , loss : 0.1227066388611561\n",
      "epoch : 79 , phase : train , loss : 0.12209401040953412\n",
      "epoch : 79 , phase : valid , loss : 0.12119471499021241\n",
      "epoch : 80 , phase : train , loss : 0.12059681224983078\n",
      "epoch : 80 , phase : valid , loss : 0.11971755447968117\n",
      "epoch : 81 , phase : train , loss : 0.11913438656288843\n",
      "epoch : 81 , phase : valid , loss : 0.11827500915032349\n",
      "epoch : 82 , phase : train , loss : 0.11770522532307615\n",
      "epoch : 82 , phase : valid , loss : 0.11686482182356034\n",
      "epoch : 83 , phase : train , loss : 0.11630877575748536\n",
      "epoch : 83 , phase : valid , loss : 0.11548713301418727\n",
      "epoch : 84 , phase : train , loss : 0.11494362281841676\n",
      "epoch : 84 , phase : valid , loss : 0.11413989120618963\n",
      "epoch : 85 , phase : train , loss : 0.11360892524663962\n",
      "epoch : 85 , phase : valid , loss : 0.1128221983822833\n",
      "epoch : 86 , phase : train , loss : 0.1123037793730787\n",
      "epoch : 86 , phase : valid , loss : 0.11153383866064608\n",
      "epoch : 87 , phase : train , loss : 0.11102674403979362\n",
      "epoch : 87 , phase : valid , loss : 0.11027364321366065\n",
      "epoch : 88 , phase : train , loss : 0.10977746707694745\n",
      "epoch : 88 , phase : valid , loss : 0.10903988243193484\n",
      "epoch : 89 , phase : train , loss : 0.10855481046013041\n",
      "epoch : 89 , phase : valid , loss : 0.10783222674440279\n",
      "epoch : 90 , phase : train , loss : 0.1073581927588522\n",
      "epoch : 90 , phase : valid , loss : 0.10665013261428727\n",
      "epoch : 91 , phase : train , loss : 0.10618670075151031\n",
      "epoch : 91 , phase : valid , loss : 0.1054929223770517\n",
      "epoch : 92 , phase : train , loss : 0.10503932441755974\n",
      "epoch : 92 , phase : valid , loss : 0.1043596041259804\n",
      "epoch : 93 , phase : train , loss : 0.10391565108782448\n",
      "epoch : 93 , phase : valid , loss : 0.10324939225562565\n",
      "epoch : 94 , phase : train , loss : 0.10281508468460582\n",
      "epoch : 94 , phase : valid , loss : 0.10216186713771178\n",
      "epoch : 95 , phase : train , loss : 0.10173635281127769\n",
      "epoch : 95 , phase : valid , loss : 0.10109598576923379\n",
      "epoch : 96 , phase : train , loss : 0.10067924722274664\n",
      "epoch : 96 , phase : valid , loss : 0.10005184523314133\n",
      "epoch : 97 , phase : train , loss : 0.09964353101633754\n",
      "epoch : 97 , phase : valid , loss : 0.09902769356541567\n",
      "epoch : 98 , phase : train , loss : 0.09862765540897003\n",
      "epoch : 98 , phase : valid , loss : 0.09802327464590681\n",
      "epoch : 99 , phase : train , loss : 0.09763187195052762\n",
      "epoch : 99 , phase : valid , loss : 0.09703903237362783\n",
      "epoch : 100 , phase : train , loss : 0.09665504006925994\n",
      "epoch : 100 , phase : valid , loss : 0.09607311003716704\n",
      "epoch : 101 , phase : train , loss : 0.09569705532420268\n",
      "epoch : 101 , phase : valid , loss : 0.09512601221238103\n",
      "epoch : 102 , phase : train , loss : 0.09475738468433681\n",
      "epoch : 102 , phase : valid , loss : 0.09419642508593169\n",
      "epoch : 103 , phase : train , loss : 0.09383518243258555\n",
      "epoch : 103 , phase : valid , loss : 0.09328450897242664\n",
      "epoch : 104 , phase : train , loss : 0.09293003080509168\n",
      "epoch : 104 , phase : valid , loss : 0.09238919787553075\n",
      "epoch : 105 , phase : train , loss : 0.09204178651394687\n",
      "epoch : 105 , phase : valid , loss : 0.09151066680003479\n",
      "epoch : 106 , phase : train , loss : 0.09116975158782872\n",
      "epoch : 106 , phase : valid , loss : 0.09064793980681352\n",
      "epoch : 107 , phase : train , loss : 0.09031364518243687\n",
      "epoch : 107 , phase : valid , loss : 0.08980091023236303\n",
      "epoch : 108 , phase : train , loss : 0.0894728431993261\n",
      "epoch : 108 , phase : valid , loss : 0.08896897322435898\n",
      "epoch : 109 , phase : train , loss : 0.088647073073053\n",
      "epoch : 109 , phase : valid , loss : 0.08815196527467567\n",
      "epoch : 110 , phase : train , loss : 0.08783595333936381\n",
      "epoch : 110 , phase : valid , loss : 0.08734916975785591\n",
      "epoch : 111 , phase : train , loss : 0.08703909425514783\n",
      "epoch : 111 , phase : valid , loss : 0.08656097500569826\n",
      "epoch : 112 , phase : train , loss : 0.08625614301373298\n",
      "epoch : 112 , phase : valid , loss : 0.08578592285784735\n",
      "epoch : 113 , phase : train , loss : 0.08548657104194626\n",
      "epoch : 113 , phase : valid , loss : 0.08502394816653433\n",
      "epoch : 114 , phase : train , loss : 0.08473038661864461\n",
      "epoch : 114 , phase : valid , loss : 0.08427519208525837\n",
      "epoch : 115 , phase : train , loss : 0.0839870885545664\n",
      "epoch : 115 , phase : valid , loss : 0.08353931290758489\n",
      "epoch : 116 , phase : train , loss : 0.08325596996269716\n",
      "epoch : 116 , phase : valid , loss : 0.08281564893656768\n",
      "epoch : 117 , phase : train , loss : 0.0825372320829437\n",
      "epoch : 117 , phase : valid , loss : 0.08210382397577692\n",
      "epoch : 118 , phase : train , loss : 0.08183062336542249\n",
      "epoch : 118 , phase : valid , loss : 0.08140425318256303\n",
      "epoch : 119 , phase : train , loss : 0.08113566236276151\n",
      "epoch : 119 , phase : valid , loss : 0.08071586672836918\n",
      "epoch : 120 , phase : train , loss : 0.08045178611268979\n",
      "epoch : 120 , phase : valid , loss : 0.08003864736819774\n",
      "epoch : 121 , phase : train , loss : 0.07977931430645167\n",
      "epoch : 121 , phase : valid , loss : 0.07937262256630417\n",
      "epoch : 122 , phase : train , loss : 0.07911753241501093\n",
      "epoch : 122 , phase : valid , loss : 0.07871725836646554\n",
      "epoch : 123 , phase : train , loss : 0.07846624556681223\n",
      "epoch : 123 , phase : valid , loss : 0.07807188285247774\n",
      "epoch : 124 , phase : train , loss : 0.07782537734163775\n",
      "epoch : 124 , phase : valid , loss : 0.07743709832185071\n",
      "epoch : 125 , phase : train , loss : 0.07719457429598027\n",
      "epoch : 125 , phase : valid , loss : 0.07681229800614921\n",
      "epoch : 126 , phase : train , loss : 0.0765736804052285\n",
      "epoch : 126 , phase : valid , loss : 0.07619692112359841\n",
      "epoch : 127 , phase : train , loss : 0.07596238998851129\n",
      "epoch : 127 , phase : valid , loss : 0.07559134834155343\n",
      "epoch : 128 , phase : train , loss : 0.07536059032600742\n",
      "epoch : 128 , phase : valid , loss : 0.07499502079435028\n",
      "epoch : 129 , phase : train , loss : 0.07476791014282551\n",
      "epoch : 129 , phase : valid , loss : 0.07440760060777606\n",
      "epoch : 130 , phase : train , loss : 0.0741842494558473\n",
      "epoch : 130 , phase : valid , loss : 0.07382925959310349\n",
      "epoch : 131 , phase : train , loss : 0.07360939237795752\n",
      "epoch : 131 , phase : valid , loss : 0.07325953660632181\n",
      "epoch : 132 , phase : train , loss : 0.07304316123214986\n",
      "epoch : 132 , phase : valid , loss : 0.07269850956927218\n",
      "epoch : 133 , phase : train , loss : 0.07248560887574163\n",
      "epoch : 133 , phase : valid , loss : 0.07214541650854069\n",
      "epoch : 134 , phase : train , loss : 0.0719357545826046\n",
      "epoch : 134 , phase : valid , loss : 0.07160048288650378\n",
      "epoch : 135 , phase : train , loss : 0.07139426702964435\n",
      "epoch : 135 , phase : valid , loss : 0.0710635905429925\n",
      "epoch : 136 , phase : train , loss : 0.0708605775230736\n",
      "epoch : 136 , phase : valid , loss : 0.07053463856283552\n",
      "epoch : 137 , phase : train , loss : 0.07033465995265126\n",
      "epoch : 137 , phase : valid , loss : 0.07001330184589229\n",
      "epoch : 138 , phase : train , loss : 0.06981618953245174\n",
      "epoch : 138 , phase : valid , loss : 0.06949911286111587\n",
      "epoch : 139 , phase : train , loss : 0.06930529426633983\n",
      "epoch : 139 , phase : valid , loss : 0.06899244525012165\n",
      "epoch : 140 , phase : train , loss : 0.06880152200136032\n",
      "epoch : 140 , phase : valid , loss : 0.06849301287368964\n",
      "epoch : 141 , phase : train , loss : 0.06830485044828304\n",
      "epoch : 141 , phase : valid , loss : 0.06800046061260935\n",
      "epoch : 142 , phase : train , loss : 0.06781515478741892\n",
      "epoch : 142 , phase : valid , loss : 0.0675147693057723\n",
      "epoch : 143 , phase : train , loss : 0.06733220894229039\n",
      "epoch : 143 , phase : valid , loss : 0.06703589743744343\n",
      "epoch : 144 , phase : train , loss : 0.0668559848921509\n",
      "epoch : 144 , phase : valid , loss : 0.06656368852523682\n",
      "epoch : 145 , phase : train , loss : 0.06638631642302678\n",
      "epoch : 145 , phase : valid , loss : 0.06609788581029885\n",
      "epoch : 146 , phase : train , loss : 0.06592291632226621\n",
      "epoch : 146 , phase : valid , loss : 0.065638054335467\n",
      "epoch : 147 , phase : train , loss : 0.06546589667285528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 147 , phase : valid , loss : 0.06518460989679531\n",
      "epoch : 148 , phase : train , loss : 0.0650149607096149\n",
      "epoch : 148 , phase : valid , loss : 0.06473739026356529\n",
      "epoch : 149 , phase : train , loss : 0.06457008741698522\n",
      "epoch : 149 , phase : valid , loss : 0.06429603903915922\n",
      "epoch : 150 , phase : train , loss : 0.06413119018538607\n",
      "epoch : 150 , phase : valid , loss : 0.06386056197190963\n",
      "epoch : 151 , phase : train , loss : 0.06369796906546266\n",
      "epoch : 151 , phase : valid , loss : 0.06343087347553199\n",
      "epoch : 152 , phase : train , loss : 0.06327043297290706\n",
      "epoch : 152 , phase : valid , loss : 0.06300655456045419\n",
      "epoch : 153 , phase : train , loss : 0.06284857490253264\n",
      "epoch : 153 , phase : valid , loss : 0.062587931604224\n",
      "epoch : 154 , phase : train , loss : 0.06243196753795497\n",
      "epoch : 154 , phase : valid , loss : 0.06217476126076374\n",
      "epoch : 155 , phase : train , loss : 0.06202088217094718\n",
      "epoch : 155 , phase : valid , loss : 0.06176666414012548\n",
      "epoch : 156 , phase : train , loss : 0.06161503349936288\n",
      "epoch : 156 , phase : valid , loss : 0.0613638823109797\n",
      "epoch : 157 , phase : train , loss : 0.061214355292346666\n",
      "epoch : 157 , phase : valid , loss : 0.0609662126655765\n",
      "epoch : 158 , phase : train , loss : 0.060818750114120856\n",
      "epoch : 158 , phase : valid , loss : 0.06057367244891352\n",
      "epoch : 159 , phase : train , loss : 0.06042809696600731\n",
      "epoch : 159 , phase : valid , loss : 0.060185829897346325\n",
      "epoch : 160 , phase : train , loss : 0.06004225701794371\n",
      "epoch : 160 , phase : valid , loss : 0.05980287342844165\n",
      "epoch : 161 , phase : train , loss : 0.05966120256760112\n",
      "epoch : 161 , phase : valid , loss : 0.05942472639776556\n",
      "epoch : 162 , phase : train , loss : 0.059284914828342666\n",
      "epoch : 162 , phase : valid , loss : 0.05905119783293688\n",
      "epoch : 163 , phase : train , loss : 0.058913237138721895\n",
      "epoch : 163 , phase : valid , loss : 0.05868223152803739\n",
      "epoch : 164 , phase : train , loss : 0.058546047544807925\n",
      "epoch : 164 , phase : valid , loss : 0.05831764864605461\n",
      "epoch : 165 , phase : train , loss : 0.05818343201934577\n",
      "epoch : 165 , phase : valid , loss : 0.05795777109361102\n",
      "epoch : 166 , phase : train , loss : 0.05782510876278235\n",
      "epoch : 166 , phase : valid , loss : 0.0576019608057942\n",
      "epoch : 167 , phase : train , loss : 0.05747101504685558\n",
      "epoch : 167 , phase : valid , loss : 0.05725037745850818\n",
      "epoch : 168 , phase : train , loss : 0.057121262954551534\n",
      "epoch : 168 , phase : valid , loss : 0.05690309961229771\n",
      "epoch : 169 , phase : train , loss : 0.05677554011823002\n",
      "epoch : 169 , phase : valid , loss : 0.05655987497923447\n",
      "epoch : 170 , phase : train , loss : 0.05643401784654592\n",
      "epoch : 170 , phase : valid , loss : 0.056220677372470204\n",
      "epoch : 171 , phase : train , loss : 0.056096378358760274\n",
      "epoch : 171 , phase : valid , loss : 0.05588543653460715\n",
      "epoch : 172 , phase : train , loss : 0.05576273246418888\n",
      "epoch : 172 , phase : valid , loss : 0.055554207394156285\n",
      "epoch : 173 , phase : train , loss : 0.05543294674586817\n",
      "epoch : 173 , phase : valid , loss : 0.055226632915796256\n",
      "epoch : 174 , phase : train , loss : 0.05510693427580044\n",
      "epoch : 174 , phase : valid , loss : 0.054902840201546656\n",
      "epoch : 175 , phase : train , loss : 0.05478470301442504\n",
      "epoch : 175 , phase : valid , loss : 0.05458282861270386\n",
      "epoch : 176 , phase : train , loss : 0.05446615711805216\n",
      "epoch : 176 , phase : valid , loss : 0.05426648477937603\n",
      "epoch : 177 , phase : train , loss : 0.054151148204092274\n",
      "epoch : 177 , phase : valid , loss : 0.05395355673298665\n",
      "epoch : 178 , phase : train , loss : 0.05383968486981989\n",
      "epoch : 178 , phase : valid , loss : 0.053644285264798953\n",
      "epoch : 179 , phase : train , loss : 0.05353179832015727\n",
      "epoch : 179 , phase : valid , loss : 0.0533384691831739\n",
      "epoch : 180 , phase : train , loss : 0.0532273054649993\n",
      "epoch : 180 , phase : valid , loss : 0.053035968612019584\n",
      "epoch : 181 , phase : train , loss : 0.05292619165713758\n",
      "epoch : 181 , phase : valid , loss : 0.05273681644457222\n",
      "epoch : 182 , phase : train , loss : 0.05262839830773847\n",
      "epoch : 182 , phase : valid , loss : 0.05244099926805588\n",
      "epoch : 183 , phase : train , loss : 0.05233385854911142\n",
      "epoch : 183 , phase : valid , loss : 0.052148451615349915\n",
      "epoch : 184 , phase : train , loss : 0.052042601994090824\n",
      "epoch : 184 , phase : valid , loss : 0.051859095883964985\n",
      "epoch : 185 , phase : train , loss : 0.051754460836615127\n",
      "epoch : 185 , phase : valid , loss : 0.05157286117779972\n",
      "epoch : 186 , phase : train , loss : 0.05146948984450707\n",
      "epoch : 186 , phase : valid , loss : 0.0512896995940829\n",
      "epoch : 187 , phase : train , loss : 0.05118747504115687\n",
      "epoch : 187 , phase : valid , loss : 0.05100959452652053\n",
      "epoch : 188 , phase : train , loss : 0.05090847565223331\n",
      "epoch : 188 , phase : valid , loss : 0.05073233232875304\n",
      "epoch : 189 , phase : train , loss : 0.05063252542999924\n",
      "epoch : 189 , phase : valid , loss : 0.05045817007898587\n",
      "epoch : 190 , phase : train , loss : 0.05035943618966838\n",
      "epoch : 190 , phase : valid , loss : 0.050186809183278544\n",
      "epoch : 191 , phase : train , loss : 0.05008926269906346\n",
      "epoch : 191 , phase : valid , loss : 0.0499182668866287\n",
      "epoch : 192 , phase : train , loss : 0.04982193267739517\n",
      "epoch : 192 , phase : valid , loss : 0.049652603227176226\n",
      "epoch : 193 , phase : train , loss : 0.04955737129653359\n",
      "epoch : 193 , phase : valid , loss : 0.04938977764724152\n",
      "epoch : 194 , phase : train , loss : 0.049295522196568124\n",
      "epoch : 194 , phase : valid , loss : 0.0491295359427854\n",
      "epoch : 195 , phase : train , loss : 0.04903642454286037\n",
      "epoch : 195 , phase : valid , loss : 0.04887204130258176\n",
      "epoch : 196 , phase : train , loss : 0.048779947784204955\n",
      "epoch : 196 , phase : valid , loss : 0.04861718355025684\n",
      "epoch : 197 , phase : train , loss : 0.04852616197246818\n",
      "epoch : 197 , phase : valid , loss : 0.048364918934612935\n",
      "epoch : 198 , phase : train , loss : 0.04827487892286376\n",
      "epoch : 198 , phase : valid , loss : 0.04811522957194881\n",
      "epoch : 199 , phase : train , loss : 0.04802617473719189\n",
      "epoch : 199 , phase : valid , loss : 0.047868039456534145\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.04802617473719189\n",
      "(compare com a entropia do dataset de treino).\n",
      "comprimento médio de código final no dataset de validação: 0.047868039456534145\n",
      "(compare com a entropia do dataset de validação).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "271db70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.8337, 6.4164, 6.6655, 6.8767, 6.7930]], device='cuda:0')\n",
      "tensor([23.5015], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41bac832",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241m.\u001b[39mT, C0\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
