{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "X = (X > 0).astype(int)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)).astype(int) # signal \n",
    "yt = yy[0:L] > 0 # train on the first part \n",
    "yc = yy[L:L+L] > 0 # encode the second part\n",
    "Xt = X[0:L,0:N] # truncated X for training \n",
    "Xc = X[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bbecba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1, -1, -1, -1],\n",
       "       [ 0, -1, -1, -1, -1],\n",
       "       [ 1, -1, -1, -1, -1],\n",
       "       ...,\n",
       "       [-1, -1,  1, -1, -1],\n",
       "       [ 1, -1, -1, -1, -1],\n",
       "       [-1, -1,  0, -1, -1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "204fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "L = 100000 # how many samples \n",
    "N = 5 # order of the AR\n",
    "my_data = genfromtxt('../SPIHT_dataset/SPIHT_bits_with_context_ricardo14.csv', delimiter=',')\n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(int)\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "\n",
    "\n",
    "yt = bitstream[0:L] > 0 # train on the first part \n",
    "yc = bitstream[L:L+L] > 0 # encode the second part\n",
    "Xt = context[0:L,0:N] # truncated X for training \n",
    "Xc = context[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a0aa3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.203426503814918e-16"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.203426503814918e-16"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc,context_coding(Xc,context_training(Xc,yc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.003491003723144531\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0901, 11.7186, 11.9979, 12.1763, 12.1026]], device='cuda:0')\n",
      "tensor([41.8704], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32098451, 0.77295341, 0.82311742, 0.86189127, 0.7005142 ,\n",
       "         0.80153656, 0.21184858]]),\n",
       " array([[0.2792105]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : train , loss : 0.946118046875\n",
      "epoch : 0 , phase : valid , loss : 0.947739296875\n",
      "epoch : 1 , phase : train , loss : 0.9273425\n",
      "epoch : 1 , phase : valid , loss : 0.931678828125\n",
      "epoch : 2 , phase : train , loss : 0.916495546875\n",
      "epoch : 2 , phase : valid , loss : 0.92316109375\n",
      "epoch : 3 , phase : train , loss : 0.90713515625\n",
      "epoch : 3 , phase : valid , loss : 0.913988203125\n",
      "epoch : 4 , phase : train , loss : 0.89854734375\n",
      "epoch : 4 , phase : valid , loss : 0.905899296875\n",
      "epoch : 5 , phase : train , loss : 0.890542890625\n",
      "epoch : 5 , phase : valid , loss : 0.898238828125\n",
      "epoch : 6 , phase : train , loss : 0.8830028125\n",
      "epoch : 6 , phase : valid , loss : 0.891033046875\n",
      "epoch : 7 , phase : train , loss : 0.875839609375\n",
      "epoch : 7 , phase : valid , loss : 0.884167734375\n",
      "epoch : 8 , phase : train , loss : 0.86898640625\n",
      "epoch : 8 , phase : valid , loss : 0.877589609375\n",
      "epoch : 9 , phase : train , loss : 0.862392265625\n",
      "epoch : 9 , phase : valid , loss : 0.87124703125\n",
      "epoch : 10 , phase : train , loss : 0.856016328125\n",
      "epoch : 10 , phase : valid , loss : 0.8651034375\n",
      "epoch : 11 , phase : train , loss : 0.849827734375\n",
      "epoch : 11 , phase : valid , loss : 0.859129140625\n",
      "epoch : 12 , phase : train , loss : 0.843801875\n",
      "epoch : 12 , phase : valid , loss : 0.85329921875\n",
      "epoch : 13 , phase : train , loss : 0.8379178125\n",
      "epoch : 13 , phase : valid , loss : 0.8475953125\n",
      "epoch : 14 , phase : train , loss : 0.83216\n",
      "epoch : 14 , phase : valid , loss : 0.842002421875\n",
      "epoch : 15 , phase : train , loss : 0.826515625\n",
      "epoch : 15 , phase : valid , loss : 0.836506953125\n",
      "epoch : 16 , phase : train , loss : 0.82097296875\n",
      "epoch : 16 , phase : valid , loss : 0.831098984375\n",
      "epoch : 17 , phase : train , loss : 0.815523359375\n",
      "epoch : 17 , phase : valid , loss : 0.825770546875\n",
      "epoch : 18 , phase : train , loss : 0.810159609375\n",
      "epoch : 18 , phase : valid , loss : 0.820514296875\n",
      "epoch : 19 , phase : train , loss : 0.8048753125\n",
      "epoch : 19 , phase : valid , loss : 0.815324765625\n",
      "epoch : 20 , phase : train , loss : 0.799664765625\n",
      "epoch : 20 , phase : valid , loss : 0.810196484375\n",
      "epoch : 21 , phase : train , loss : 0.794523515625\n",
      "epoch : 21 , phase : valid , loss : 0.80512546875\n",
      "epoch : 22 , phase : train , loss : 0.789447265625\n",
      "epoch : 22 , phase : valid , loss : 0.800108984375\n",
      "epoch : 23 , phase : train , loss : 0.78443296875\n",
      "epoch : 23 , phase : valid , loss : 0.795143359375\n",
      "epoch : 24 , phase : train , loss : 0.77947765625\n",
      "epoch : 24 , phase : valid , loss : 0.79022671875\n",
      "epoch : 25 , phase : train , loss : 0.77457859375\n",
      "epoch : 25 , phase : valid , loss : 0.785356640625\n",
      "epoch : 26 , phase : train , loss : 0.76973328125\n",
      "epoch : 26 , phase : valid , loss : 0.78053125\n",
      "epoch : 27 , phase : train , loss : 0.76493984375\n",
      "epoch : 27 , phase : valid , loss : 0.77574890625\n",
      "epoch : 28 , phase : train , loss : 0.760196171875\n",
      "epoch : 28 , phase : valid , loss : 0.77100859375\n",
      "epoch : 29 , phase : train , loss : 0.75550078125\n",
      "epoch : 29 , phase : valid , loss : 0.766309140625\n",
      "epoch : 30 , phase : train , loss : 0.750852265625\n",
      "epoch : 30 , phase : valid , loss : 0.761649453125\n",
      "epoch : 31 , phase : train , loss : 0.74624953125\n",
      "epoch : 31 , phase : valid , loss : 0.7570284375\n",
      "epoch : 32 , phase : train , loss : 0.74169078125\n",
      "epoch : 32 , phase : valid , loss : 0.752445703125\n",
      "epoch : 33 , phase : train , loss : 0.73717546875\n",
      "epoch : 33 , phase : valid , loss : 0.74790046875\n",
      "epoch : 34 , phase : train , loss : 0.732702109375\n",
      "epoch : 34 , phase : valid , loss : 0.743392265625\n",
      "epoch : 35 , phase : train , loss : 0.728270390625\n",
      "epoch : 35 , phase : valid , loss : 0.738920234375\n",
      "epoch : 36 , phase : train , loss : 0.72387921875\n",
      "epoch : 36 , phase : valid , loss : 0.73448453125\n",
      "epoch : 37 , phase : train , loss : 0.71952765625\n",
      "epoch : 37 , phase : valid , loss : 0.730084296875\n",
      "epoch : 38 , phase : train , loss : 0.715215078125\n",
      "epoch : 38 , phase : valid , loss : 0.725719140625\n",
      "epoch : 39 , phase : train , loss : 0.7109409375\n",
      "epoch : 39 , phase : valid , loss : 0.721389140625\n",
      "epoch : 40 , phase : train , loss : 0.706704765625\n",
      "epoch : 40 , phase : valid , loss : 0.71709359375\n",
      "epoch : 41 , phase : train , loss : 0.702505546875\n",
      "epoch : 41 , phase : valid , loss : 0.712832578125\n",
      "epoch : 42 , phase : train , loss : 0.698343046875\n",
      "epoch : 42 , phase : valid , loss : 0.70860578125\n",
      "epoch : 43 , phase : train , loss : 0.69421703125\n",
      "epoch : 43 , phase : valid , loss : 0.704412421875\n",
      "epoch : 44 , phase : train , loss : 0.690126328125\n",
      "epoch : 44 , phase : valid , loss : 0.7002528125\n",
      "epoch : 45 , phase : train , loss : 0.686071171875\n",
      "epoch : 45 , phase : valid , loss : 0.696127265625\n",
      "epoch : 46 , phase : train , loss : 0.682051015625\n",
      "epoch : 46 , phase : valid , loss : 0.69203453125\n",
      "epoch : 47 , phase : train , loss : 0.678065\n",
      "epoch : 47 , phase : valid , loss : 0.687974921875\n",
      "epoch : 48 , phase : train , loss : 0.674113203125\n",
      "epoch : 48 , phase : valid , loss : 0.683948359375\n",
      "epoch : 49 , phase : train , loss : 0.670195078125\n",
      "epoch : 49 , phase : valid , loss : 0.679954296875\n",
      "epoch : 50 , phase : train , loss : 0.666310390625\n",
      "epoch : 50 , phase : valid , loss : 0.675992734375\n",
      "epoch : 51 , phase : train , loss : 0.66245859375\n",
      "epoch : 51 , phase : valid , loss : 0.67206328125\n",
      "epoch : 52 , phase : train , loss : 0.658639296875\n",
      "epoch : 52 , phase : valid , loss : 0.668166484375\n",
      "epoch : 53 , phase : train , loss : 0.654852578125\n",
      "epoch : 53 , phase : valid , loss : 0.66430140625\n",
      "epoch : 54 , phase : train , loss : 0.6510976953125\n",
      "epoch : 54 , phase : valid , loss : 0.66046796875\n",
      "epoch : 55 , phase : train , loss : 0.6473747265625\n",
      "epoch : 55 , phase : valid , loss : 0.656666015625\n",
      "epoch : 56 , phase : train , loss : 0.643682890625\n",
      "epoch : 56 , phase : valid , loss : 0.6528957421875\n",
      "epoch : 57 , phase : train , loss : 0.64002234375\n",
      "epoch : 57 , phase : valid , loss : 0.649156484375\n",
      "epoch : 58 , phase : train , loss : 0.6363925\n",
      "epoch : 58 , phase : valid , loss : 0.64544828125\n",
      "epoch : 59 , phase : train , loss : 0.6327933203125\n",
      "epoch : 59 , phase : valid , loss : 0.6417710546875\n",
      "epoch : 60 , phase : train , loss : 0.6292243359375\n",
      "epoch : 60 , phase : valid , loss : 0.6381241796875\n",
      "epoch : 61 , phase : train , loss : 0.625685234375\n",
      "epoch : 61 , phase : valid , loss : 0.6345074609375\n",
      "epoch : 62 , phase : train , loss : 0.6221759375\n",
      "epoch : 62 , phase : valid , loss : 0.630921328125\n",
      "epoch : 63 , phase : train , loss : 0.61869609375\n",
      "epoch : 63 , phase : valid , loss : 0.6273649609375\n",
      "epoch : 64 , phase : train , loss : 0.6152453125\n",
      "epoch : 64 , phase : valid , loss : 0.623838203125\n",
      "epoch : 65 , phase : train , loss : 0.6118233984375\n",
      "epoch : 65 , phase : valid , loss : 0.6203409375\n",
      "epoch : 66 , phase : train , loss : 0.6084300390625\n",
      "epoch : 66 , phase : valid , loss : 0.616872890625\n",
      "epoch : 67 , phase : train , loss : 0.605065078125\n",
      "epoch : 67 , phase : valid , loss : 0.6134342578125\n",
      "epoch : 68 , phase : train , loss : 0.601728359375\n",
      "epoch : 68 , phase : valid , loss : 0.610024140625\n",
      "epoch : 69 , phase : train , loss : 0.598419296875\n",
      "epoch : 69 , phase : valid , loss : 0.6066427734375\n",
      "epoch : 70 , phase : train , loss : 0.595137890625\n",
      "epoch : 70 , phase : valid , loss : 0.603289765625\n",
      "epoch : 71 , phase : train , loss : 0.5918840234375\n",
      "epoch : 71 , phase : valid , loss : 0.5999649609375\n",
      "epoch : 72 , phase : train , loss : 0.5886569921875\n",
      "epoch : 72 , phase : valid , loss : 0.596667734375\n",
      "epoch : 73 , phase : train , loss : 0.5854566796875\n",
      "epoch : 73 , phase : valid , loss : 0.593398828125\n",
      "epoch : 74 , phase : train , loss : 0.5822834765625\n",
      "epoch : 74 , phase : valid , loss : 0.590156796875\n",
      "epoch : 75 , phase : train , loss : 0.57913609375\n",
      "epoch : 75 , phase : valid , loss : 0.586942109375\n",
      "epoch : 76 , phase : train , loss : 0.576014921875\n",
      "epoch : 76 , phase : valid , loss : 0.58375453125\n",
      "epoch : 77 , phase : train , loss : 0.5729199609375\n",
      "epoch : 77 , phase : valid , loss : 0.5805934375\n",
      "epoch : 78 , phase : train , loss : 0.569850234375\n",
      "epoch : 78 , phase : valid , loss : 0.5774587890625\n",
      "epoch : 79 , phase : train , loss : 0.566805859375\n",
      "epoch : 79 , phase : valid , loss : 0.5743508203125\n",
      "epoch : 80 , phase : train , loss : 0.563786953125\n",
      "epoch : 80 , phase : valid , loss : 0.57126859375\n",
      "epoch : 81 , phase : train , loss : 0.5607928125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 81 , phase : valid , loss : 0.5682123046875\n",
      "epoch : 82 , phase : train , loss : 0.5578233203125\n",
      "epoch : 82 , phase : valid , loss : 0.56518125\n",
      "epoch : 83 , phase : train , loss : 0.5548781640625\n",
      "epoch : 83 , phase : valid , loss : 0.5621755859375\n",
      "epoch : 84 , phase : train , loss : 0.5519571484375\n",
      "epoch : 84 , phase : valid , loss : 0.559195234375\n",
      "epoch : 85 , phase : train , loss : 0.54906046875\n",
      "epoch : 85 , phase : valid , loss : 0.55623953125\n",
      "epoch : 86 , phase : train , loss : 0.5461872265625\n",
      "epoch : 86 , phase : valid , loss : 0.5533084375\n",
      "epoch : 87 , phase : train , loss : 0.54333765625\n",
      "epoch : 87 , phase : valid , loss : 0.5504015625\n",
      "epoch : 88 , phase : train , loss : 0.5405112890625\n",
      "epoch : 88 , phase : valid , loss : 0.5475191015625\n",
      "epoch : 89 , phase : train , loss : 0.537708125\n",
      "epoch : 89 , phase : valid , loss : 0.5446603125\n",
      "epoch : 90 , phase : train , loss : 0.5349277734375\n",
      "epoch : 90 , phase : valid , loss : 0.5418255859375\n",
      "epoch : 91 , phase : train , loss : 0.5321701953125\n",
      "epoch : 91 , phase : valid , loss : 0.5390138671875\n",
      "epoch : 92 , phase : train , loss : 0.5294346875\n",
      "epoch : 92 , phase : valid , loss : 0.5362255078125\n",
      "epoch : 93 , phase : train , loss : 0.526721640625\n",
      "epoch : 93 , phase : valid , loss : 0.53346015625\n",
      "epoch : 94 , phase : train , loss : 0.5240306640625\n",
      "epoch : 94 , phase : valid , loss : 0.530717578125\n",
      "epoch : 95 , phase : train , loss : 0.5213613671875\n",
      "epoch : 95 , phase : valid , loss : 0.52799765625\n",
      "epoch : 96 , phase : train , loss : 0.51871375\n",
      "epoch : 96 , phase : valid , loss : 0.525299921875\n",
      "epoch : 97 , phase : train , loss : 0.5160874609375\n",
      "epoch : 97 , phase : valid , loss : 0.522624296875\n",
      "epoch : 98 , phase : train , loss : 0.51348234375\n",
      "epoch : 98 , phase : valid , loss : 0.5199706640625\n",
      "epoch : 99 , phase : train , loss : 0.5108981640625\n",
      "epoch : 99 , phase : valid , loss : 0.5173385546875\n",
      "epoch : 100 , phase : train , loss : 0.5083346484375\n",
      "epoch : 100 , phase : valid , loss : 0.514728125\n",
      "epoch : 101 , phase : train , loss : 0.505791875\n",
      "epoch : 101 , phase : valid , loss : 0.512138828125\n",
      "epoch : 102 , phase : train , loss : 0.5032694921875\n",
      "epoch : 102 , phase : valid , loss : 0.50957046875\n",
      "epoch : 103 , phase : train , loss : 0.500767109375\n",
      "epoch : 103 , phase : valid , loss : 0.507023046875\n",
      "epoch : 104 , phase : train , loss : 0.498284765625\n",
      "epoch : 104 , phase : valid , loss : 0.5044961328125\n",
      "epoch : 105 , phase : train , loss : 0.4958221484375\n",
      "epoch : 105 , phase : valid , loss : 0.5019898046875\n",
      "epoch : 106 , phase : train , loss : 0.49337921875\n",
      "epoch : 106 , phase : valid , loss : 0.499503515625\n",
      "epoch : 107 , phase : train , loss : 0.4909555859375\n",
      "epoch : 107 , phase : valid , loss : 0.497037421875\n",
      "epoch : 108 , phase : train , loss : 0.488551328125\n",
      "epoch : 108 , phase : valid , loss : 0.49459109375\n",
      "epoch : 109 , phase : train , loss : 0.486166015625\n",
      "epoch : 109 , phase : valid , loss : 0.4921644140625\n",
      "epoch : 110 , phase : train , loss : 0.4837995703125\n",
      "epoch : 110 , phase : valid , loss : 0.4897571875\n",
      "epoch : 111 , phase : train , loss : 0.4814519140625\n",
      "epoch : 111 , phase : valid , loss : 0.487368984375\n",
      "epoch : 112 , phase : train , loss : 0.479122421875\n",
      "epoch : 112 , phase : valid , loss : 0.484999921875\n",
      "epoch : 113 , phase : train , loss : 0.4768112890625\n",
      "epoch : 113 , phase : valid , loss : 0.4826496875\n",
      "epoch : 114 , phase : train , loss : 0.4745183984375\n",
      "epoch : 114 , phase : valid , loss : 0.480318359375\n",
      "epoch : 115 , phase : train , loss : 0.4722436328125\n",
      "epoch : 115 , phase : valid , loss : 0.4780053125\n",
      "epoch : 116 , phase : train , loss : 0.469986484375\n",
      "epoch : 116 , phase : valid , loss : 0.47571046875\n",
      "epoch : 117 , phase : train , loss : 0.467746796875\n",
      "epoch : 117 , phase : valid , loss : 0.47343390625\n",
      "epoch : 118 , phase : train , loss : 0.4655246484375\n",
      "epoch : 118 , phase : valid , loss : 0.4711751953125\n",
      "epoch : 119 , phase : train , loss : 0.4633198046875\n",
      "epoch : 119 , phase : valid , loss : 0.4689343359375\n",
      "epoch : 120 , phase : train , loss : 0.4611321875\n",
      "epoch : 120 , phase : valid , loss : 0.4667109375\n",
      "epoch : 121 , phase : train , loss : 0.4589612890625\n",
      "epoch : 121 , phase : valid , loss : 0.4645048828125\n",
      "epoch : 122 , phase : train , loss : 0.4568071484375\n",
      "epoch : 122 , phase : valid , loss : 0.462316171875\n",
      "epoch : 123 , phase : train , loss : 0.4546697265625\n",
      "epoch : 123 , phase : valid , loss : 0.4601444921875\n",
      "epoch : 124 , phase : train , loss : 0.4525487109375\n",
      "epoch : 124 , phase : valid , loss : 0.4579898046875\n",
      "epoch : 125 , phase : train , loss : 0.4504440625\n",
      "epoch : 125 , phase : valid , loss : 0.4558516796875\n",
      "epoch : 126 , phase : train , loss : 0.4483553515625\n",
      "epoch : 126 , phase : valid , loss : 0.4537301953125\n",
      "epoch : 127 , phase : train , loss : 0.446282890625\n",
      "epoch : 127 , phase : valid , loss : 0.4516253125\n",
      "epoch : 128 , phase : train , loss : 0.44422625\n",
      "epoch : 128 , phase : valid , loss : 0.44953640625\n",
      "epoch : 129 , phase : train , loss : 0.442185\n",
      "epoch : 129 , phase : valid , loss : 0.4474634765625\n",
      "epoch : 130 , phase : train , loss : 0.4401593359375\n",
      "epoch : 130 , phase : valid , loss : 0.4454067578125\n",
      "epoch : 131 , phase : train , loss : 0.4381492578125\n",
      "epoch : 131 , phase : valid , loss : 0.4433655859375\n",
      "epoch : 132 , phase : train , loss : 0.43615421875\n",
      "epoch : 132 , phase : valid , loss : 0.44134015625\n",
      "epoch : 133 , phase : train , loss : 0.4341743359375\n",
      "epoch : 133 , phase : valid , loss : 0.43933\n",
      "epoch : 134 , phase : train , loss : 0.432209296875\n",
      "epoch : 134 , phase : valid , loss : 0.4373353515625\n",
      "epoch : 135 , phase : train , loss : 0.4302591015625\n",
      "epoch : 135 , phase : valid , loss : 0.4353559375\n",
      "epoch : 136 , phase : train , loss : 0.428323828125\n",
      "epoch : 136 , phase : valid , loss : 0.4333912890625\n",
      "epoch : 137 , phase : train , loss : 0.426402734375\n",
      "epoch : 137 , phase : valid , loss : 0.431441484375\n",
      "epoch : 138 , phase : train , loss : 0.42449609375\n",
      "epoch : 138 , phase : valid , loss : 0.4295065625\n",
      "epoch : 139 , phase : train , loss : 0.42260375\n",
      "epoch : 139 , phase : valid , loss : 0.4275861328125\n",
      "epoch : 140 , phase : train , loss : 0.4207254296875\n",
      "epoch : 140 , phase : valid , loss : 0.4256800390625\n",
      "epoch : 141 , phase : train , loss : 0.4188609765625\n",
      "epoch : 141 , phase : valid , loss : 0.4237885546875\n",
      "epoch : 142 , phase : train , loss : 0.4170106640625\n",
      "epoch : 142 , phase : valid , loss : 0.4219109765625\n",
      "epoch : 143 , phase : train , loss : 0.415173828125\n",
      "epoch : 143 , phase : valid , loss : 0.4200473046875\n",
      "epoch : 144 , phase : train , loss : 0.4133505078125\n",
      "epoch : 144 , phase : valid , loss : 0.41819765625\n",
      "epoch : 145 , phase : train , loss : 0.411540703125\n",
      "epoch : 145 , phase : valid , loss : 0.4163618359375\n",
      "epoch : 146 , phase : train , loss : 0.4097443359375\n",
      "epoch : 146 , phase : valid , loss : 0.414539375\n",
      "epoch : 147 , phase : train , loss : 0.4079609375\n",
      "epoch : 147 , phase : valid , loss : 0.4127306640625\n",
      "epoch : 148 , phase : train , loss : 0.406190703125\n",
      "epoch : 148 , phase : valid , loss : 0.41093515625\n",
      "epoch : 149 , phase : train , loss : 0.404433515625\n",
      "epoch : 149 , phase : valid , loss : 0.4091530078125\n",
      "epoch : 150 , phase : train , loss : 0.402688984375\n",
      "epoch : 150 , phase : valid , loss : 0.407383828125\n",
      "epoch : 151 , phase : train , loss : 0.4009573046875\n",
      "epoch : 151 , phase : valid , loss : 0.4056275390625\n",
      "epoch : 152 , phase : train , loss : 0.399238125\n",
      "epoch : 152 , phase : valid , loss : 0.403884296875\n",
      "epoch : 153 , phase : train , loss : 0.397531484375\n",
      "epoch : 153 , phase : valid , loss : 0.40215359375\n",
      "epoch : 154 , phase : train , loss : 0.395836953125\n",
      "epoch : 154 , phase : valid , loss : 0.4004354296875\n",
      "epoch : 155 , phase : train , loss : 0.3941547265625\n",
      "epoch : 155 , phase : valid , loss : 0.3987300390625\n",
      "epoch : 156 , phase : train , loss : 0.3924848046875\n",
      "epoch : 156 , phase : valid , loss : 0.3970367578125\n",
      "epoch : 157 , phase : train , loss : 0.3908266796875\n",
      "epoch : 157 , phase : valid , loss : 0.395355859375\n",
      "epoch : 158 , phase : train , loss : 0.3891805859375\n",
      "epoch : 158 , phase : valid , loss : 0.393687109375\n",
      "epoch : 159 , phase : train , loss : 0.3875462109375\n",
      "epoch : 159 , phase : valid , loss : 0.3920302734375\n",
      "epoch : 160 , phase : train , loss : 0.385923515625\n",
      "epoch : 160 , phase : valid , loss : 0.3903854296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 161 , phase : train , loss : 0.384312421875\n",
      "epoch : 161 , phase : valid , loss : 0.388752109375\n",
      "epoch : 162 , phase : train , loss : 0.3827125\n",
      "epoch : 162 , phase : valid , loss : 0.3871307421875\n",
      "epoch : 163 , phase : train , loss : 0.3811242578125\n",
      "epoch : 163 , phase : valid , loss : 0.3855209765625\n",
      "epoch : 164 , phase : train , loss : 0.3795471875\n",
      "epoch : 164 , phase : valid , loss : 0.3839225\n",
      "epoch : 165 , phase : train , loss : 0.377981171875\n",
      "epoch : 165 , phase : valid , loss : 0.38233546875\n",
      "epoch : 166 , phase : train , loss : 0.376426171875\n",
      "epoch : 166 , phase : valid , loss : 0.3807595703125\n",
      "epoch : 167 , phase : train , loss : 0.3748821875\n",
      "epoch : 167 , phase : valid , loss : 0.379195078125\n",
      "epoch : 168 , phase : train , loss : 0.3733490625\n",
      "epoch : 168 , phase : valid , loss : 0.377641328125\n",
      "epoch : 169 , phase : train , loss : 0.3718266015625\n",
      "epoch : 169 , phase : valid , loss : 0.3760986328125\n",
      "epoch : 170 , phase : train , loss : 0.3703147265625\n",
      "epoch : 170 , phase : valid , loss : 0.374566796875\n",
      "epoch : 171 , phase : train , loss : 0.3688134765625\n",
      "epoch : 171 , phase : valid , loss : 0.3730456640625\n",
      "epoch : 172 , phase : train , loss : 0.3673226171875\n",
      "epoch : 172 , phase : valid , loss : 0.3715350390625\n",
      "epoch : 173 , phase : train , loss : 0.3658419921875\n",
      "epoch : 173 , phase : valid , loss : 0.3700351171875\n",
      "epoch : 174 , phase : train , loss : 0.364371796875\n",
      "epoch : 174 , phase : valid , loss : 0.368545703125\n",
      "epoch : 175 , phase : train , loss : 0.3629118359375\n",
      "epoch : 175 , phase : valid , loss : 0.3670662890625\n",
      "epoch : 176 , phase : train , loss : 0.3614615625\n",
      "epoch : 176 , phase : valid , loss : 0.3655975\n",
      "epoch : 177 , phase : train , loss : 0.3600215625\n",
      "epoch : 177 , phase : valid , loss : 0.3641385546875\n",
      "epoch : 178 , phase : train , loss : 0.358591328125\n",
      "epoch : 178 , phase : valid , loss : 0.3626898828125\n",
      "epoch : 179 , phase : train , loss : 0.357171015625\n",
      "epoch : 179 , phase : valid , loss : 0.361251015625\n",
      "epoch : 180 , phase : train , loss : 0.3557603125\n",
      "epoch : 180 , phase : valid , loss : 0.3598219921875\n",
      "epoch : 181 , phase : train , loss : 0.3543590234375\n",
      "epoch : 181 , phase : valid , loss : 0.35840296875\n",
      "epoch : 182 , phase : train , loss : 0.3529676171875\n",
      "epoch : 182 , phase : valid , loss : 0.356993515625\n",
      "epoch : 183 , phase : train , loss : 0.3515855078125\n",
      "epoch : 183 , phase : valid , loss : 0.35559359375\n",
      "epoch : 184 , phase : train , loss : 0.35021265625\n",
      "epoch : 184 , phase : valid , loss : 0.354203203125\n",
      "epoch : 185 , phase : train , loss : 0.3488490234375\n",
      "epoch : 185 , phase : valid , loss : 0.3528224609375\n",
      "epoch : 186 , phase : train , loss : 0.34749484375\n",
      "epoch : 186 , phase : valid , loss : 0.3514508203125\n",
      "epoch : 187 , phase : train , loss : 0.346149609375\n",
      "epoch : 187 , phase : valid , loss : 0.350088515625\n",
      "epoch : 188 , phase : train , loss : 0.344813359375\n",
      "epoch : 188 , phase : valid , loss : 0.3487352734375\n",
      "epoch : 189 , phase : train , loss : 0.343486015625\n",
      "epoch : 189 , phase : valid , loss : 0.347391328125\n",
      "epoch : 190 , phase : train , loss : 0.3421677734375\n",
      "epoch : 190 , phase : valid , loss : 0.346056328125\n",
      "epoch : 191 , phase : train , loss : 0.3408580859375\n",
      "epoch : 191 , phase : valid , loss : 0.3447302734375\n",
      "epoch : 192 , phase : train , loss : 0.3395573046875\n",
      "epoch : 192 , phase : valid , loss : 0.34341296875\n",
      "epoch : 193 , phase : train , loss : 0.338264921875\n",
      "epoch : 193 , phase : valid , loss : 0.342104453125\n",
      "epoch : 194 , phase : train , loss : 0.33698125\n",
      "epoch : 194 , phase : valid , loss : 0.3408047265625\n",
      "epoch : 195 , phase : train , loss : 0.335706015625\n",
      "epoch : 195 , phase : valid , loss : 0.3395135546875\n",
      "epoch : 196 , phase : train , loss : 0.3344391796875\n",
      "epoch : 196 , phase : valid , loss : 0.3382309375\n",
      "epoch : 197 , phase : train , loss : 0.333180625\n",
      "epoch : 197 , phase : valid , loss : 0.3369567578125\n",
      "epoch : 198 , phase : train , loss : 0.331930390625\n",
      "epoch : 198 , phase : valid , loss : 0.3356910546875\n",
      "epoch : 199 , phase : train , loss : 0.3306883984375\n",
      "epoch : 199 , phase : valid , loss : 0.334433671875\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.3306883984375\n",
      "(compare com a entropia do dataset de treino).\n",
      "comprimento médio de código final no dataset de validação: 0.334433671875\n",
      "(compare com a entropia do dataset de validação).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "271db70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7900, 2.2502, 2.6719, 2.8991, 2.8084]], device='cuda:0')\n",
      "tensor([9.1377], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "41bac832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32098451, 0.77295341, 0.82311742, 0.86189127, 0.7005142 ,\n",
       "         0.80153656, 0.21184858]]),\n",
       " array([[0.2792105]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
