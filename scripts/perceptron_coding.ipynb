{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "#from perceptronac.perfect_AC import perfect_AC\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "X = (X > 0).astype(int)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)).astype(int) # signal \n",
    "yt = yy[0:L] > 0 # train on the first part \n",
    "yc = yy[L:L+L] > 0 # encode the second part\n",
    "Xt = X[0:L,0:N] # truncated X for training \n",
    "Xc = X[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bbecba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fd3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is context and y is bitstream to encode\n",
    "L = 100000 # how many samples \n",
    "#N = 10 # order of the AR\n",
    "first = True\n",
    "for pc_num in range(11, 15):\n",
    "    if first:\n",
    "        my_data = genfromtxt(f'../SPIHT_dataset/ricardo/SPIHT_bits_with_context_ricardo_v9_Y_{pc_num}_v10.csv', delimiter=',')\n",
    "        first = False\n",
    "    else:\n",
    "        my_data = np.append(my_data,\n",
    "                            genfromtxt(f'../SPIHT_dataset/ricardo/SPIHT_bits_with_context_ricardo_v9_Y_{pc_num}_v10.csv', delimiter=','),\n",
    "                            axis=0)\n",
    "    \n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:7].astype(float)\n",
    "extra_context = my_data[:, 7:].astype(float)\n",
    "#extra_context = extra_context.reshape((len(extra_context), 1))\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/andrew/SPIHT_bits_with_context_andrew_Y_10_v10.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:7].astype(float)\n",
    "extra_context_test = my_data_test[:, 7:].astype(float)\n",
    "#extra_context_test = extra_context_test.reshape((len(extra_context_test), 1))\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "Xt = np.append(Xt, extra_context/abs(extra_context).max(axis=0), axis=1)\n",
    "#Xt = extra_context/abs(extra_context).max(axis=0)\n",
    "Xt[np.isnan(Xt)] = 0\n",
    "Xc = np.append(Xc, extra_context_test/abs(extra_context_test).max(axis=0), axis=1)\n",
    "#Xc = extra_context_test/abs(extra_context_test).max(axis=0)\n",
    "Xc[np.isnan(Xc)] = 0\n",
    "\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0aa3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9921e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "#Xt = np.append(Xt, extra_context/abs(extra_context).max(axis=0), axis=1)\n",
    "Xt[np.isnan(Xt)] = 0\n",
    "#Xc = np.append(Xc, extra_context_test/abs(extra_context_test).max(axis=0), axis=1)\n",
    "Xc[np.isnan(Xc)] = 0\n",
    "\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perfect_AC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# treino\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mperfect_AC\u001b[49m(yt,context_coding(Xt,context_training(Xt,yt)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perfect_AC' is not defined"
     ]
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perfect_AC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# teste\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mperfect_AC\u001b[49m(yc[:],context_coding(Xc[:, :],context_training(Xc[:, :],yc[:])))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perfect_AC' is not defined"
     ]
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc[:],context_coding(Xc[:, :],context_training(Xc[:, :],yc[:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449d735",
   "metadata": {},
   "source": [
    "# Criando classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a561b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_N_64N_32N_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 64*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64*N, 32*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32*N, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28dc8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_N_1024_512_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class MLP_N_2048_1024_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.003491003723144531\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.0901, 11.7186, 11.9979, 12.1763, 12.1026]], device='cuda:0')\n",
      "tensor([41.8704], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.32098451, 0.77295341, 0.82311742, 0.86189127, 0.7005142 ,\n",
       "         0.80153656, 0.21184858]]),\n",
       " array([[0.2792105]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Perceptron(N)\n",
    "#net = MLP_N_64N_32N_1(N)\n",
    "net = MLP_N_1024_512_1(N) #melhor resultado\n",
    "#net = MLP_N_2048_1024_1(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : train , loss : 0.9717047951376283\n",
      "epoch : 0 , phase : valid , loss : 0.9509854270695919\n",
      "epoch : 1 , phase : train , loss : 0.9497114645081053\n",
      "epoch : 1 , phase : valid , loss : 0.943273384908049\n",
      "epoch : 2 , phase : train , loss : 0.9432321312440688\n",
      "epoch : 2 , phase : valid , loss : 0.9402434393096178\n",
      "epoch : 3 , phase : train , loss : 0.9409189501607299\n",
      "epoch : 3 , phase : valid , loss : 0.9389055571568122\n",
      "epoch : 4 , phase : train , loss : 0.9395846382051576\n",
      "epoch : 4 , phase : valid , loss : 0.9373177774424886\n",
      "epoch : 5 , phase : train , loss : 0.9386583164653571\n",
      "epoch : 5 , phase : valid , loss : 0.9366583947306468\n",
      "epoch : 6 , phase : train , loss : 0.9378952746717534\n",
      "epoch : 6 , phase : valid , loss : 0.9361031529829074\n",
      "epoch : 7 , phase : train , loss : 0.9369317013182733\n",
      "epoch : 7 , phase : valid , loss : 0.9356766088278893\n",
      "epoch : 8 , phase : train , loss : 0.9360641699760633\n",
      "epoch : 8 , phase : valid , loss : 0.9359921471283851\n",
      "epoch : 9 , phase : train , loss : 0.9357901307044316\n",
      "epoch : 9 , phase : valid , loss : 0.934149642578495\n",
      "epoch : 10 , phase : train , loss : 0.9353234683796727\n",
      "epoch : 10 , phase : valid , loss : 0.9341887319696689\n",
      "epoch : 11 , phase : train , loss : 0.934795863702324\n",
      "epoch : 11 , phase : valid , loss : 0.9335598035793584\n",
      "epoch : 12 , phase : train , loss : 0.9343646222426971\n",
      "epoch : 12 , phase : valid , loss : 0.9331280762376953\n",
      "epoch : 13 , phase : train , loss : 0.9335286446258706\n",
      "epoch : 13 , phase : valid , loss : 0.9329266531674939\n",
      "epoch : 14 , phase : train , loss : 0.9334233012515322\n",
      "epoch : 14 , phase : valid , loss : 0.9328481982345063\n",
      "epoch : 15 , phase : train , loss : 0.9330437820447353\n",
      "epoch : 15 , phase : valid , loss : 0.9331026697085634\n",
      "epoch : 16 , phase : train , loss : 0.9323027395271258\n",
      "epoch : 16 , phase : valid , loss : 0.9328025824385267\n",
      "epoch : 17 , phase : train , loss : 0.9322909258936376\n",
      "epoch : 17 , phase : valid , loss : 0.9319576915127744\n",
      "epoch : 18 , phase : train , loss : 0.9325852975015949\n",
      "epoch : 18 , phase : valid , loss : 0.9318637989546985\n",
      "epoch : 19 , phase : train , loss : 0.9317327221344313\n",
      "epoch : 19 , phase : valid , loss : 0.9322203898629314\n",
      "epoch : 20 , phase : train , loss : 0.9317742877559168\n",
      "epoch : 20 , phase : valid , loss : 0.9314181400813639\n",
      "epoch : 21 , phase : train , loss : 0.931502570980035\n",
      "epoch : 21 , phase : valid , loss : 0.9321703409108067\n",
      "epoch : 22 , phase : train , loss : 0.931244119036849\n",
      "epoch : 22 , phase : valid , loss : 0.9317784570124289\n",
      "epoch : 23 , phase : train , loss : 0.9312254797662657\n",
      "epoch : 23 , phase : valid , loss : 0.9316519967761048\n",
      "epoch : 24 , phase : train , loss : 0.9308210914224393\n",
      "epoch : 24 , phase : valid , loss : 0.9318585554438846\n",
      "epoch : 25 , phase : train , loss : 0.9308669361101108\n",
      "epoch : 25 , phase : valid , loss : 0.9307782353733891\n",
      "epoch : 26 , phase : train , loss : 0.9306906700627647\n",
      "epoch : 26 , phase : valid , loss : 0.9308822436243198\n",
      "epoch : 27 , phase : train , loss : 0.9306329660610468\n",
      "epoch : 27 , phase : valid , loss : 0.9313270566187528\n",
      "epoch : 28 , phase : train , loss : 0.9303847104993052\n",
      "epoch : 28 , phase : valid , loss : 0.9304714889853751\n",
      "epoch : 29 , phase : train , loss : 0.9297719219992358\n",
      "epoch : 29 , phase : valid , loss : 0.9304685766685548\n",
      "epoch : 30 , phase : train , loss : 0.9298359100429391\n",
      "epoch : 30 , phase : valid , loss : 0.9310196855404566\n",
      "epoch : 31 , phase : train , loss : 0.9300608096962485\n",
      "epoch : 31 , phase : valid , loss : 0.9302577825738501\n",
      "epoch : 32 , phase : train , loss : 0.9296597146802463\n",
      "epoch : 32 , phase : valid , loss : 0.9301132720056563\n",
      "epoch : 33 , phase : train , loss : 0.9295906258011568\n",
      "epoch : 33 , phase : valid , loss : 0.9301693084666778\n",
      "epoch : 34 , phase : train , loss : 0.929418494245037\n",
      "epoch : 34 , phase : valid , loss : 0.9299442222358254\n",
      "epoch : 35 , phase : train , loss : 0.9292514670505216\n",
      "epoch : 35 , phase : valid , loss : 0.9300640374298116\n",
      "epoch : 36 , phase : train , loss : 0.929394357920331\n",
      "epoch : 36 , phase : valid , loss : 0.9298266624954872\n",
      "epoch : 37 , phase : train , loss : 0.9292554454264366\n",
      "epoch : 37 , phase : valid , loss : 0.9298338122500381\n",
      "epoch : 38 , phase : train , loss : 0.9291242266605263\n",
      "epoch : 38 , phase : valid , loss : 0.9296626290154341\n",
      "epoch : 39 , phase : train , loss : 0.9289297242932053\n",
      "epoch : 39 , phase : valid , loss : 0.9299068018133242\n",
      "epoch : 40 , phase : train , loss : 0.929033335653115\n",
      "epoch : 40 , phase : valid , loss : 0.9298138268528839\n",
      "epoch : 41 , phase : train , loss : 0.9288365373969657\n",
      "epoch : 41 , phase : valid , loss : 0.9300656916525764\n",
      "epoch : 42 , phase : train , loss : 0.9286610825401641\n",
      "epoch : 42 , phase : valid , loss : 0.9295931871835474\n",
      "epoch : 43 , phase : train , loss : 0.9286936724929473\n",
      "epoch : 43 , phase : valid , loss : 0.9316659825995284\n",
      "epoch : 44 , phase : train , loss : 0.928576805596736\n",
      "epoch : 44 , phase : valid , loss : 0.9292398236183502\n",
      "epoch : 45 , phase : train , loss : 0.9287263606990015\n",
      "epoch : 45 , phase : valid , loss : 0.9292431246909257\n",
      "epoch : 46 , phase : train , loss : 0.9282990713289331\n",
      "epoch : 46 , phase : valid , loss : 0.9294260912465202\n",
      "epoch : 47 , phase : train , loss : 0.9282867364562332\n",
      "epoch : 47 , phase : valid , loss : 0.9307476235387502\n",
      "epoch : 48 , phase : train , loss : 0.9287046448027508\n",
      "epoch : 48 , phase : valid , loss : 0.9291428163223538\n",
      "epoch : 49 , phase : train , loss : 0.9281809101502387\n",
      "epoch : 49 , phase : valid , loss : 0.9293248981234712\n",
      "epoch : 50 , phase : train , loss : 0.9280344728662844\n",
      "epoch : 50 , phase : valid , loss : 0.9288875016504693\n",
      "epoch : 51 , phase : train , loss : 0.9280325946740693\n",
      "epoch : 51 , phase : valid , loss : 0.9289385486324548\n",
      "epoch : 52 , phase : train , loss : 0.9279356108418864\n",
      "epoch : 52 , phase : valid , loss : 0.9287246136593565\n",
      "epoch : 53 , phase : train , loss : 0.9279918706968338\n",
      "epoch : 53 , phase : valid , loss : 0.9288536671646744\n",
      "epoch : 54 , phase : train , loss : 0.9278656139615256\n",
      "epoch : 54 , phase : valid , loss : 0.9290429134662506\n",
      "epoch : 55 , phase : train , loss : 0.9279141060378996\n",
      "epoch : 55 , phase : valid , loss : 0.9287355263015092\n",
      "epoch : 56 , phase : train , loss : 0.9276444120291927\n",
      "epoch : 56 , phase : valid , loss : 0.9288182461532377\n",
      "epoch : 57 , phase : train , loss : 0.9273378578170628\n",
      "epoch : 57 , phase : valid , loss : 0.929721282875117\n",
      "epoch : 58 , phase : train , loss : 0.9277180276111784\n",
      "epoch : 58 , phase : valid , loss : 0.928474328012352\n",
      "epoch : 59 , phase : train , loss : 0.9271920241576077\n",
      "epoch : 59 , phase : valid , loss : 0.9289821248012573\n",
      "epoch : 60 , phase : train , loss : 0.9275507170369195\n",
      "epoch : 60 , phase : valid , loss : 0.9290829593306358\n",
      "epoch : 61 , phase : train , loss : 0.9274334455872733\n",
      "epoch : 61 , phase : valid , loss : 0.9285428140412959\n",
      "epoch : 62 , phase : train , loss : 0.9272964553633255\n",
      "epoch : 62 , phase : valid , loss : 0.9290966569385857\n",
      "epoch : 63 , phase : train , loss : 0.927288035394607\n",
      "epoch : 63 , phase : valid , loss : 0.9283558433014241\n",
      "epoch : 64 , phase : train , loss : 0.9273264001713635\n",
      "epoch : 64 , phase : valid , loss : 0.9282098440667957\n",
      "epoch : 65 , phase : train , loss : 0.9270665989687419\n",
      "epoch : 65 , phase : valid , loss : 0.9281632550408914\n",
      "epoch : 66 , phase : train , loss : 0.9270602673228062\n",
      "epoch : 66 , phase : valid , loss : 0.9283838799643198\n",
      "epoch : 67 , phase : train , loss : 0.9271307769473979\n",
      "epoch : 67 , phase : valid , loss : 0.9282271617951477\n",
      "epoch : 68 , phase : train , loss : 0.9270637852066378\n",
      "epoch : 68 , phase : valid , loss : 0.9282261470085733\n",
      "epoch : 69 , phase : train , loss : 0.9267815638257556\n",
      "epoch : 69 , phase : valid , loss : 0.9283934688260996\n",
      "epoch : 70 , phase : train , loss : 0.9270242364218686\n",
      "epoch : 70 , phase : valid , loss : 0.9279901568490592\n",
      "epoch : 71 , phase : train , loss : 0.9267718458880527\n",
      "epoch : 71 , phase : valid , loss : 0.9283006902543426\n",
      "epoch : 72 , phase : train , loss : 0.9272168617189531\n",
      "epoch : 72 , phase : valid , loss : 0.9278991799591464\n",
      "epoch : 73 , phase : train , loss : 0.9266340287658599\n",
      "epoch : 73 , phase : valid , loss : 0.927993624818502\n",
      "epoch : 74 , phase : train , loss : 0.92675996028765\n",
      "epoch : 74 , phase : valid , loss : 0.9279951496794379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 75 , phase : train , loss : 0.9265743710787937\n",
      "epoch : 75 , phase : valid , loss : 0.9278184548266027\n",
      "epoch : 76 , phase : train , loss : 0.9267429603881178\n",
      "epoch : 76 , phase : valid , loss : 0.9278159252331205\n",
      "epoch : 77 , phase : train , loss : 0.9264490973570421\n",
      "epoch : 77 , phase : valid , loss : 0.9288513084896707\n",
      "epoch : 78 , phase : train , loss : 0.9265811231461477\n",
      "epoch : 78 , phase : valid , loss : 0.9280870977884699\n",
      "epoch : 79 , phase : train , loss : 0.9265303310135962\n",
      "epoch : 79 , phase : valid , loss : 0.9279657570632792\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 10000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(150):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9fbc5",
   "metadata": {},
   "source": [
    "### Salva os pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e919036",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pesos_ricardo_vox9_Y_1024-512.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.eval().state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7b8ef",
   "metadata": {},
   "source": [
    "### Carregando os pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "381e1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pesos_phil9-v3_U_1024-512.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f292d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_test = genfromtxt('../SPIHT_dataset/david/SPIHT_bits_with_context_david_Y80_v5.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xc = Xc.astype(int)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)\n",
    "N = Xc[0, :].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b2bbddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_N_1024_512_1(N)\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d65daa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.9485439658164978\n"
     ]
    }
   ],
   "source": [
    "Xc_tensor = torch.from_numpy(Xc[0:, :])\n",
    "yc_tensor = torch.from_numpy(yc[0:])\n",
    "predictions = model(Xc_tensor.float())\n",
    "criterion=Log2BCELoss()\n",
    "tamanho_medio = criterion(predictions,yc_tensor.float())\n",
    "print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_medio}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb037251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.9572733044624329\n",
      "comprimento médio de código final no modelo treinado: 0.961675226688385\n",
      "comprimento médio de código final no modelo treinado: 0.9664247632026672\n",
      "comprimento médio de código final no modelo treinado: 0.9623333811759949\n"
     ]
    }
   ],
   "source": [
    "bit_list = [591889,301037,131569,51154]\n",
    "for i in bit_list:\n",
    "    Xc_tensor = torch.from_numpy(Xc[0:i, :])\n",
    "    yc_tensor = torch.from_numpy(yc[0:i])\n",
    "    predictions = model(Xc_tensor.float())\n",
    "    criterion=Log2BCELoss()\n",
    "    tamanho_medio = criterion(predictions,yc_tensor.float())\n",
    "    print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_medio}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a11252b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9040812081822108"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_AC(yc[0:1042536],context_coding(Xc[0:1042536, :],context_training(Xc[0:, :],yc[0:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271db70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41bac832",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241m.\u001b[39mT, C0\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
