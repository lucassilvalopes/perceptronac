{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71032773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "343a3815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))\n",
    "    \n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]\n",
    "    \n",
    "class MLP_N_64N_32N_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 64*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64*N, 32*N),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32*N, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class MLP_N_1024_512_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class MLP_N_2048_1024_1(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(N, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db6e1a",
   "metadata": {},
   "source": [
    "## Carregando os pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5880155",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pesos_andrew9-v3_V_1024-512.txt'\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/andrew/SPIHT_bits_with_context_andrew_V80_v5.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c041586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xc = Xc.astype(int)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)\n",
    "N = Xc[0, :].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2067b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_N_1024_512_1(N)\n",
    "model.load_state_dict(torch.load(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70600f",
   "metadata": {},
   "source": [
    "## Realizando os testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "332894d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.901471734046936\n",
      "comprimento médio de código final no modelo treinado: 0.9125586152076721\n",
      "comprimento médio de código final no modelo treinado: 0.8967228531837463\n",
      "comprimento médio de código final no modelo treinado: 0.8991806507110596\n",
      "comprimento médio de código final no modelo treinado: 0.8882057070732117\n",
      "comprimento médio de código final no modelo treinado: 0.9351104497909546\n",
      "comprimento médio de código final no modelo treinado: 0.9462733268737793\n",
      "comprimento médio de código final no modelo treinado: 0.9489244818687439\n",
      "comprimento médio de código final no modelo treinado: 0.9153303503990173\n"
     ]
    }
   ],
   "source": [
    "bit_list = [890306,507324,266178,92913,24914,5440,1829,743,293]\n",
    "for i in bit_list:\n",
    "    Xc_tensor = torch.from_numpy(Xc[0:i, :])\n",
    "    yc_tensor = torch.from_numpy(yc[0:i])\n",
    "    predictions = model(Xc_tensor.float())\n",
    "    criterion=Log2BCELoss()\n",
    "    tamanho_medio = criterion(predictions,yc_tensor.float())\n",
    "    print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_medio}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52585c1e",
   "metadata": {},
   "source": [
    "## Comparar com teórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b014a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100000 # how many samples \n",
    "#N = 10 # order of the AR\n",
    "first = True\n",
    "for pc_num in range(1052, 1081):\n",
    "    if first:\n",
    "        my_data = genfromtxt(f'../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_Y{pc_num}_v5.csv', delimiter=',')\n",
    "        first = False\n",
    "    else:\n",
    "        my_data = np.append(my_data,\n",
    "                            genfromtxt(f'../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_Y{pc_num}_v5.csv', delimiter=','),\n",
    "                            axis=0)\n",
    "    \n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(float)\n",
    "extra_context = my_data[:, 6:].astype(float)\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_Y1082_v5.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "\n",
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "Xt = np.append(Xt, extra_context/extra_context.max(axis=0), axis=1)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0a4802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.8998248100386786\n",
      "comprimento médio de código final no modelo treinado: 0.9039480465672349\n",
      "comprimento médio de código final no modelo treinado: 0.9011865653318071\n",
      "comprimento médio de código final no modelo treinado: 0.908467066595722\n",
      "comprimento médio de código final no modelo treinado: 0.914228300718732\n",
      "comprimento médio de código final no modelo treinado: 0.9237322435313927\n",
      "comprimento médio de código final no modelo treinado: 0.9272066370934923\n",
      "comprimento médio de código final no modelo treinado: 0.9265491010676893\n",
      "comprimento médio de código final no modelo treinado: 0.9282372557795862\n"
     ]
    }
   ],
   "source": [
    "bit_list = [1425144,1127017,836615,530172,278762,112175,36069,10298,2800]\n",
    "for i in bit_list:\n",
    "    tamanho_estimado = perfect_AC(yc[0:i, :],context_coding(Xc[0:i, :],context_training(Xt,yt)))\n",
    "    print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_estimado}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e711d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100000 # how many samples \n",
    "#N = 10 # order of the AR\n",
    "first = True\n",
    "for pc_num in range(1052,1081):\n",
    "    if first:\n",
    "        my_data = genfromtxt(f'../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_U{pc_num}_v5.csv', delimiter=',')\n",
    "        first = False\n",
    "    else:\n",
    "        my_data = np.append(my_data,\n",
    "                            genfromtxt(f'../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_U{pc_num}_v5.csv', delimiter=','),\n",
    "                            axis=0)\n",
    "    \n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(float)\n",
    "extra_context = my_data[:, 6:].astype(float)\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_U1082_v5.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "\n",
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "Xt = np.append(Xt, extra_context/extra_context.max(axis=0), axis=1)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc2a6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.886570537087748\n",
      "comprimento médio de código final no modelo treinado: 0.9108485470670586\n",
      "comprimento médio de código final no modelo treinado: 0.9105093605853859\n",
      "comprimento médio de código final no modelo treinado: 0.9315149706581537\n",
      "comprimento médio de código final no modelo treinado: 0.940785283571943\n",
      "comprimento médio de código final no modelo treinado: 0.9414877880649091\n",
      "comprimento médio de código final no modelo treinado: 0.9407770210352806\n",
      "comprimento médio de código final no modelo treinado: 0.9405984261003056\n",
      "comprimento médio de código final no modelo treinado: 0.9409892106836274\n"
     ]
    }
   ],
   "source": [
    "bit_list = [1073299,711315,436593,208488,84220,29887,9847,2887,816]\n",
    "for i in bit_list:\n",
    "    tamanho_estimado = perfect_AC(yc[0:i, :],context_coding(Xc[0:i, :],context_training(Xt,yt)))\n",
    "    print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_estimado}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b118e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100000 # how many samples \n",
    "#N = 10 # order of the AR\n",
    "first = True\n",
    "for pc_num in range(1052,1081):\n",
    "    if first:\n",
    "        my_data = genfromtxt(f'../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_V{pc_num}_v5.csv', delimiter=',')\n",
    "        first = False\n",
    "    else:\n",
    "        my_data = np.append(my_data,\n",
    "                            genfromtxt(f'../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_V{pc_num}_v5.csv', delimiter=','),\n",
    "                            axis=0)\n",
    "    \n",
    "bitstream = my_data[:, 0].astype(int)\n",
    "context = my_data[:, 1:6].astype(float)\n",
    "extra_context = my_data[:, 6:].astype(float)\n",
    "bitstream = bitstream.reshape((len(bitstream), 1))\n",
    "\n",
    "my_data_test = genfromtxt('../SPIHT_dataset/longdress/SPIHT_bits_with_context_longdress_V1082_v5.csv', delimiter=',')\n",
    "bitstream_test = my_data_test[:, 0].astype(int)\n",
    "context_test = my_data_test[:, 1:6].astype(float)\n",
    "extra_context_test = my_data_test[:, 6:].astype(float)\n",
    "bitstream_test = bitstream_test.reshape((len(bitstream_test), 1))\n",
    "\n",
    "\n",
    "yt = bitstream > 0 # train on the first part \n",
    "yc = bitstream_test > 0 # encode the second part\n",
    "Xt = context >= 0 # truncated X for training \n",
    "Xc = context_test >= 0 # truncated X for coding\n",
    "Xt = Xt.astype(int)\n",
    "Xc = Xc.astype(int)\n",
    "Xt = np.append(Xt, extra_context/extra_context.max(axis=0), axis=1)\n",
    "Xc = np.append(Xc, extra_context_test/extra_context_test.max(axis=0), axis=1)\n",
    "\n",
    "N = Xc[0, :].size # order of the AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2b3bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no modelo treinado: 0.8886449877294255\n",
      "comprimento médio de código final no modelo treinado: 0.9130558970138097\n",
      "comprimento médio de código final no modelo treinado: 0.9145539491728297\n",
      "comprimento médio de código final no modelo treinado: 0.9313661969952604\n",
      "comprimento médio de código final no modelo treinado: 0.9416278678359963\n",
      "comprimento médio de código final no modelo treinado: 0.94708922984849\n",
      "comprimento médio de código final no modelo treinado: 0.9427896555366677\n",
      "comprimento médio de código final no modelo treinado: 0.9339605219490211\n",
      "comprimento médio de código final no modelo treinado: 0.9315936698398919\n"
     ]
    }
   ],
   "source": [
    "bit_list = [1073736,710427,437740,218967,96893,38163,13647,4317,1155]\n",
    "for i in bit_list:\n",
    "    tamanho_estimado = perfect_AC(yc[0:i, :],context_coding(Xc[0:i, :],context_training(Xt,yt)))\n",
    "    print(f\"\"\"comprimento médio de código final no modelo treinado: {tamanho_estimado}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f49d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
