{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c1f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ast\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f03fd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31bae972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_confs(ids_list):\n",
    "\n",
    "    identifier = str(int(time.time()))\n",
    "\n",
    "    all_keys = ['id','ModelClass','OptimizerClass','training_set','validation_set',\n",
    "                'epochs','learning_rate','batch_size','num_workers','device','parent_id',\n",
    "                'N_vec','phases','xscale']\n",
    "    non_string_keys = ['training_set','validation_set','epochs','learning_rate',\n",
    "                       'batch_size','num_workers','parent_id','N_vec','phases']\n",
    "    list_keys = ['training_set','validation_set','N_vec','phases']\n",
    "\n",
    "    ds = []\n",
    "    for i in ids_list:\n",
    "\n",
    "        d = pd.read_csv( f\"results/exp_{i}/exp_{i}_conf.csv\",index_col=0).T.replace(np.nan, '').to_dict(\n",
    "            orient='list')\n",
    "        d = {k:v[0] for k,v in d.items()}\n",
    "\n",
    "        for k,v in d.items():\n",
    "            if k in non_string_keys:\n",
    "                if v:\n",
    "                    d[k] = ast.literal_eval(v)\n",
    "\n",
    "        d['parent_id'] = d['parent_id'] if isinstance(d['parent_id'],list) else str(d['parent_id'])\n",
    "\n",
    "        ds.append( d )\n",
    "\n",
    "    new_d = dict()\n",
    "\n",
    "    for d in ds:\n",
    "        for k in all_keys:\n",
    "            if not isinstance(new_d.get(k),list):\n",
    "                new_d[k] = []\n",
    "            if isinstance(d[k],list):\n",
    "                new_d[k] += d[k]\n",
    "            else:\n",
    "                new_d[k].append(d[k])\n",
    "\n",
    "    new_d = {k:sorted(list(set(v))) for k,v in new_d.items()}\n",
    "\n",
    "    new_d = {k:(v[0] if (len(v)==1) and (k not in list_keys) else v) for k,v in new_d.items() }\n",
    "\n",
    "    new_d['parent_id'] = new_d['id']\n",
    "    new_d['id'] = identifier\n",
    "\n",
    "    return new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9b5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_src_name(ids_list,N):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ids_list : experiments ids given in order\n",
    "        N : size of neighborhood\n",
    "    \"\"\"\n",
    "    model_names = []\n",
    "    for i in ids_list:\n",
    "        model_name = f\"results/exp_{i}/exp_{i}_{N:03d}_model.pt\"\n",
    "        if os.path.isfile(model_name):\n",
    "            model_names.append(model_name)\n",
    "\n",
    "    return model_names[-1]\n",
    "\n",
    "def get_min_valid_loss_model_src_name(id_of_min_loss,N):\n",
    "    model_name = f\"results/exp_{id_of_min_loss}/exp_{id_of_min_loss}_{N:03d}_min_valid_loss_model.pt\"\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71bb9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_dst_name(identifier,N):\n",
    "    return f\"results/exp_{identifier}/exp_{identifier}_{N:03d}_model.pt\"\n",
    "\n",
    "def get_min_valid_loss_model_dst_name(identifier,N):\n",
    "    return f\"results/exp_{identifier}/exp_{identifier}_{N:03d}_min_valid_loss_model.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32d6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_N_data(ids_list,N,phase):\n",
    "    \"\"\"\n",
    "    The ids in ids_list must be given in order\n",
    "    \n",
    "    Args:\n",
    "        ids_list : experiments ids given in order\n",
    "        N : N data to marge\n",
    "        phase : phase to merge\n",
    "    \"\"\"\n",
    "    \n",
    "    csv_names = []\n",
    "    filtered_ids_list = []\n",
    "    for i in ids_list:\n",
    "        csv_name = f\"results/exp_{i}/exp_{i}_{N:03d}_{phase}_values.csv\"\n",
    "        if os.path.isfile(csv_name):\n",
    "            csv_names.append(csv_name)\n",
    "            filtered_ids_list.append(i)\n",
    "\n",
    "    dfs = []\n",
    "    mins_list = []\n",
    "    for i,csv_name in zip(filtered_ids_list,csv_names):\n",
    "        df = pd.read_csv( csv_name ,index_col=0)\n",
    "        mins_list.append(min(df['mlp'].values))\n",
    "#         print(f\"{i} min : {min(df['mlp'].values)} at index {np.argmin(df['mlp'].values)}\")\n",
    "#         print(f\"{i} last : {df['mlp'].values[-1]}\")\n",
    "        dfs.append( df )\n",
    "        \n",
    "    id_of_min_loss = filtered_ids_list[::-1][np.argmin(mins_list[::-1])]\n",
    "    \n",
    "    final_df = pd.concat(dfs, ignore_index=True,axis=0)\n",
    "    final_df.index.name = \"epoch\"\n",
    "    \n",
    "    return final_df , id_of_min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cab60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_empty_data(phases):\n",
    "    data = dict()\n",
    "    for phase in phases:\n",
    "        data[phase] = {\n",
    "            \"mlp\": [], \n",
    "            \"static\": [],    \n",
    "            \"cabac\": []          \n",
    "        }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "462fcd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_ids(ids_list):\n",
    "\n",
    "    configs = merge_confs(ids_list)\n",
    "    \n",
    "    os.makedirs(f'results/exp_{configs[\"id\"]}')\n",
    "\n",
    "    data = init_empty_data(configs[\"phases\"])\n",
    "\n",
    "    for N in configs[\"N_vec\"]:\n",
    "\n",
    "        print(f\"--------------------- context size : {N} ---------------------\")\n",
    "        \n",
    "        N_data = init_empty_data(configs[\"phases\"])\n",
    "\n",
    "        for phase in configs[\"phases\"]:\n",
    "            d,id_of_min_loss = merge_N_data(ids_list,N,phase)\n",
    "            N_data[phase] = d.to_dict(orient='list')\n",
    "            if (phase == 'valid') and ('train' in configs[\"phases\"]) and (N>0):\n",
    "                print(id_of_min_loss)\n",
    "#                 shutil.copy2(\n",
    "#                     get_min_valid_loss_model_src_name(id_of_min_loss,N), \n",
    "#                     get_min_valid_loss_model_dst_name(configs[\"id\"],N))\n",
    "\n",
    "        save_N_data({k: (v if k != 'epochs' else len(d.index.values)) for k,v in configs.items()},N,N_data)\n",
    "        \n",
    "        if ('train' in configs[\"phases\"]) and (N>0):\n",
    "            shutil.copy2(get_model_src_name(ids_list,N), get_model_dst_name(configs[\"id\"],N))\n",
    "\n",
    "        for phase in configs[\"phases\"]:\n",
    "#             data[phase][\"mlp\"].append(min(N_data[phase][\"mlp\"]))\n",
    "            data[phase][\"mlp\"].append(N_data[phase][\"mlp\"][-1])\n",
    "            data[phase][\"static\"].append(N_data[phase][\"static\"][-1])\n",
    "            data[phase][\"cabac\"].append(N_data[phase][\"cabac\"][-1])\n",
    "\n",
    "    save_final_data(configs,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f790a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_graph(fig,xvalues,values,linestyle,color,label,marker):\n",
    "    ax, = fig.axes\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_mlp_handle,= ax.plot(xvalues, values, linestyle=linestyle, color=color, \n",
    "                         label=label, marker=marker)\n",
    "    handles.append(new_mlp_handle)\n",
    "    ax.legend(handles=handles,loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef0f8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_labels(fig,old_labels,new_labels):\n",
    "    ax, = fig.axes\n",
    "    labels = ax.get_legend_handles_labels()[1]\n",
    "    for olb,nlb in zip(old_labels,new_labels):\n",
    "        labels[labels.index(olb)] = nlb\n",
    "    ax.legend(labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab5ec658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_ids([\"1649217265\",\"1649245701\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf23224",
   "metadata": {},
   "source": [
    "# Merging (graph for very large N - up to 170)\n",
    "\n",
    "1646351538 : training on page 3 ; validation on page 5; MLP_N_64N_32N_1; neighborhoods 0, 2, 4, 10, 26, 67, 170; 420 epochs; 1e-05 learning_rate; 2048 batch size; parents 1646255547, 1646256140 and 1646334695 .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86cbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_list = [\"1646108338\", \"1646138205\" , \"1646147306\", \"1646182637\"] #-> 1646255547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50470606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = merge_N_data(ids_list,170,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07fd4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d1132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(d.index,d['mlp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77ccf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_ids(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53bf0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import filecmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e671a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filecmp.cmp(\"results/exp_1646255547_170_model.pt\" , \"results/exp_1646147306_170_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f38e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_list = [\"1646255547\",\"1646256140\",\"1646334695\"] #-> 1646351538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "765c862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_ids(ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d22c5",
   "metadata": {},
   "source": [
    "# Abandoned Experiment : limiting the hidden units for N=67 and 170\n",
    "\n",
    "1646351538 : training on page 3 ; validation on page 5; MLP_N_64N_32N_1; neighborhoods 0, 2, 4, 10, 26, 67, 170; 420 epochs; 1e-05 learning_rate; 2048 batch size; parents 1646255547, 1646256140 and 1646334695 .\n",
    "\n",
    "1646397720 : training on page 3 ; validation on page 5; MLP_N_2048_1024_1; neighborhoods 67, 170; 420 epochs; 1e-05 learning_rate; 2048 batch size . \n",
    "\n",
    "1646523973 : training on pages 1 and 3 ; validation on page 5; MLP_N_64N_32N_1 and MLP_N_2048_1024_1; neighborhoods 0, 2, 4, 10, 26, 67, 170; 420 epochs; 1e-05 learning_rate; 2048 batch size; parents 1646427815, 1646449472 and 1646504279 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba68ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_list = [\"1646427815\",\"1646449472\",\"1646504279\"] #-> 1646523973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52597080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_ids(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6402544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = dict()\n",
    "new_data[\"train\"] = dict() \n",
    "new_data[\"train\"][\"mlp\"] = pd.read_csv( f\"results/exp_1646397720_train_values.csv\" ,index_col=0)['mlp'].values\n",
    "new_data[\"valid\"] = dict() \n",
    "new_data[\"valid\"][\"mlp\"] =pd.read_csv( f\"results/exp_1646397720_valid_values.csv\" ,index_col=0)['mlp'].values\n",
    "data = dict()\n",
    "data['train'] = pd.read_csv( f\"results/exp_1646351538_train_values.csv\" ,index_col=0).to_dict(orient=\"list\")\n",
    "data['valid'] = pd.read_csv( f\"results/exp_1646351538_valid_values.csv\" ,index_col=0).to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f5172d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t = plot_comparison([0,2,4,10,26,67,170],data['train'],\"context size\",xscale = \"symlog\")\n",
    "append_graph(fig_t,[67,170],new_data[\"train\"][\"mlp\"],'dashed','blue','mlp*','o')\n",
    "fig_v = plot_comparison([0,2,4,10,26,67,170],data['valid'],\"context size\",xscale = \"symlog\")\n",
    "append_graph(fig_v,[67,170],new_data[\"valid\"][\"mlp\"],'dashed','blue','mlp*','o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9516e4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33c250d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88816dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train']['mlp'][-2:] = new_data[\"train\"][\"mlp\"]\n",
    "data['valid']['mlp'][-2:] = new_data[\"valid\"][\"mlp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56963a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t = plot_comparison([0,2,4,10,26,67,170],data['train'],\"context size\",xscale = \"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dfaf7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_v = plot_comparison([0,2,4,10,26,67,170],data['valid'],\"context size\",xscale = \"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f602b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data = dict()\n",
    "other_data['train'] = pd.read_csv( f\"results/exp_1646523973_train_values.csv\" ,index_col=0).to_dict(orient=\"list\")\n",
    "other_data['valid'] = pd.read_csv( f\"results/exp_1646523973_valid_values.csv\" ,index_col=0).to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d43054b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_t,[0,2,4,10,26,67,170],other_data[\"train\"][\"mlp\"],'dashed','blue','mlp*','o')\n",
    "append_graph(fig_t,[0,2,4,10,26],other_data[\"train\"][\"cabac\"][:-2],'dashed','green','cabac*','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5072801",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_v,[0,2,4,10,26,67,170],other_data[\"valid\"][\"mlp\"],'dashed','blue','mlp*','o')\n",
    "append_graph(fig_v,[0,2,4,10,26],other_data[\"valid\"][\"cabac\"][:-2],'dashed','green','cabac*','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f79688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54145327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508cd5b",
   "metadata": {},
   "source": [
    "# Impact of the amount of pages in the training set\n",
    "\n",
    "1646735060 : training on pages 1 and 3 ; validation on page 5; MLP_N_64N_32N_1; neighborhoods 0, 2, 4, 10, 26, 67, 170; 420 epochs; 1e-05 learning_rate; 2048 batch size; parents 1646449472 and 1646527898 . \n",
    "\n",
    "1646351538 : training on page 3 ; validation on page 5; MLP_N_64N_32N_1; neighborhoods 0, 2, 4, 10, 26, 67, 170; 420 epochs; 1e-05 learning_rate; 2048 batch size; parents 1646255547, 1646256140 and 1646334695 .\n",
    "\n",
    "linestyles : https://matplotlib.org/2.1.2/api/_as_gen/matplotlib.pyplot.plot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a7928ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_list = [\"1646449472\",\"1646527898\"] # -> 1646735060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "766ae3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_ids(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2d63a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = dict()\n",
    "data3['train'] = pd.read_csv( f\"results/exp_1646351538_train_values.csv\" ,index_col=0).to_dict(orient=\"list\")\n",
    "data3['valid'] = pd.read_csv( f\"results/exp_1646351538_valid_values.csv\" ,index_col=0).to_dict(orient=\"list\")\n",
    "fig_t = plot_comparison([0,2,4,10,26,67,170],data3['train'],\"context size\",xscale = \"symlog\")\n",
    "fig_v = plot_comparison([0,2,4,10,26,67,170],data3['valid'],\"context size\",xscale = \"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d630fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data13 = dict()\n",
    "data13['train'] = pd.read_csv( f\"results/exp_1646735060_train_values.csv\" ,index_col=0).to_dict(orient=\"list\")\n",
    "data13['valid'] = pd.read_csv( f\"results/exp_1646735060_valid_values.csv\" ,index_col=0).to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d75be6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_t,[0,2,4,10,26,67,170],data13[\"train\"][\"mlp\"],'dashed',(0.2,0,0.8),'mlp (pp.1,3)','o')\n",
    "append_graph(fig_t,[0,2,4,10,26],data13[\"train\"][\"cabac\"][:-2],'dashed',(0.2,0.8,0),'cabac (pp.1,3)','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5711d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_v,[0,2,4,10,26,67,170],data13[\"valid\"][\"mlp\"],'dashed',(0.2,0,0.8),'mlp (pp.1,3)','o')\n",
    "append_graph(fig_v,[0,2,4,10,26],data13[\"valid\"][\"cabac\"][:-2],'dashed',(0.2,0.8,0),'cabac (pp.1,3)','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed3fa0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data123 = dict()\n",
    "data123['train'] = pd.read_csv( f\"results/exp_1647694682_train_values.csv\" ,index_col=0).to_dict(orient=\"list\")\n",
    "data123['valid'] = pd.read_csv( f\"results/exp_1647694682_valid_values.csv\" ,index_col=0).to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03b4a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_t,[0,2,4,10,26,67,170],data123[\"train\"][\"mlp\"],'dotted',(0.4,0,0.6),'mlp (pp.1,2,3)','o')\n",
    "append_graph(fig_t,[0,2,4,10,26],data123[\"train\"][\"cabac\"][:-2],'dotted',(0.4,0.6,0),'cabac (pp.1,2,3)','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18c386af",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_v,[0,2,4,10,26,67,170],data123[\"valid\"][\"mlp\"],'dotted',(0.4,0,0.6),'mlp (pp.1,2,3)','o')\n",
    "append_graph(fig_v,[0,2,4,10,26],data123[\"valid\"][\"cabac\"][:-2],'dotted',(0.4,0.6,0),'cabac (pp.1,2,3)','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd584849",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1234 = dict()\n",
    "data1234['train'] = pd.read_csv( f\"results/exp_1647894746_train_values.csv\" ,index_col=0).to_dict(orient=\"list\")\n",
    "data1234['valid'] = pd.read_csv( f\"results/exp_1647894746_valid_values.csv\" ,index_col=0).to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "964890c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_t,[0,2,4,10,26,67,170],data1234[\"train\"][\"mlp\"],'dashdot',(0.6,0,0.4),'mlp (pp.1,2,3,4)','o')\n",
    "append_graph(fig_t,[0,2,4,10,26],data1234[\"train\"][\"cabac\"][:-2],'dashdot',(0.6,0.4,0),'cabac (pp.1,2,3,4)','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a80a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_graph(fig_v,[0,2,4,10,26,67,170],data1234[\"valid\"][\"mlp\"],'dashdot',(0.6,0,0.4),'mlp (pp.1,2,3,4)','o')\n",
    "append_graph(fig_v,[0,2,4,10,26],data1234[\"valid\"][\"cabac\"][:-2],'dashdot',(0.6,0.4,0),'cabac (pp.1,2,3,4)','^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da614b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_labels(fig_t,['mlp','cabac'],['mlp (p.3)','cabac (p.3)'])\n",
    "replace_labels(fig_v,['mlp','cabac'],['mlp (p.3)','cabac (p.3)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4761ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "044e7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96cfb121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_fig(f\"results/exp_1646351538_1646735060_1647694682_1647894746_train_graph\",fig_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "904790c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_fig(f\"results/exp_1646351538_1646735060_1647694682_1647894746_valid_graph\",fig_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b96f7",
   "metadata": {},
   "source": [
    "# Seeing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee71c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv( f\"results/exp_1646396496_valid_values.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1feb6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv( f\"results/exp_1646735060_valid_values.csv\" ,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014bfcfe",
   "metadata": {},
   "source": [
    "# Varying pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from perceptronac.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afee17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_list = [\"1646351538\",\"1646735060\",\"1647694682\",\"1647894746\",\"1648672366\",\n",
    "            \"1648693742\",\"1648724675\",\"1648767269\",\"1648810180\",\"1648845111\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ab357",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data['train'] = dict()\n",
    "data['valid'] = dict()\n",
    "data['train']['mlp'] = []\n",
    "data['valid']['mlp'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ca131",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ids_list:\n",
    "    data['train']['mlp'].append(pd.read_csv(f\"results/exp_{i}_train_values.csv\",index_col=0).loc[67,'mlp'])\n",
    "    data['valid']['mlp'].append(pd.read_csv(f\"results/exp_{i}_valid_values.csv\",index_col=0).loc[67,'mlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_t = plot_comparison(np.arange(1,11),data['train'],\"number of pages\",xscale = \"linear\")\n",
    "fig_t.axes[0].set_xticks(np.arange(1,11))\n",
    "fig_t.axes[0].legend(['mlp N=67'])\n",
    "fig_v = plot_comparison(np.arange(1,11),data['valid'],\"number of pages\",xscale = \"linear\")\n",
    "fig_v.axes[0].set_xticks(np.arange(1,11))\n",
    "fig_v.axes[0].legend(['mlp N=67'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(f\"results/exp_1646351538_to_1648845111_067_valid_graph\",fig_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0928396",
   "metadata": {},
   "source": [
    "# Average graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1dadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from perceptronac.utils import plot_comparison\n",
    "from perceptronac.utils import save_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19092fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_avg = [\n",
    "  \"1648504002\",  \"1648505291\",  \"1648506606\",  \"1648508102\",  \"1648509733\",\n",
    "  \"1648504655\",  \"1648505962\",  \"1648507460\",  \"1648508751\",  \"1648510660\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_experiments(ids):\n",
    "\n",
    "    dfs = []\n",
    "    for i_d in ids:\n",
    "        dfs.append(pd.read_csv( f\"results/exp_{i_d}/exp_{i_d}_valid_values.csv\" ,index_col=0))\n",
    "\n",
    "    assert len(set([len(df.index.values) for df in dfs])) == 1\n",
    "    assert len(set([v for df in dfs for v in df.index.values]) ) == len(dfs[0].index.values)\n",
    "\n",
    "    assert len(set([len(df.columns) for df in dfs])) == 1\n",
    "    assert len(set([v for df in dfs for v in df.columns]) ) == len(dfs[0].columns)\n",
    "\n",
    "    new_df = pd.DataFrame(\n",
    "        data = np.zeros((len(dfs[0].index.values),len(dfs[0].columns))),\n",
    "        columns=dfs[0].columns, index=dfs[0].index.values)\n",
    "\n",
    "    for R in dfs[0].index.values:\n",
    "        for C in dfs[0].columns:\n",
    "            for df in dfs:\n",
    "                new_df.loc[R,C] = new_df.loc[R,C] + df.loc[R,C] \n",
    "\n",
    "    return new_df/len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafdb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=average_experiments(ids_to_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3627b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_v = plot_comparison(new_df.index.values,new_df.to_dict(orient=\"list\"),\"context size\",xscale = \"symlog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(f\"results/exp_1648504002_to_1648510660_valid_graph\",fig_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv( f\"results/exp_1648083609/exp_1648083609_train_values.csv\" ,index_col=0)[::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
