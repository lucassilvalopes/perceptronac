{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633ef8a1",
   "metadata": {},
   "source": [
    "# MLP Coding Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d99b2f",
   "metadata": {},
   "source": [
    "Acesse o servidor remoto por ssh. Crie uma virtualenv com:\n",
    "```\n",
    "mkvirtualenv <nome-da-sua-env>\n",
    "```\n",
    "Ative a sua virtualenv com:\n",
    "```\n",
    "workon <nome-da-sua-env>\n",
    "```\n",
    "Instale o jupyter:\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "Na pasta contendo o setup.py, instale o pacote do projeto :\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "Comando para servir o jupyter:\n",
    "```\n",
    "nohup jupyter notebook --no-browser &\n",
    "```\n",
    "Talvez você precise de um token. Se precisar consulte com:\n",
    "```\n",
    "jupyter notebook list\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Na sua máquina local, redirecione a porta adequada:\n",
    "```\n",
    "ssh -NfL localhost:<porta-local>:localhost:<porta-remoto> <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Geralmente:\n",
    "```\n",
    "ssh -NfL localhost:8888:localhost:8888 <seu-usuario>@<ip-do-servidor>\n",
    "```\n",
    "Abra localhost:8888 no seu browser. Se você quiser fechar o jupyter, no localhost:8888 clique em Quit, depois libere a porta com:\n",
    "```\n",
    "lsof -ti:8888 | xargs kill -9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a80402",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from perceptronac.context_training import context_training\n",
    "from perceptronac.context_coding import context_coding\n",
    "from perceptronac.perfect_AC import perfect_AC\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f6660",
   "metadata": {},
   "source": [
    "## Gerando dados randômicos correlacionados (substituir pelos seus dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters  \n",
    "L = 100000 # how many samples \n",
    "N = 7 # order of the AR\n",
    "# Np = N # number of parameters to estimate \n",
    "\n",
    "C0 = np.random.rand(1,1) \n",
    "C = np.random.rand(N,1)\n",
    "\n",
    "X = 2 * (np.random.rand(2*L,N) > 0.5) - 1 # correlated (context) signals\n",
    "\n",
    "X = (X > 0).astype(int)\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "\n",
    "p = sigmoid(C0 + X @ C);\n",
    "yy = (np.random.rand(2*L, 1) > (1 - p)).astype(int) # signal \n",
    "yt = yy[0:L] > 0 # train on the first part \n",
    "yc = yy[L:L+L] > 0 # encode the second part\n",
    "Xt = X[0:L,0:N] # truncated X for training \n",
    "Xc = X[L:L+L,0:N] # truncated X for coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafab0",
   "metadata": {},
   "source": [
    "## Entropia dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3568ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6231081471345179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treino\n",
    "perfect_AC(yt,context_coding(Xt,context_training(Xt,yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a687d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6211330550586928"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teste\n",
    "perfect_AC(yc,context_coding(Xc,context_training(Xc,yc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274d7ca",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Batch Gradient Descent (Quando todos os dados couberem na memória da placa de vídeo de uma só vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9753993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bda4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(N, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ccf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log2BCELoss(torch.nn.Module):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__()\n",
    "        self.bce_loss = torch.nn.BCELoss(*args,**kwargs)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return self.bce_loss(pred, target)/torch.log(torch.tensor(2,dtype=target.dtype,device=target.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx,:],self.y[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f6c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c39627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f61bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ac96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cb79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(torch.tensor(trainset.X).float().cuda())\n",
    "    loss = criterion(outputs,torch.tensor(trainset.y).view(-1,1).float().cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss.append(loss.item()/len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bcf67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.62384859375\n",
      "(compare com a entropia do dataset de treino).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a87913",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af09293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9022, 0.6098, 0.7072, 0.0310, 0.1403, 0.0376, 0.9343]],\n",
      "       device='cuda:0')\n",
      "tensor([0.0158], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d47017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.89106724, 0.62633137, 0.70989337, 0.03960594, 0.1334368 ,\n",
       "         0.03148984, 0.92488601]]),\n",
       " array([[0.01856426]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50b273",
   "metadata": {},
   "source": [
    "## Treinando Modelo No Pytorch com Stochastic Gradient Descent (um pedaço dos dados na memória da placa de vídeo de cada vez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14cf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Perceptron(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807a7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3bce1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(Xt,yt)\n",
    "validset = CustomDataset(Xc,yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9903ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Log2BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f8bad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 , phase : train , loss : 0.976436171875\n",
      "epoch : 0 , phase : valid , loss : 0.65307\n",
      "epoch : 1 , phase : train , loss : 0.65563890625\n",
      "epoch : 1 , phase : valid , loss : 0.644643125\n",
      "epoch : 2 , phase : train , loss : 0.647405546875\n",
      "epoch : 2 , phase : valid , loss : 0.641886796875\n",
      "epoch : 3 , phase : train , loss : 0.644700078125\n",
      "epoch : 3 , phase : valid , loss : 0.640156015625\n",
      "epoch : 4 , phase : train , loss : 0.64296703125\n",
      "epoch : 4 , phase : valid , loss : 0.638736953125\n",
      "epoch : 5 , phase : train , loss : 0.6415239453125\n",
      "epoch : 5 , phase : valid , loss : 0.6374794921875\n",
      "epoch : 6 , phase : train , loss : 0.6402335546875\n",
      "epoch : 6 , phase : valid , loss : 0.6363410546875\n",
      "epoch : 7 , phase : train , loss : 0.639059140625\n",
      "epoch : 7 , phase : valid , loss : 0.6353037109375\n",
      "epoch : 8 , phase : train , loss : 0.6379853125\n",
      "epoch : 8 , phase : valid , loss : 0.6343559375\n",
      "epoch : 9 , phase : train , loss : 0.6370019140625\n",
      "epoch : 9 , phase : valid , loss : 0.6334887890625\n",
      "epoch : 10 , phase : train , loss : 0.6361003515625\n",
      "epoch : 10 , phase : valid , loss : 0.632694453125\n",
      "epoch : 11 , phase : train , loss : 0.635273046875\n",
      "epoch : 11 , phase : valid , loss : 0.6319661328125\n",
      "epoch : 12 , phase : train , loss : 0.63451328125\n",
      "epoch : 12 , phase : valid , loss : 0.63129765625\n",
      "epoch : 13 , phase : train , loss : 0.6338148828125\n",
      "epoch : 13 , phase : valid , loss : 0.6306837109375\n",
      "epoch : 14 , phase : train , loss : 0.633172265625\n",
      "epoch : 14 , phase : valid , loss : 0.63011890625\n",
      "epoch : 15 , phase : train , loss : 0.632580390625\n",
      "epoch : 15 , phase : valid , loss : 0.62959921875\n",
      "epoch : 16 , phase : train , loss : 0.632034765625\n",
      "epoch : 16 , phase : valid , loss : 0.6291203515625\n",
      "epoch : 17 , phase : train , loss : 0.631531171875\n",
      "epoch : 17 , phase : valid , loss : 0.6286787109375\n",
      "epoch : 18 , phase : train , loss : 0.631066015625\n",
      "epoch : 18 , phase : valid , loss : 0.628271015625\n",
      "epoch : 19 , phase : train , loss : 0.6306359375\n",
      "epoch : 19 , phase : valid , loss : 0.6278942578125\n",
      "epoch : 20 , phase : train , loss : 0.630237734375\n",
      "epoch : 20 , phase : valid , loss : 0.627545625\n",
      "epoch : 21 , phase : train , loss : 0.6298687109375\n",
      "epoch : 21 , phase : valid , loss : 0.627222890625\n",
      "epoch : 22 , phase : train , loss : 0.62952640625\n",
      "epoch : 22 , phase : valid , loss : 0.62692359375\n",
      "epoch : 23 , phase : train , loss : 0.629208515625\n",
      "epoch : 23 , phase : valid , loss : 0.626645859375\n",
      "epoch : 24 , phase : train , loss : 0.6289129296875\n",
      "epoch : 24 , phase : valid , loss : 0.6263878515625\n",
      "epoch : 25 , phase : train , loss : 0.6286380078125\n",
      "epoch : 25 , phase : valid , loss : 0.626147890625\n",
      "epoch : 26 , phase : train , loss : 0.62838171875\n",
      "epoch : 26 , phase : valid , loss : 0.625924453125\n",
      "epoch : 27 , phase : train , loss : 0.62814265625\n",
      "epoch : 27 , phase : valid , loss : 0.625716328125\n",
      "epoch : 28 , phase : train , loss : 0.627919609375\n",
      "epoch : 28 , phase : valid , loss : 0.62552203125\n",
      "epoch : 29 , phase : train , loss : 0.62771109375\n",
      "epoch : 29 , phase : valid , loss : 0.625340546875\n",
      "epoch : 30 , phase : train , loss : 0.6275159765625\n",
      "epoch : 30 , phase : valid , loss : 0.6251710546875\n",
      "epoch : 31 , phase : train , loss : 0.62733328125\n",
      "epoch : 31 , phase : valid , loss : 0.6250122265625\n",
      "epoch : 32 , phase : train , loss : 0.6271619140625\n",
      "epoch : 32 , phase : valid , loss : 0.624863515625\n",
      "epoch : 33 , phase : train , loss : 0.627001171875\n",
      "epoch : 33 , phase : valid , loss : 0.6247241015625\n",
      "epoch : 34 , phase : train , loss : 0.62685015625\n",
      "epoch : 34 , phase : valid , loss : 0.6245931640625\n",
      "epoch : 35 , phase : train , loss : 0.6267080859375\n",
      "epoch : 35 , phase : valid , loss : 0.6244701953125\n",
      "epoch : 36 , phase : train , loss : 0.6265744140625\n",
      "epoch : 36 , phase : valid , loss : 0.624354453125\n",
      "epoch : 37 , phase : train , loss : 0.626448515625\n",
      "epoch : 37 , phase : valid , loss : 0.6242455859375\n",
      "epoch : 38 , phase : train , loss : 0.626329765625\n",
      "epoch : 38 , phase : valid , loss : 0.624142890625\n",
      "epoch : 39 , phase : train , loss : 0.62621765625\n",
      "epoch : 39 , phase : valid , loss : 0.6240462109375\n",
      "epoch : 40 , phase : train , loss : 0.6261118359375\n",
      "epoch : 40 , phase : valid , loss : 0.623954765625\n",
      "epoch : 41 , phase : train , loss : 0.6260117578125\n",
      "epoch : 41 , phase : valid , loss : 0.6238684375\n",
      "epoch : 42 , phase : train , loss : 0.625916953125\n",
      "epoch : 42 , phase : valid , loss : 0.623786796875\n",
      "epoch : 43 , phase : train , loss : 0.6258272265625\n",
      "epoch : 43 , phase : valid , loss : 0.6237096484375\n",
      "epoch : 44 , phase : train , loss : 0.6257421875\n",
      "epoch : 44 , phase : valid , loss : 0.623636484375\n",
      "epoch : 45 , phase : train , loss : 0.6256616015625\n",
      "epoch : 45 , phase : valid , loss : 0.6235670703125\n",
      "epoch : 46 , phase : train , loss : 0.6255850390625\n",
      "epoch : 46 , phase : valid , loss : 0.6235014453125\n",
      "epoch : 47 , phase : train , loss : 0.62551234375\n",
      "epoch : 47 , phase : valid , loss : 0.6234390234375\n",
      "epoch : 48 , phase : train , loss : 0.6254431640625\n",
      "epoch : 48 , phase : valid , loss : 0.6233797265625\n",
      "epoch : 49 , phase : train , loss : 0.625377421875\n",
      "epoch : 49 , phase : valid , loss : 0.623323359375\n",
      "epoch : 50 , phase : train , loss : 0.6253148046875\n",
      "epoch : 50 , phase : valid , loss : 0.62326984375\n",
      "epoch : 51 , phase : train , loss : 0.625255234375\n",
      "epoch : 51 , phase : valid , loss : 0.6232187890625\n",
      "epoch : 52 , phase : train , loss : 0.6251984375\n",
      "epoch : 52 , phase : valid , loss : 0.6231702734375\n",
      "epoch : 53 , phase : train , loss : 0.6251442578125\n",
      "epoch : 53 , phase : valid , loss : 0.6231240625\n",
      "epoch : 54 , phase : train , loss : 0.6250925390625\n",
      "epoch : 54 , phase : valid , loss : 0.6230799609375\n",
      "epoch : 55 , phase : train , loss : 0.6250432421875\n",
      "epoch : 55 , phase : valid , loss : 0.6230379296875\n",
      "epoch : 56 , phase : train , loss : 0.6249961328125\n",
      "epoch : 56 , phase : valid , loss : 0.6229978515625\n",
      "epoch : 57 , phase : train , loss : 0.6249511328125\n",
      "epoch : 57 , phase : valid , loss : 0.62295953125\n",
      "epoch : 58 , phase : train , loss : 0.6249080859375\n",
      "epoch : 58 , phase : valid , loss : 0.62292296875\n",
      "epoch : 59 , phase : train , loss : 0.624866953125\n",
      "epoch : 59 , phase : valid , loss : 0.622888046875\n",
      "epoch : 60 , phase : train , loss : 0.6248275390625\n",
      "epoch : 60 , phase : valid , loss : 0.6228546875\n",
      "epoch : 61 , phase : train , loss : 0.62478984375\n",
      "epoch : 61 , phase : valid , loss : 0.6228227734375\n",
      "epoch : 62 , phase : train , loss : 0.624753828125\n",
      "epoch : 62 , phase : valid , loss : 0.6227922265625\n",
      "epoch : 63 , phase : train , loss : 0.6247192578125\n",
      "epoch : 63 , phase : valid , loss : 0.62276296875\n",
      "epoch : 64 , phase : train , loss : 0.624686171875\n",
      "epoch : 64 , phase : valid , loss : 0.6227350390625\n",
      "epoch : 65 , phase : train , loss : 0.624654375\n",
      "epoch : 65 , phase : valid , loss : 0.622708203125\n",
      "epoch : 66 , phase : train , loss : 0.6246239453125\n",
      "epoch : 66 , phase : valid , loss : 0.6226826171875\n",
      "epoch : 67 , phase : train , loss : 0.6245948046875\n",
      "epoch : 67 , phase : valid , loss : 0.622658046875\n",
      "epoch : 68 , phase : train , loss : 0.6245667578125\n",
      "epoch : 68 , phase : valid , loss : 0.6226344921875\n",
      "epoch : 69 , phase : train , loss : 0.6245398828125\n",
      "epoch : 69 , phase : valid , loss : 0.622611953125\n",
      "epoch : 70 , phase : train , loss : 0.6245140625\n",
      "epoch : 70 , phase : valid , loss : 0.6225903125\n",
      "epoch : 71 , phase : train , loss : 0.6244892578125\n",
      "epoch : 71 , phase : valid , loss : 0.6225695703125\n",
      "epoch : 72 , phase : train , loss : 0.62446546875\n",
      "epoch : 72 , phase : valid , loss : 0.622549609375\n",
      "epoch : 73 , phase : train , loss : 0.624442578125\n",
      "epoch : 73 , phase : valid , loss : 0.622530625\n",
      "epoch : 74 , phase : train , loss : 0.6244207421875\n",
      "epoch : 74 , phase : valid , loss : 0.622512265625\n",
      "epoch : 75 , phase : train , loss : 0.62439953125\n",
      "epoch : 75 , phase : valid , loss : 0.6224946875\n",
      "epoch : 76 , phase : train , loss : 0.624379296875\n",
      "epoch : 76 , phase : valid , loss : 0.6224778125\n",
      "epoch : 77 , phase : train , loss : 0.624359765625\n",
      "epoch : 77 , phase : valid , loss : 0.622461640625\n",
      "epoch : 78 , phase : train , loss : 0.6243410546875\n",
      "epoch : 78 , phase : valid , loss : 0.62244609375\n",
      "epoch : 79 , phase : train , loss : 0.6243230078125\n",
      "epoch : 79 , phase : valid , loss : 0.622431171875\n",
      "epoch : 80 , phase : train , loss : 0.6243056640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 80 , phase : valid , loss : 0.6224168359375\n",
      "epoch : 81 , phase : train , loss : 0.624288984375\n",
      "epoch : 81 , phase : valid , loss : 0.6224030859375\n",
      "epoch : 82 , phase : train , loss : 0.624272890625\n",
      "epoch : 82 , phase : valid , loss : 0.622389921875\n",
      "epoch : 83 , phase : train , loss : 0.6242574609375\n",
      "epoch : 83 , phase : valid , loss : 0.6223772265625\n",
      "epoch : 84 , phase : train , loss : 0.62424265625\n",
      "epoch : 84 , phase : valid , loss : 0.6223649609375\n",
      "epoch : 85 , phase : train , loss : 0.6242283203125\n",
      "epoch : 85 , phase : valid , loss : 0.62235328125\n",
      "epoch : 86 , phase : train , loss : 0.62421453125\n",
      "epoch : 86 , phase : valid , loss : 0.6223419921875\n",
      "epoch : 87 , phase : train , loss : 0.6242012890625\n",
      "epoch : 87 , phase : valid , loss : 0.622331171875\n",
      "epoch : 88 , phase : train , loss : 0.6241884765625\n",
      "epoch : 88 , phase : valid , loss : 0.6223208203125\n",
      "epoch : 89 , phase : train , loss : 0.6241762109375\n",
      "epoch : 89 , phase : valid , loss : 0.622310859375\n",
      "epoch : 90 , phase : train , loss : 0.6241644140625\n",
      "epoch : 90 , phase : valid , loss : 0.6223012109375\n",
      "epoch : 91 , phase : train , loss : 0.62415296875\n",
      "epoch : 91 , phase : valid , loss : 0.62229203125\n",
      "epoch : 92 , phase : train , loss : 0.6241419921875\n",
      "epoch : 92 , phase : valid , loss : 0.6222831640625\n",
      "epoch : 93 , phase : train , loss : 0.6241314453125\n",
      "epoch : 93 , phase : valid , loss : 0.6222746484375\n",
      "epoch : 94 , phase : train , loss : 0.62412125\n",
      "epoch : 94 , phase : valid , loss : 0.622266484375\n",
      "epoch : 95 , phase : train , loss : 0.6241114453125\n",
      "epoch : 95 , phase : valid , loss : 0.62225859375\n",
      "epoch : 96 , phase : train , loss : 0.6241019921875\n",
      "epoch : 96 , phase : valid , loss : 0.62225109375\n",
      "epoch : 97 , phase : train , loss : 0.624092890625\n",
      "epoch : 97 , phase : valid , loss : 0.622243828125\n",
      "epoch : 98 , phase : train , loss : 0.6240841796875\n",
      "epoch : 98 , phase : valid , loss : 0.6222368359375\n",
      "epoch : 99 , phase : train , loss : 0.624075625\n",
      "epoch : 99 , phase : valid , loss : 0.62223015625\n",
      "epoch : 100 , phase : train , loss : 0.6240675\n",
      "epoch : 100 , phase : valid , loss : 0.622223671875\n",
      "epoch : 101 , phase : train , loss : 0.6240596484375\n",
      "epoch : 101 , phase : valid , loss : 0.6222174609375\n",
      "epoch : 102 , phase : train , loss : 0.624052109375\n",
      "epoch : 102 , phase : valid , loss : 0.6222116015625\n",
      "epoch : 103 , phase : train , loss : 0.62404484375\n",
      "epoch : 103 , phase : valid , loss : 0.622205859375\n",
      "epoch : 104 , phase : train , loss : 0.6240378515625\n",
      "epoch : 104 , phase : valid , loss : 0.6222003125\n",
      "epoch : 105 , phase : train , loss : 0.6240309765625\n",
      "epoch : 105 , phase : valid , loss : 0.622195078125\n",
      "epoch : 106 , phase : train , loss : 0.6240244921875\n",
      "epoch : 106 , phase : valid , loss : 0.62219\n",
      "epoch : 107 , phase : train , loss : 0.6240182421875\n",
      "epoch : 107 , phase : valid , loss : 0.6221851171875\n",
      "epoch : 108 , phase : train , loss : 0.6240121484375\n",
      "epoch : 108 , phase : valid , loss : 0.6221805078125\n",
      "epoch : 109 , phase : train , loss : 0.6240062890625\n",
      "epoch : 109 , phase : valid , loss : 0.6221759765625\n",
      "epoch : 110 , phase : train , loss : 0.6240006640625\n",
      "epoch : 110 , phase : valid , loss : 0.622171640625\n",
      "epoch : 111 , phase : train , loss : 0.623995234375\n",
      "epoch : 111 , phase : valid , loss : 0.6221675390625\n",
      "epoch : 112 , phase : train , loss : 0.62399\n",
      "epoch : 112 , phase : valid , loss : 0.62216359375\n",
      "epoch : 113 , phase : train , loss : 0.623985\n",
      "epoch : 113 , phase : valid , loss : 0.622159765625\n",
      "epoch : 114 , phase : train , loss : 0.623980078125\n",
      "epoch : 114 , phase : valid , loss : 0.62215609375\n",
      "epoch : 115 , phase : train , loss : 0.623975390625\n",
      "epoch : 115 , phase : valid , loss : 0.6221525390625\n",
      "epoch : 116 , phase : train , loss : 0.6239708984375\n",
      "epoch : 116 , phase : valid , loss : 0.6221491796875\n",
      "epoch : 117 , phase : train , loss : 0.6239665234375\n",
      "epoch : 117 , phase : valid , loss : 0.6221458984375\n",
      "epoch : 118 , phase : train , loss : 0.62396234375\n",
      "epoch : 118 , phase : valid , loss : 0.622142734375\n",
      "epoch : 119 , phase : train , loss : 0.62395828125\n",
      "epoch : 119 , phase : valid , loss : 0.6221398046875\n",
      "epoch : 120 , phase : train , loss : 0.623954453125\n",
      "epoch : 120 , phase : valid , loss : 0.6221369921875\n",
      "epoch : 121 , phase : train , loss : 0.623950625\n",
      "epoch : 121 , phase : valid , loss : 0.6221341796875\n",
      "epoch : 122 , phase : train , loss : 0.6239469921875\n",
      "epoch : 122 , phase : valid , loss : 0.6221315625\n",
      "epoch : 123 , phase : train , loss : 0.6239434375\n",
      "epoch : 123 , phase : valid , loss : 0.622128984375\n",
      "epoch : 124 , phase : train , loss : 0.62394\n",
      "epoch : 124 , phase : valid , loss : 0.6221265234375\n",
      "epoch : 125 , phase : train , loss : 0.623936875\n",
      "epoch : 125 , phase : valid , loss : 0.6221241796875\n",
      "epoch : 126 , phase : train , loss : 0.6239337109375\n",
      "epoch : 126 , phase : valid , loss : 0.622121953125\n",
      "epoch : 127 , phase : train , loss : 0.623930625\n",
      "epoch : 127 , phase : valid , loss : 0.62211984375\n",
      "epoch : 128 , phase : train , loss : 0.623927734375\n",
      "epoch : 128 , phase : valid , loss : 0.6221178125\n",
      "epoch : 129 , phase : train , loss : 0.6239249609375\n",
      "epoch : 129 , phase : valid , loss : 0.62211578125\n",
      "epoch : 130 , phase : train , loss : 0.6239221484375\n",
      "epoch : 130 , phase : valid , loss : 0.6221138671875\n",
      "epoch : 131 , phase : train , loss : 0.6239195703125\n",
      "epoch : 131 , phase : valid , loss : 0.6221120703125\n",
      "epoch : 132 , phase : train , loss : 0.6239170703125\n",
      "epoch : 132 , phase : valid , loss : 0.622110390625\n",
      "epoch : 133 , phase : train , loss : 0.6239146484375\n",
      "epoch : 133 , phase : valid , loss : 0.6221087109375\n",
      "epoch : 134 , phase : train , loss : 0.6239123046875\n",
      "epoch : 134 , phase : valid , loss : 0.622107109375\n",
      "epoch : 135 , phase : train , loss : 0.6239100390625\n",
      "epoch : 135 , phase : valid , loss : 0.622105546875\n",
      "epoch : 136 , phase : train , loss : 0.6239077734375\n",
      "epoch : 136 , phase : valid , loss : 0.622104140625\n",
      "epoch : 137 , phase : train , loss : 0.6239057421875\n",
      "epoch : 137 , phase : valid , loss : 0.622102734375\n",
      "epoch : 138 , phase : train , loss : 0.6239037109375\n",
      "epoch : 138 , phase : valid , loss : 0.6221013671875\n",
      "epoch : 139 , phase : train , loss : 0.6239017578125\n",
      "epoch : 139 , phase : valid , loss : 0.622100078125\n",
      "epoch : 140 , phase : train , loss : 0.6238998828125\n",
      "epoch : 140 , phase : valid , loss : 0.622098828125\n",
      "epoch : 141 , phase : train , loss : 0.623898046875\n",
      "epoch : 141 , phase : valid , loss : 0.6220977734375\n",
      "epoch : 142 , phase : train , loss : 0.6238962890625\n",
      "epoch : 142 , phase : valid , loss : 0.6220965234375\n",
      "epoch : 143 , phase : train , loss : 0.623894609375\n",
      "epoch : 143 , phase : valid , loss : 0.62209546875\n",
      "epoch : 144 , phase : train , loss : 0.623892890625\n",
      "epoch : 144 , phase : valid , loss : 0.622094375\n",
      "epoch : 145 , phase : train , loss : 0.623891328125\n",
      "epoch : 145 , phase : valid , loss : 0.6220934765625\n",
      "epoch : 146 , phase : train , loss : 0.62388984375\n",
      "epoch : 146 , phase : valid , loss : 0.6220925390625\n",
      "epoch : 147 , phase : train , loss : 0.6238883984375\n",
      "epoch : 147 , phase : valid , loss : 0.6220916796875\n",
      "epoch : 148 , phase : train , loss : 0.62388703125\n",
      "epoch : 148 , phase : valid , loss : 0.62209078125\n",
      "epoch : 149 , phase : train , loss : 0.6238855859375\n",
      "epoch : 149 , phase : valid , loss : 0.6220898828125\n",
      "epoch : 150 , phase : train , loss : 0.62388421875\n",
      "epoch : 150 , phase : valid , loss : 0.6220891796875\n",
      "epoch : 151 , phase : train , loss : 0.62388296875\n",
      "epoch : 151 , phase : valid , loss : 0.6220883984375\n",
      "epoch : 152 , phase : train , loss : 0.623881796875\n",
      "epoch : 152 , phase : valid , loss : 0.622087734375\n",
      "epoch : 153 , phase : train , loss : 0.623880625\n",
      "epoch : 153 , phase : valid , loss : 0.6220869921875\n",
      "epoch : 154 , phase : train , loss : 0.6238794921875\n",
      "epoch : 154 , phase : valid , loss : 0.6220863671875\n",
      "epoch : 155 , phase : train , loss : 0.623878359375\n",
      "epoch : 155 , phase : valid , loss : 0.6220858203125\n",
      "epoch : 156 , phase : train , loss : 0.62387734375\n",
      "epoch : 156 , phase : valid , loss : 0.6220851953125\n",
      "epoch : 157 , phase : train , loss : 0.623876328125\n",
      "epoch : 157 , phase : valid , loss : 0.6220846484375\n",
      "epoch : 158 , phase : train , loss : 0.6238753125\n",
      "epoch : 158 , phase : valid , loss : 0.622084140625\n",
      "epoch : 159 , phase : train , loss : 0.623874375\n",
      "epoch : 159 , phase : valid , loss : 0.6220835546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 160 , phase : train , loss : 0.6238734765625\n",
      "epoch : 160 , phase : valid , loss : 0.622083125\n",
      "epoch : 161 , phase : train , loss : 0.6238726171875\n",
      "epoch : 161 , phase : valid , loss : 0.62208265625\n",
      "epoch : 162 , phase : train , loss : 0.62387171875\n",
      "epoch : 162 , phase : valid , loss : 0.6220822265625\n",
      "epoch : 163 , phase : train , loss : 0.6238709375\n",
      "epoch : 163 , phase : valid , loss : 0.622081796875\n",
      "epoch : 164 , phase : train , loss : 0.62387015625\n",
      "epoch : 164 , phase : valid , loss : 0.62208140625\n",
      "epoch : 165 , phase : train , loss : 0.6238693359375\n",
      "epoch : 165 , phase : valid , loss : 0.622081015625\n",
      "epoch : 166 , phase : train , loss : 0.6238686328125\n",
      "epoch : 166 , phase : valid , loss : 0.622080703125\n",
      "epoch : 167 , phase : train , loss : 0.623867890625\n",
      "epoch : 167 , phase : valid , loss : 0.6220803515625\n",
      "epoch : 168 , phase : train , loss : 0.6238672265625\n",
      "epoch : 168 , phase : valid , loss : 0.622080078125\n",
      "epoch : 169 , phase : train , loss : 0.6238666015625\n",
      "epoch : 169 , phase : valid , loss : 0.6220797265625\n",
      "epoch : 170 , phase : train , loss : 0.6238658984375\n",
      "epoch : 170 , phase : valid , loss : 0.6220794921875\n",
      "epoch : 171 , phase : train , loss : 0.6238652734375\n",
      "epoch : 171 , phase : valid , loss : 0.62207921875\n",
      "epoch : 172 , phase : train , loss : 0.6238647265625\n",
      "epoch : 172 , phase : valid , loss : 0.6220789453125\n",
      "epoch : 173 , phase : train , loss : 0.6238641015625\n",
      "epoch : 173 , phase : valid , loss : 0.6220787109375\n",
      "epoch : 174 , phase : train , loss : 0.62386359375\n",
      "epoch : 174 , phase : valid , loss : 0.6220784765625\n",
      "epoch : 175 , phase : train , loss : 0.623863046875\n",
      "epoch : 175 , phase : valid , loss : 0.6220783203125\n",
      "epoch : 176 , phase : train , loss : 0.623862578125\n",
      "epoch : 176 , phase : valid , loss : 0.6220780859375\n",
      "epoch : 177 , phase : train , loss : 0.6238620703125\n",
      "epoch : 177 , phase : valid , loss : 0.6220778515625\n",
      "epoch : 178 , phase : train , loss : 0.6238615625\n",
      "epoch : 178 , phase : valid , loss : 0.6220776953125\n",
      "epoch : 179 , phase : train , loss : 0.6238611328125\n",
      "epoch : 179 , phase : valid , loss : 0.6220775390625\n",
      "epoch : 180 , phase : train , loss : 0.6238606640625\n",
      "epoch : 180 , phase : valid , loss : 0.6220773828125\n",
      "epoch : 181 , phase : train , loss : 0.623860234375\n",
      "epoch : 181 , phase : valid , loss : 0.622077265625\n",
      "epoch : 182 , phase : train , loss : 0.62385984375\n",
      "epoch : 182 , phase : valid , loss : 0.6220771484375\n",
      "epoch : 183 , phase : train , loss : 0.6238594140625\n",
      "epoch : 183 , phase : valid , loss : 0.622076953125\n",
      "epoch : 184 , phase : train , loss : 0.623858984375\n",
      "epoch : 184 , phase : valid , loss : 0.622076875\n",
      "epoch : 185 , phase : train , loss : 0.6238586328125\n",
      "epoch : 185 , phase : valid , loss : 0.622076796875\n",
      "epoch : 186 , phase : train , loss : 0.6238583203125\n",
      "epoch : 186 , phase : valid , loss : 0.6220766796875\n",
      "epoch : 187 , phase : train , loss : 0.62385796875\n",
      "epoch : 187 , phase : valid , loss : 0.6220765625\n",
      "epoch : 188 , phase : train , loss : 0.6238576171875\n",
      "epoch : 188 , phase : valid , loss : 0.6220764453125\n",
      "epoch : 189 , phase : train , loss : 0.62385734375\n",
      "epoch : 189 , phase : valid , loss : 0.62207640625\n",
      "epoch : 190 , phase : train , loss : 0.623856953125\n",
      "epoch : 190 , phase : valid , loss : 0.6220763671875\n",
      "epoch : 191 , phase : train , loss : 0.6238566796875\n",
      "epoch : 191 , phase : valid , loss : 0.6220762890625\n",
      "epoch : 192 , phase : train , loss : 0.62385640625\n",
      "epoch : 192 , phase : valid , loss : 0.62207625\n",
      "epoch : 193 , phase : train , loss : 0.623856171875\n",
      "epoch : 193 , phase : valid , loss : 0.62207625\n",
      "epoch : 194 , phase : train , loss : 0.6238558203125\n",
      "epoch : 194 , phase : valid , loss : 0.6220761328125\n",
      "epoch : 195 , phase : train , loss : 0.6238555859375\n",
      "epoch : 195 , phase : valid , loss : 0.6220760546875\n",
      "epoch : 196 , phase : train , loss : 0.623855390625\n",
      "epoch : 196 , phase : valid , loss : 0.6220761328125\n",
      "epoch : 197 , phase : train , loss : 0.623855078125\n",
      "epoch : 197 , phase : valid , loss : 0.6220761328125\n",
      "epoch : 198 , phase : train , loss : 0.623854921875\n",
      "epoch : 198 , phase : valid , loss : 0.622076015625\n",
      "epoch : 199 , phase : train , loss : 0.6238546875\n",
      "epoch : 199 , phase : valid , loss : 0.622076015625\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100000\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    for phase in ['train','valid']:\n",
    "\n",
    "        if phase == 'train':\n",
    "            net.train(True)\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "        else:\n",
    "            net.train(False)\n",
    "            dataloader=torch.utils.data.DataLoader(\n",
    "                validset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        for data in dataloader: #tqdm(dataloader):\n",
    "            \n",
    "            X_b,y_b= data\n",
    "            X_b = X_b.float().cuda()\n",
    "            y_b = y_b.float().cuda()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(X_b.float())\n",
    "                loss = criterion(outputs,y_b.view(-1,1).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = net(X_b)\n",
    "                    loss = criterion(outputs, y_b)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader.dataset)\n",
    "        if phase=='train':\n",
    "            train_loss.append(final_loss)\n",
    "        else:\n",
    "            valid_loss.append(final_loss)\n",
    "            \n",
    "        print(\"epoch :\" , epoch, \", phase :\", phase, \", loss :\", final_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b15b265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento médio de código final no dataset de treino: 0.6238546875\n",
      "(compare com a entropia do dataset de treino).\n",
      "comprimento médio de código final no dataset de validação: 0.622076015625\n",
      "(compare com a entropia do dataset de validação).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"comprimento médio de código final no dataset de treino: {train_loss[-1]}\n",
    "(compare com a entropia do dataset de treino).\"\"\")\n",
    "\n",
    "print(f\"\"\"comprimento médio de código final no dataset de validação: {valid_loss[-1]}\n",
    "(compare com a entropia do dataset de validação).\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ca88",
   "metadata": {},
   "source": [
    "### Pesos aprendidos são aproximadamente os parâmetros usados para gerar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271db70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8959, 0.6037, 0.7009, 0.0253, 0.1345, 0.0318, 0.9280]],\n",
      "       device='cuda:0')\n",
      "tensor([0.0358], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41bac832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.89106724, 0.62633137, 0.70989337, 0.03960594, 0.1334368 ,\n",
       "         0.03148984, 0.92488601]]),\n",
       " array([[0.01856426]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.T, C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e33e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
